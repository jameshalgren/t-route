{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic imports and path management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "root = pathlib.Path(\"../../\").resolve()\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v02\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v01\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_routing_v01\")))\n",
    "sys.path.append(\".\")\n",
    "import nhd_io as nio\n",
    "import compute_nhd_routing_SingleSeg as tr\n",
    "import nhd_network_utilities_v01 as nnu\n",
    "import nhd_reach_utilities as nru\n",
    "\n",
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt60.yaml\"\n",
    "run_pocono2_test = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the primary data input from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supernetwork_parameters = None\n",
    "waterbody_parameters = None\n",
    "if custom_input_file:\n",
    "    (\n",
    "        supernetwork_parameters,\n",
    "        waterbody_parameters,\n",
    "        forcing_parameters,\n",
    "        restart_parameters,\n",
    "        output_parameters,\n",
    "        run_parameters,\n",
    "    ) = nio.read_custom_input(custom_input_folder.joinpath(custom_input_file))\n",
    "\n",
    "    break_network_at_waterbodies = run_parameters.get(\n",
    "        \"break_network_at_waterbodies\", None\n",
    "    )\n",
    "\n",
    "    dt = run_parameters.get(\"dt\", None)\n",
    "    nts = run_parameters.get(\"nts\", None)\n",
    "    qts_subdivisions = run_parameters.get(\"qts_subdivisions\", None)\n",
    "    debuglevel = -1 * int(run_parameters.get(\"debuglevel\", 0))\n",
    "    verbose = run_parameters.get(\"verbose\", None)\n",
    "    showtiming = run_parameters.get(\"showtiming\", None)\n",
    "    percentage_complete = run_parameters.get(\"percentage_complete\", None)\n",
    "    do_network_analysis_only = run_parameters.get(\"do_network_analysis_only\", None)\n",
    "    assume_short_ts = run_parameters.get(\"assume_short_ts\", None)\n",
    "    parallel_compute = run_parameters.get(\"parallel_compute\", None)\n",
    "    cpu_pool = run_parameters.get(\"cpu_pool\", None)\n",
    "    sort_networks = run_parameters.get(\"sort_networks\", None)\n",
    "\n",
    "    csv_output = output_parameters.get(\"csv_output\", None)\n",
    "    nc_output_folder = output_parameters.get(\"nc_output_folder\", None)\n",
    "\n",
    "    qlat_const = forcing_parameters.get(\"qlat_const\", None)\n",
    "    qlat_input_file = forcing_parameters.get(\"qlat_input_file\", None)\n",
    "    qlat_input_folder = forcing_parameters.get(\"qlat_input_folder\", None)\n",
    "    qlat_file_pattern_filter = forcing_parameters.get(\"qlat_file_pattern_filter\", None)\n",
    "    qlat_file_index_col = forcing_parameters.get(\"qlat_file_index_col\", None)\n",
    "    qlat_file_value_col = forcing_parameters.get(\"qlat_file_value_col\", None)\n",
    "\n",
    "    wrf_hydro_channel_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_upstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_upstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_downstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_downstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_depth_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_depth_flow_field_name\", None\n",
    "    )\n",
    "\n",
    "    wrf_hydro_waterbody_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file_field_name\", None\n",
    "    )\n",
    "\n",
    "# Any specific commandline arguments will override the file\n",
    "# TODO: There are probably some pathological collisions that could\n",
    "# arise from this ordering ... check these out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_pocono2_test:\n",
    "    if verbose:\n",
    "        print(\"running test case for Pocono_TEST2 domain\")\n",
    "    # Overwrite the following test defaults\n",
    "    supernetwork = \"Pocono_TEST2\"\n",
    "    break_network_at_waterbodies = False\n",
    "    qts_subdivisions = 1  # change qts_subdivisions = 1 as  default\n",
    "    dt = 300 / qts_subdivisions\n",
    "    nts = 144 * qts_subdivisions\n",
    "    csv_output = {\"csv_output_folder\": os.path.join(root, \"test\", \"output\", \"text\")}\n",
    "    nc_output_folder = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "    # test 1. Take lateral flow from re-formatted wrf-hydro output from Pocono Basin simulation\n",
    "    qlat_input_file = os.path.join(\n",
    "        root, r\"test/input/geo/PoconoSampleData2/Pocono_ql_testsamp1_nwm_mc.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showtiming:\n",
    "    program_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"begin program t-route ...\")\n",
    "\n",
    "# STEP 1: Read the supernetwork dataset and build the connections graph\n",
    "if verbose:\n",
    "    print(\"creating supernetwork connections set\")\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "\n",
    "if supernetwork_parameters:\n",
    "    supernetwork_values = nnu.get_nhd_connections(\n",
    "        supernetwork_parameters=supernetwork_parameters,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    test_folder = os.path.join(root, r\"test\")\n",
    "    geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "    supernetwork_parameters, supernetwork_values = nnu.set_networks(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "    waterbody_parameters = nnu.set_waterbody_parameters(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "if verbose:\n",
    "    print(\"supernetwork connections set complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "connections = supernetwork_values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Separate the networks and build the sub-graph of reaches within each network\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"organizing connections into reaches ...\")\n",
    "networks = nru.compose_networks(\n",
    "    supernetwork_values,\n",
    "    break_network_at_waterbodies=break_network_at_waterbodies,\n",
    "    verbose=False,\n",
    "    debuglevel=debuglevel,\n",
    "    showtiming=showtiming,\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(\"reach organization complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Organize Network for Waterbodies\n",
    "if break_network_at_waterbodies:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"reading waterbody parameter file ...\")\n",
    "\n",
    "    ## STEP 3a: Read waterbody parameter file\n",
    "    waterbodies_values = supernetwork_values[12]\n",
    "    waterbodies_segments = supernetwork_values[13]\n",
    "    connections_tailwaters = supernetwork_values[4]\n",
    "\n",
    "    waterbodies_df = nio.read_waterbody_df(waterbody_parameters, waterbodies_values,)\n",
    "    waterbodies_df = waterbodies_df.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "\n",
    "    nru.order_networks(connections, networks, connections_tailwaters)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbodies complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "    ## STEP 3b: Order subnetworks above and below reservoirs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks ...\")\n",
    "\n",
    "    max_network_seqorder = -1\n",
    "    for network in networks:\n",
    "        max_network_seqorder = max(\n",
    "            networks[network][\"network_seqorder\"], max_network_seqorder\n",
    "        )\n",
    "    ordered_networks = {}\n",
    "\n",
    "    for terminal_segment, network in networks.items():\n",
    "        if network[\"network_seqorder\"] not in ordered_networks:\n",
    "            ordered_networks[network[\"network_seqorder\"]] = []\n",
    "        ordered_networks[network[\"network_seqorder\"]].append(\n",
    "            (terminal_segment, network)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "else:\n",
    "    # If we are not splitting the networks, we can put them all in one order\n",
    "    max_network_seqorder = 0\n",
    "    ordered_networks = {}\n",
    "    ordered_networks[0] = [\n",
    "        (terminal_segment, network) for terminal_segment, network in networks.items()\n",
    "    ]\n",
    "\n",
    "if do_network_analysis_only:\n",
    "    sys.exit()\n",
    "\n",
    "if break_network_at_waterbodies:\n",
    "    ## STEP 3c: Handle Waterbody Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting waterbody initial states ...\")\n",
    "\n",
    "    if wrf_hydro_waterbody_restart_file:\n",
    "\n",
    "        waterbody_initial_states_df = nio.get_reservoir_restart_from_wrf_hydro(\n",
    "            wrf_hydro_waterbody_restart_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file_field_name,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file_field_name,\n",
    "        )\n",
    "    else:\n",
    "        # TODO: Consider adding option to read cold state from route-link file\n",
    "        waterbody_initial_ds_flow_const = 0.0\n",
    "        waterbody_initial_depth_const = 0.0\n",
    "        # Set initial states from cold-state\n",
    "        waterbody_initial_states_df = pd.DataFrame(\n",
    "            0, index=waterbodies_df.index, columns=[\"qd0\", \"h0\",], dtype=\"float32\"\n",
    "        )\n",
    "        # TODO: This assignment could probably by done in the above call\n",
    "        waterbody_initial_states_df[\"qd0\"] = waterbody_initial_ds_flow_const\n",
    "        waterbody_initial_states_df[\"h0\"] = waterbody_initial_depth_const\n",
    "        waterbody_initial_states_df[\"index\"] = range(len(waterbody_initial_states_df))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbody initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Handle Channel Initial States\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"setting channel initial states ...\")\n",
    "\n",
    "if wrf_hydro_channel_restart_file:\n",
    "\n",
    "    channel_initial_states_df = nio.get_stream_restart_from_wrf_hydro(\n",
    "        wrf_hydro_channel_restart_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file_field_name,\n",
    "        wrf_hydro_channel_restart_upstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_downstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_depth_flow_field_name,\n",
    "    )\n",
    "else:\n",
    "    # TODO: Consider adding option to read cold state from route-link file\n",
    "    channel_initial_us_flow_const = 0.0\n",
    "    channel_initial_ds_flow_const = 0.0\n",
    "    channel_initial_depth_const = 0.0\n",
    "    # Set initial states from cold-state\n",
    "    channel_initial_states_df = pd.DataFrame(\n",
    "        0, index=connections.keys(), columns=[\"qu0\", \"qd0\", \"h0\",], dtype=\"float32\"\n",
    "    )\n",
    "    channel_initial_states_df[\"qu0\"] = channel_initial_us_flow_const\n",
    "    channel_initial_states_df[\"qd0\"] = channel_initial_ds_flow_const\n",
    "    channel_initial_states_df[\"h0\"] = channel_initial_depth_const\n",
    "    channel_initial_states_df[\"index\"] = range(len(channel_initial_states_df))\n",
    "\n",
    "if verbose:\n",
    "    print(\"channel initial states complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Read (or set) QLateral Inputs\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"creating qlateral array ...\")\n",
    "\n",
    "# initialize qlateral dict\n",
    "qlateral = {}\n",
    "\n",
    "if qlat_input_folder:\n",
    "    qlat_files = []\n",
    "    for pattern in qlat_file_pattern_filter:\n",
    "        qlat_files.extend(glob.glob(qlat_input_folder + pattern))\n",
    "    qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "        qlat_files=qlat_files,\n",
    "        index_col=qlat_file_index_col,\n",
    "        value_col=qlat_file_value_col,\n",
    "    )\n",
    "\n",
    "elif qlat_input_file:\n",
    "    qlat_df = nio.get_ql_from_csv(qlat_input_file)\n",
    "\n",
    "else:\n",
    "    qlat_df = pd.DataFrame(\n",
    "        qlat_const, index=connections.keys(), columns=range(nts), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "for index, row in qlat_df.iterrows():\n",
    "    qlateral[index] = row.tolist()\n",
    "\n",
    "if verbose:\n",
    "    print(\"qlateral array complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Sort the ordered networks\n",
    "if sort_networks:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"sorting the ordered networks ...\")\n",
    "\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        sort_ordered_network(ordered_networks[nsq], True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"sorting complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pool after we create the static global objects (and collect the garbage)\n",
    "if parallel_compute:\n",
    "    import gc\n",
    "\n",
    "    gc.collect()\n",
    "    pool = multiprocessing.Pool(cpu_pool)\n",
    "\n",
    "flowveldepth_connect = (\n",
    "    {}\n",
    ")  # dict to contain values to transfer from upstream to downstream networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Main Execution Loop across ordered networks\n",
    "if showtiming:\n",
    "    main_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"executing routing computation ...\")\n",
    "\n",
    "compute_network_func = tr.compute_network\n",
    "\n",
    "tr.connections_g = connections\n",
    "tr.networks_g = networks\n",
    "tr.qlateral_g = qlateral\n",
    "tr.waterbodies_df_g = waterbodies_df\n",
    "tr.waterbody_initial_states_df_g = waterbody_initial_states_df\n",
    "tr.channel_initial_states_df_g = channel_initial_states_df\n",
    "\n",
    "progress_count = 0\n",
    "percentage_complete = True\n",
    "if percentage_complete:\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        for terminal_segment, network in ordered_networks[nsq]:\n",
    "            progress_count += len(network[\"all_segments\"])\n",
    "    pbar = tqdm(total=(progress_count))\n",
    "\n",
    "for nsq in range(max_network_seqorder, -1, -1):\n",
    "\n",
    "    if parallel_compute:\n",
    "        nslist = []\n",
    "    results = []\n",
    "\n",
    "    current_index_total = 0\n",
    "\n",
    "    for terminal_segment, network in ordered_networks[nsq]:\n",
    "\n",
    "        if percentage_complete:\n",
    "            if current_index_total == 0:\n",
    "                pbar.update(0)\n",
    "\n",
    "        if break_network_at_waterbodies:\n",
    "            waterbody = waterbodies_segments.get(terminal_segment)\n",
    "        else:\n",
    "            waterbody = None\n",
    "        if not parallel_compute:  # serial execution\n",
    "            if showtiming:\n",
    "                start_time = time.time()\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"routing ordered reaches for terminal segment {terminal_segment} ...\"\n",
    "                )\n",
    "\n",
    "            results.append(\n",
    "                compute_network_func(\n",
    "                    flowveldepth_connect=flowveldepth_connect,\n",
    "                    terminal_segment=terminal_segment,\n",
    "                    supernetwork_parameters=supernetwork_parameters,\n",
    "                    waterbody_parameters=waterbody_parameters,\n",
    "                    waterbody=waterbody,\n",
    "                    nts=nts,\n",
    "                    dt=dt,\n",
    "                    qts_subdivisions=qts_subdivisions,\n",
    "                    verbose=verbose,\n",
    "                    debuglevel=debuglevel,\n",
    "                    csv_output=csv_output,\n",
    "                    nc_output_folder=nc_output_folder,\n",
    "                    assume_short_ts=assume_short_ts,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if showtiming:\n",
    "                print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "            if percentage_complete:\n",
    "                pbar.update(len(network[\"all_segments\"]))\n",
    "\n",
    "        else:  # parallel execution\n",
    "            nslist.append(\n",
    "                [\n",
    "                    flowveldepth_connect,\n",
    "                    terminal_segment,\n",
    "                    supernetwork_parameters,  # TODO: This should probably be global...\n",
    "                    waterbody_parameters,\n",
    "                    waterbody,\n",
    "                    nts,\n",
    "                    dt,\n",
    "                    qts_subdivisions,\n",
    "                    verbose,\n",
    "                    debuglevel,\n",
    "                    csv_output,\n",
    "                    nc_output_folder,\n",
    "                    assume_short_ts,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    if parallel_compute:\n",
    "        if verbose:\n",
    "            print(f\"routing ordered reaches for networks of order {nsq} ... \")\n",
    "        if debuglevel <= -2:\n",
    "            print(f\"reaches to be routed include:\")\n",
    "            print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "        # with pool:\n",
    "        # with multiprocessing.Pool() as pool:\n",
    "        results = pool.starmap(compute_network_func, nslist)\n",
    "\n",
    "        if showtiming:\n",
    "            print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "        if percentage_complete:\n",
    "            pbar.update(\n",
    "                sum(\n",
    "                    len(network[1][\"all_segments\"]) for network in ordered_networks[nsq]\n",
    "                )\n",
    "            )\n",
    "            # print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "\n",
    "    max_courant = 0\n",
    "    maxa = []\n",
    "    for result in results:\n",
    "        for seg in result:\n",
    "            maxa.extend(result[seg][:, 8:9])\n",
    "    max_courant = max(maxa)\n",
    "    print(f\"max_courant: {max_courant}\")\n",
    "\n",
    "    if (\n",
    "        nsq > 0\n",
    "    ):  # We skip this step for zero-order networks, i.e., those that have no downstream dependents\n",
    "        flowveldepth_connect = (\n",
    "            {}\n",
    "        )  # There is no need to preserve previously passed on values -- so we clear the dictionary\n",
    "        for i, (terminal_segment, network) in enumerate(ordered_networks[nsq]):\n",
    "            # seg = network[\"reaches\"][network[\"terminal_reach\"]][\"reach_tail\"]\n",
    "            seg = terminal_segment\n",
    "            flowveldepth_connect[seg] = {}\n",
    "            flowveldepth_connect[seg] = results[i][seg]\n",
    "            # TODO: The value passed here could be much more specific to\n",
    "            # TODO: exactly and only the most recent time step for the passing reach\n",
    "\n",
    "if parallel_compute:\n",
    "    pool.close()\n",
    "\n",
    "if percentage_complete:\n",
    "    pbar.close()\n",
    "\n",
    "if verbose:\n",
    "    print(\"ordered reach computation complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - main_start_time))\n",
    "if verbose:\n",
    "    print(\"program complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - program_start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the main dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results)\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "all_results = {}\n",
    "seg_courant_maxes = []\n",
    "time = []\n",
    "flowval = []  # flowval\n",
    "velval_list = []  # velval\n",
    "depthval = []  # depthval\n",
    "qlatval = []  # qlatval\n",
    "storageval = []  # storageval\n",
    "qlatCumval = []  # qlatCumval\n",
    "kinCelerity = []  # ck\n",
    "courant = []  # cn\n",
    "X = []  # X\n",
    "\n",
    "for result in results:\n",
    "    all_results.update(result)\n",
    "\n",
    "# print(all_results[8780801][1][0])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# print(all_results)\n",
    "\n",
    "for key, data in all_results.items():\n",
    "    time.extend(data[:, 0])  # time\n",
    "    flowval.extend(data[:, 1])  # flowval\n",
    "    velval_list.extend(data[:, 2])  # velval\n",
    "    depthval.extend(data[:, 3])  # depthval\n",
    "    qlatval.extend(data[:, 4])  # qlatval\n",
    "    storageval.extend(data[:, 5])  # storageval\n",
    "    qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "    kinCelerity.extend(data[:, 7])  # ck\n",
    "    courant.extend(data[:, 8])  # cn\n",
    "    X.extend(data[:, 9])  # X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_seg_length = len(all_results[933020089][:, 0])\n",
    "single_seg_length * 611\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_index = all_results.keys()\n",
    "key_index = list(\n",
    "    itertools.chain.from_iterable(\n",
    "        itertools.repeat(x, single_seg_length) for x in key_index\n",
    "    )\n",
    ")\n",
    "data = {\n",
    "    \"key_index\": list(key_index),\n",
    "    \"time\": list(time),\n",
    "    \"flowval\": list(flowval),\n",
    "    \"velval_list\": list(velval_list),\n",
    "    \"depthval\": list(depthval),\n",
    "    \"qlatval\": list(qlatval),\n",
    "    \"storageval\": list(storageval),\n",
    "    \"qlatCumval\": list(qlatCumval),\n",
    "    \"kinCelerity\": list(kinCelerity),\n",
    "    \"courant\": list(courant),\n",
    "    \"X\": list(X),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index(\"key_index\")\n",
    "df = df.reset_index()\n",
    "df = df.set_index(\"key_index\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 25 courants based on our work this morning and their segment IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list = []\n",
    "seg_courant_maxes = []\n",
    "for seg in all_results:\n",
    "    seg_list.append(seg)\n",
    "    seg_courant_maxes.append(max(all_results[seg][:, tr.courant_index]))\n",
    "zipped = zip(seg_list, seg_courant_maxes)\n",
    "zipped = list(zipped)\n",
    "res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "# A.sort(reverse=True)\n",
    "res = (res)[:25]\n",
    "print((res)[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of those IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_segments = []\n",
    "for x, y in res[:25]:\n",
    "    major_segments.append(x)\n",
    "major_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the above segment IDs from the original df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"courant\"] == 25.363832473754883]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated plotter based on filtered dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "import plotly.io as pio\n",
    "\n",
    "df_indexed = df_filtered.reset_index()\n",
    "test_chart = go.FigureWidget()\n",
    "for x in range(0, 25):\n",
    "    temp_df_range_1 = single_seg_length * (x)\n",
    "    temp_df_range_2 = single_seg_length * (x + 1)\n",
    "    print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed[\"key_index\"][temp_df_range_1]),\n",
    "    )\n",
    "test_chart.layout.title = \"Timestep Chart \" + str(dt)\n",
    "plot(test_chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt300.yaml\"\n",
    "all_results = tr.route_supernetwork(\n",
    "    tr.connections_g,\n",
    "    tr.networks_g,\n",
    "    tr.qlateral_g,\n",
    "    tr.waterbodies_df_g,\n",
    "    tr.waterbody_initial_states_df_g,\n",
    "    tr.channel_initial_states_df_g,\n",
    "    custom_input_file=custom_input_folder.joinpath(custom_input_file),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "florence_933020089_dt300.yaml\n",
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.03496813774108887 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.0044324398040771484 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.015255451202392578 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 3.7670135498046875e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.018177509307861328 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.020459413528442383 seconds.\n",
      "creating qlateral array ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qlateral array complete\n",
      "... in 5.738178968429565 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1108 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 467/1108 [00:06<00:08, 76.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 7.489843368530273 seconds.\n",
      "max_courant: [27.53112221]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 499/1108 [00:09<00:24, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 10.875653982162476 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [00:19<00:00, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 20.84665608406067 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [00:20<00:00, 55.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [126.81378174]\n",
      "ordered reach computation complete\n",
      "... in 20.07181739807129 seconds.\n",
      "program complete\n",
      "... in 27.28542709350586 seconds.\n",
      "2016 10080\n",
      "      key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0       8777735       0.0  0.004696     0.206769  0.011542  0.000035   \n",
      "1       8777735     300.0  0.004707     0.206968  0.011559  0.000035   \n",
      "2       8777735     600.0  0.004716     0.207135  0.011573  0.000035   \n",
      "3       8777735     900.0  0.004724     0.207273  0.011584  0.000035   \n",
      "4       8777735    1200.0  0.004730     0.207388  0.011594  0.000035   \n",
      "...         ...       ...       ...          ...       ...       ...   \n",
      "6043  933020027  603300.0  0.058953     0.755009  0.049310  0.000000   \n",
      "6044  933020027  603600.0  0.058909     0.754795  0.049287  0.000000   \n",
      "6045  933020027  603900.0  0.058867     0.754590  0.049266  0.000000   \n",
      "6046  933020027  604200.0  0.058826     0.754394  0.049246  0.000000   \n",
      "6047  933020027  604500.0  0.058788     0.754206  0.049226  0.000000   \n",
      "\n",
      "      storageval  qlatCumval  kinCelerity    courant         X  \n",
      "0       0.000012    0.010392     0.341748   9.320413  0.497108  \n",
      "1       0.000021    0.020784     0.342073   9.329271  0.497105  \n",
      "2       0.000030    0.031175     0.342345   9.336675  0.497101  \n",
      "3       0.000036    0.041567     0.342571   9.342841  0.497099  \n",
      "4       0.000042    0.051959     0.342759   9.347967  0.497096  \n",
      "...          ...         ...          ...        ...       ...  \n",
      "6043   90.658967    0.000000     1.211574  36.347221  0.493714  \n",
      "6044   90.658884    0.000000     1.211248  36.337448  0.493717  \n",
      "6045   90.658805    0.000000     1.210937  36.328110  0.493719  \n",
      "6046   90.658730    0.000000     1.210639  36.319172  0.493722  \n",
      "6047   90.658657    0.000000     1.210353  36.310593  0.493724  \n",
      "\n",
      "[6048 rows x 11 columns] Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "florence_933020089_dt60.yaml\n",
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.02541375160217285 seconds.\n",
      "organizing connections into reaches ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reach organization complete\n",
      "... in 0.1449296474456787 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.013668060302734375 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 3.7670135498046875e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.017720937728881836 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.018649578094482422 seconds.\n",
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 5.37065863609314 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1108 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 467/1108 [00:30<00:41, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 30.948049068450928 seconds.\n",
      "max_courant: [5.51265717]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 499/1108 [00:43<01:40,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 43.799787521362305 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [01:32<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 93.53104567527771 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [01:35<00:00, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [25.36383247]\n",
      "ordered reach computation complete\n",
      "... in 95.64656949043274 seconds.\n",
      "program complete\n",
      "... in 101.93572330474854 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 10080\n",
      "      key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0       8777735       0.0  0.004696     0.206769  0.011542  0.000035   \n",
      "1       8777735     300.0  0.004707     0.206968  0.011559  0.000035   \n",
      "2       8777735     600.0  0.004716     0.207135  0.011573  0.000035   \n",
      "3       8777735     900.0  0.004724     0.207273  0.011584  0.000035   \n",
      "4       8777735    1200.0  0.004730     0.207388  0.011594  0.000035   \n",
      "...         ...       ...       ...          ...       ...       ...   \n",
      "6043  933020027  603300.0  0.058953     0.755009  0.049310  0.000000   \n",
      "6044  933020027  603600.0  0.058909     0.754795  0.049287  0.000000   \n",
      "6045  933020027  603900.0  0.058867     0.754590  0.049266  0.000000   \n",
      "6046  933020027  604200.0  0.058826     0.754394  0.049246  0.000000   \n",
      "6047  933020027  604500.0  0.058788     0.754206  0.049226  0.000000   \n",
      "\n",
      "      storageval  qlatCumval  kinCelerity    courant         X  \n",
      "0       0.000012    0.010392     0.341748   9.320413  0.497108  \n",
      "1       0.000021    0.020784     0.342073   9.329271  0.497105  \n",
      "2       0.000030    0.031175     0.342345   9.336675  0.497101  \n",
      "3       0.000036    0.041567     0.342571   9.342841  0.497099  \n",
      "4       0.000042    0.051959     0.342759   9.347967  0.497096  \n",
      "...          ...         ...          ...        ...       ...  \n",
      "6043   90.658967    0.000000     1.211574  36.347221  0.493714  \n",
      "6044   90.658884    0.000000     1.211248  36.337448  0.493717  \n",
      "6045   90.658805    0.000000     1.210937  36.328110  0.493719  \n",
      "6046   90.658730    0.000000     1.210639  36.319172  0.493722  \n",
      "6047   90.658657    0.000000     1.210353  36.310593  0.493724  \n",
      "\n",
      "[6048 rows x 11 columns]        key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0        8777735       0.0  0.004696     0.206769  0.011542  0.000035   \n",
      "1        8777735      60.0  0.004698     0.206816  0.011546  0.000035   \n",
      "2        8777735     120.0  0.004700     0.206857  0.011549  0.000035   \n",
      "3        8777735     180.0  0.004703     0.206897  0.011552  0.000035   \n",
      "4        8777735     240.0  0.004705     0.206935  0.011556  0.000035   \n",
      "...          ...       ...       ...          ...       ...       ...   \n",
      "30235  933020027  604500.0  0.058770     0.754123  0.049218  0.000000   \n",
      "30236  933020027  604560.0  0.058763     0.754086  0.049214  0.000000   \n",
      "30237  933020027  604620.0  0.058755     0.754050  0.049210  0.000000   \n",
      "30238  933020027  604680.0  0.058748     0.754015  0.049206  0.000000   \n",
      "30239  933020027  604740.0  0.058741     0.753979  0.049203  0.000000   \n",
      "\n",
      "       storageval  qlatCumval  kinCelerity   courant         X  \n",
      "0        0.000002    0.002078     0.341748  1.864082  0.497108  \n",
      "1        0.000003    0.004157     0.341824  1.864496  0.497108  \n",
      "2        0.000003    0.006235     0.341891  1.864862  0.497107  \n",
      "3        0.000004    0.008313     0.341956  1.865216  0.497106  \n",
      "4        0.000004    0.010392     0.342019  1.865557  0.497106  \n",
      "...           ...         ...          ...       ...       ...  \n",
      "30235    4.286447    0.000000     1.210227  7.261362  0.493725  \n",
      "30236    4.286444    0.000000     1.210172  7.261031  0.493726  \n",
      "30237    4.286441    0.000000     1.210117  7.260703  0.493726  \n",
      "30238    4.286438    0.000000     1.210063  7.260379  0.493727  \n",
      "30239    4.286436    0.000000     1.210009  7.260056  0.493727  \n",
      "\n",
      "[30240 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_input_file_list = [\"florence_933020089_dt300.yaml\",\"florence_933020089_dt60.yaml\"]\n",
    "df_indexed_300 = pd.DataFrame()\n",
    "df_indexed_60 = pd.DataFrame()\n",
    "for c_i in (custom_input_file_list):\n",
    "    print(c_i)\n",
    "    import pathlib\n",
    "    import sys\n",
    "    import time\n",
    "    import glob\n",
    "    from tqdm import tqdm\n",
    "    import multiprocessing\n",
    "\n",
    "    root = pathlib.Path(\"../../\").resolve()\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_framework_v02\")))\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_framework_v01\")))\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_routing_v01\")))\n",
    "    sys.path.append(\".\")\n",
    "    import nhd_io as nio\n",
    "    import compute_nhd_routing_SingleSeg as tr\n",
    "    import nhd_network_utilities_v01 as nnu\n",
    "    import nhd_reach_utilities as nru\n",
    "\n",
    "    custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "    custom_input_file = c_i\n",
    "    run_pocono2_test = None\n",
    "\n",
    "    supernetwork_parameters = None\n",
    "    waterbody_parameters = None\n",
    "    if custom_input_file:\n",
    "        (\n",
    "            supernetwork_parameters,\n",
    "            waterbody_parameters,\n",
    "            forcing_parameters,\n",
    "            restart_parameters,\n",
    "            output_parameters,\n",
    "            run_parameters,\n",
    "        ) = nio.read_custom_input(custom_input_folder.joinpath(custom_input_file))\n",
    "\n",
    "        break_network_at_waterbodies = run_parameters.get(\n",
    "            \"break_network_at_waterbodies\", None\n",
    "        )\n",
    "\n",
    "        dt = run_parameters.get(\"dt\", None)\n",
    "        nts = run_parameters.get(\"nts\", None)\n",
    "        qts_subdivisions = run_parameters.get(\"qts_subdivisions\", None)\n",
    "        debuglevel = -1 * int(run_parameters.get(\"debuglevel\", 0))\n",
    "        verbose = run_parameters.get(\"verbose\", None)\n",
    "        showtiming = run_parameters.get(\"showtiming\", None)\n",
    "        percentage_complete = run_parameters.get(\"percentage_complete\", None)\n",
    "        do_network_analysis_only = run_parameters.get(\"do_network_analysis_only\", None)\n",
    "        assume_short_ts = run_parameters.get(\"assume_short_ts\", None)\n",
    "        parallel_compute = run_parameters.get(\"parallel_compute\", None)\n",
    "        cpu_pool = run_parameters.get(\"cpu_pool\", None)\n",
    "        sort_networks = run_parameters.get(\"sort_networks\", None)\n",
    "\n",
    "        csv_output = output_parameters.get(\"csv_output\", None)\n",
    "        nc_output_folder = output_parameters.get(\"nc_output_folder\", None)\n",
    "\n",
    "        qlat_const = forcing_parameters.get(\"qlat_const\", None)\n",
    "        qlat_input_file = forcing_parameters.get(\"qlat_input_file\", None)\n",
    "        qlat_input_folder = forcing_parameters.get(\"qlat_input_folder\", None)\n",
    "        qlat_file_pattern_filter = forcing_parameters.get(\"qlat_file_pattern_filter\", None)\n",
    "        qlat_file_index_col = forcing_parameters.get(\"qlat_file_index_col\", None)\n",
    "        qlat_file_value_col = forcing_parameters.get(\"qlat_file_value_col\", None)\n",
    "\n",
    "        wrf_hydro_channel_restart_file = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_file\", None\n",
    "        )\n",
    "        wrf_hydro_channel_ID_crosswalk_file = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_ID_crosswalk_file\", None\n",
    "        )\n",
    "        wrf_hydro_channel_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_ID_crosswalk_file_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_upstream_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_upstream_flow_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_downstream_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_downstream_flow_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_depth_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_depth_flow_field_name\", None\n",
    "        )\n",
    "\n",
    "        wrf_hydro_waterbody_restart_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_restart_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_ID_crosswalk_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_ID_crosswalk_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_ID_crosswalk_file_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_crosswalk_filter_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_crosswalk_filter_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_crosswalk_filter_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_crosswalk_filter_file_field_name\", None\n",
    "        )\n",
    "\n",
    "    # Any specific commandline arguments will override the file\n",
    "    # TODO: There are probably some pathological collisions that could\n",
    "    # arise from this ordering ... check these out.\n",
    "\n",
    "    if run_pocono2_test:\n",
    "        if verbose:\n",
    "            print(\"running test case for Pocono_TEST2 domain\")\n",
    "        # Overwrite the following test defaults\n",
    "        supernetwork = \"Pocono_TEST2\"\n",
    "        break_network_at_waterbodies = False\n",
    "        qts_subdivisions = 1  # change qts_subdivisions = 1 as  default\n",
    "        dt = 300 / qts_subdivisions\n",
    "        nts = 144 * qts_subdivisions\n",
    "        csv_output = {\"csv_output_folder\": os.path.join(root, \"test\", \"output\", \"text\")}\n",
    "        nc_output_folder = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "        # test 1. Take lateral flow from re-formatted wrf-hydro output from Pocono Basin simulation\n",
    "        qlat_input_file = os.path.join(\n",
    "            root, r\"test/input/geo/PoconoSampleData2/Pocono_ql_testsamp1_nwm_mc.csv\"\n",
    "        )\n",
    "    if showtiming:\n",
    "        program_start_time = time.time()\n",
    "    if verbose:\n",
    "        print(f\"begin program t-route ...\")\n",
    "\n",
    "    # STEP 1: Read the supernetwork dataset and build the connections graph\n",
    "    if verbose:\n",
    "        print(\"creating supernetwork connections set\")\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "\n",
    "    if supernetwork_parameters:\n",
    "        supernetwork_values = nnu.get_nhd_connections(\n",
    "            supernetwork_parameters=supernetwork_parameters,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        test_folder = os.path.join(root, r\"test\")\n",
    "        geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "        supernetwork_parameters, supernetwork_values = nnu.set_networks(\n",
    "            supernetwork=supernetwork,\n",
    "            geo_input_folder=geo_input_folder,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "        waterbody_parameters = nnu.set_waterbody_parameters(\n",
    "            supernetwork=supernetwork,\n",
    "            geo_input_folder=geo_input_folder,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"supernetwork connections set complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    connections = supernetwork_values[0]\n",
    "    # STEP 2: Separate the networks and build the sub-graph of reaches within each network\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"organizing connections into reaches ...\")\n",
    "    networks = nru.compose_networks(\n",
    "        supernetwork_values,\n",
    "        break_network_at_waterbodies=break_network_at_waterbodies,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "        showtiming=showtiming,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"reach organization complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 3: Organize Network for Waterbodies\n",
    "    if break_network_at_waterbodies:\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"reading waterbody parameter file ...\")\n",
    "\n",
    "        ## STEP 3a: Read waterbody parameter file\n",
    "        waterbodies_values = supernetwork_values[12]\n",
    "        waterbodies_segments = supernetwork_values[13]\n",
    "        connections_tailwaters = supernetwork_values[4]\n",
    "\n",
    "        waterbodies_df = nio.read_waterbody_df(waterbody_parameters, waterbodies_values,)\n",
    "        waterbodies_df = waterbodies_df.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "\n",
    "        nru.order_networks(connections, networks, connections_tailwaters)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"waterbodies complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "\n",
    "        ## STEP 3b: Order subnetworks above and below reservoirs\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"ordering waterbody subnetworks ...\")\n",
    "\n",
    "        max_network_seqorder = -1\n",
    "        for network in networks:\n",
    "            max_network_seqorder = max(\n",
    "                networks[network][\"network_seqorder\"], max_network_seqorder\n",
    "            )\n",
    "        ordered_networks = {}\n",
    "\n",
    "        for terminal_segment, network in networks.items():\n",
    "            if network[\"network_seqorder\"] not in ordered_networks:\n",
    "                ordered_networks[network[\"network_seqorder\"]] = []\n",
    "            ordered_networks[network[\"network_seqorder\"]].append(\n",
    "                (terminal_segment, network)\n",
    "            )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"ordering waterbody subnetworks complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "\n",
    "    else:\n",
    "        # If we are not splitting the networks, we can put them all in one order\n",
    "        max_network_seqorder = 0\n",
    "        ordered_networks = {}\n",
    "        ordered_networks[0] = [\n",
    "            (terminal_segment, network) for terminal_segment, network in networks.items()\n",
    "        ]\n",
    "\n",
    "    if do_network_analysis_only:\n",
    "        sys.exit()\n",
    "\n",
    "    if break_network_at_waterbodies:\n",
    "        ## STEP 3c: Handle Waterbody Initial States\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"setting waterbody initial states ...\")\n",
    "\n",
    "        if wrf_hydro_waterbody_restart_file:\n",
    "\n",
    "            waterbody_initial_states_df = nio.get_reservoir_restart_from_wrf_hydro(\n",
    "                wrf_hydro_waterbody_restart_file,\n",
    "                wrf_hydro_waterbody_ID_crosswalk_file,\n",
    "                wrf_hydro_waterbody_ID_crosswalk_file_field_name,\n",
    "                wrf_hydro_waterbody_crosswalk_filter_file,\n",
    "                wrf_hydro_waterbody_crosswalk_filter_file_field_name,\n",
    "            )\n",
    "        else:\n",
    "            # TODO: Consider adding option to read cold state from route-link file\n",
    "            waterbody_initial_ds_flow_const = 0.0\n",
    "            waterbody_initial_depth_const = 0.0\n",
    "            # Set initial states from cold-state\n",
    "            waterbody_initial_states_df = pd.DataFrame(\n",
    "                0, index=waterbodies_df.index, columns=[\"qd0\", \"h0\",], dtype=\"float32\"\n",
    "            )\n",
    "            # TODO: This assignment could probably by done in the above call\n",
    "            waterbody_initial_states_df[\"qd0\"] = waterbody_initial_ds_flow_const\n",
    "            waterbody_initial_states_df[\"h0\"] = waterbody_initial_depth_const\n",
    "            waterbody_initial_states_df[\"index\"] = range(len(waterbody_initial_states_df))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"waterbody initial states complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "    # STEP 4: Handle Channel Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting channel initial states ...\")\n",
    "\n",
    "    if wrf_hydro_channel_restart_file:\n",
    "\n",
    "        channel_initial_states_df = nio.get_stream_restart_from_wrf_hydro(\n",
    "            wrf_hydro_channel_restart_file,\n",
    "            wrf_hydro_channel_ID_crosswalk_file,\n",
    "            wrf_hydro_channel_ID_crosswalk_file_field_name,\n",
    "            wrf_hydro_channel_restart_upstream_flow_field_name,\n",
    "            wrf_hydro_channel_restart_downstream_flow_field_name,\n",
    "            wrf_hydro_channel_restart_depth_flow_field_name,\n",
    "        )\n",
    "    else:\n",
    "        # TODO: Consider adding option to read cold state from route-link file\n",
    "        channel_initial_us_flow_const = 0.0\n",
    "        channel_initial_ds_flow_const = 0.0\n",
    "        channel_initial_depth_const = 0.0\n",
    "        # Set initial states from cold-state\n",
    "        channel_initial_states_df = pd.DataFrame(\n",
    "            0, index=connections.keys(), columns=[\"qu0\", \"qd0\", \"h0\",], dtype=\"float32\"\n",
    "        )\n",
    "        channel_initial_states_df[\"qu0\"] = channel_initial_us_flow_const\n",
    "        channel_initial_states_df[\"qd0\"] = channel_initial_ds_flow_const\n",
    "        channel_initial_states_df[\"h0\"] = channel_initial_depth_const\n",
    "        channel_initial_states_df[\"index\"] = range(len(channel_initial_states_df))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"channel initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 5: Read (or set) QLateral Inputs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"creating qlateral array ...\")\n",
    "\n",
    "    # initialize qlateral dict\n",
    "    qlateral = {}\n",
    "\n",
    "    if qlat_input_folder:\n",
    "        qlat_files = []\n",
    "        for pattern in qlat_file_pattern_filter:\n",
    "            qlat_files.extend(glob.glob(qlat_input_folder + pattern))\n",
    "        qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "            qlat_files=qlat_files,\n",
    "            index_col=qlat_file_index_col,\n",
    "            value_col=qlat_file_value_col,\n",
    "        )\n",
    "\n",
    "    elif qlat_input_file:\n",
    "        qlat_df = nio.get_ql_from_csv(qlat_input_file)\n",
    "\n",
    "    else:\n",
    "        qlat_df = pd.DataFrame(\n",
    "            qlat_const, index=connections.keys(), columns=range(nts), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "    for index, row in qlat_df.iterrows():\n",
    "        qlateral[index] = row.tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"qlateral array complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 6: Sort the ordered networks\n",
    "    if sort_networks:\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"sorting the ordered networks ...\")\n",
    "\n",
    "        for nsq in range(max_network_seqorder, -1, -1):\n",
    "            sort_ordered_network(ordered_networks[nsq], True)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"sorting complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "    # Define the pool after we create the static global objects (and collect the garbage)\n",
    "    if parallel_compute:\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "        pool = multiprocessing.Pool(cpu_pool)\n",
    "\n",
    "    flowveldepth_connect = (\n",
    "        {}\n",
    "    )  # dict to contain values to transfer from upstream to downstream networks\n",
    "    ################### Main Execution Loop across ordered networks\n",
    "    if showtiming:\n",
    "        main_start_time = time.time()\n",
    "    if verbose:\n",
    "        print(f\"executing routing computation ...\")\n",
    "\n",
    "    compute_network_func = tr.compute_network\n",
    "\n",
    "    tr.connections_g = connections\n",
    "    tr.networks_g = networks\n",
    "    tr.qlateral_g = qlateral\n",
    "    tr.waterbodies_df_g = waterbodies_df\n",
    "    tr.waterbody_initial_states_df_g = waterbody_initial_states_df\n",
    "    tr.channel_initial_states_df_g = channel_initial_states_df\n",
    "\n",
    "    progress_count = 0\n",
    "    percentage_complete = True\n",
    "    if percentage_complete:\n",
    "        for nsq in range(max_network_seqorder, -1, -1):\n",
    "            for terminal_segment, network in ordered_networks[nsq]:\n",
    "                progress_count += len(network[\"all_segments\"])\n",
    "        pbar = tqdm(total=(progress_count))\n",
    "\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "\n",
    "        if parallel_compute:\n",
    "            nslist = []\n",
    "        results = []\n",
    "\n",
    "        current_index_total = 0\n",
    "\n",
    "        for terminal_segment, network in ordered_networks[nsq]:\n",
    "\n",
    "            if percentage_complete:\n",
    "                if current_index_total == 0:\n",
    "                    pbar.update(0)\n",
    "\n",
    "            if break_network_at_waterbodies:\n",
    "                waterbody = waterbodies_segments.get(terminal_segment)\n",
    "            else:\n",
    "                waterbody = None\n",
    "            if not parallel_compute:  # serial execution\n",
    "                if showtiming:\n",
    "                    start_time = time.time()\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"routing ordered reaches for terminal segment {terminal_segment} ...\"\n",
    "                    )\n",
    "\n",
    "                results.append(\n",
    "                    compute_network_func(\n",
    "                        flowveldepth_connect=flowveldepth_connect,\n",
    "                        terminal_segment=terminal_segment,\n",
    "                        supernetwork_parameters=supernetwork_parameters,\n",
    "                        waterbody_parameters=waterbody_parameters,\n",
    "                        waterbody=waterbody,\n",
    "                        nts=nts,\n",
    "                        dt=dt,\n",
    "                        qts_subdivisions=qts_subdivisions,\n",
    "                        verbose=verbose,\n",
    "                        debuglevel=debuglevel,\n",
    "                        csv_output=csv_output,\n",
    "                        nc_output_folder=nc_output_folder,\n",
    "                        assume_short_ts=assume_short_ts,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if showtiming:\n",
    "                    print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "                if percentage_complete:\n",
    "                    pbar.update(len(network[\"all_segments\"]))\n",
    "\n",
    "            else:  # parallel execution\n",
    "                nslist.append(\n",
    "                    [\n",
    "                        flowveldepth_connect,\n",
    "                        terminal_segment,\n",
    "                        supernetwork_parameters,  # TODO: This should probably be global...\n",
    "                        waterbody_parameters,\n",
    "                        waterbody,\n",
    "                        nts,\n",
    "                        dt,\n",
    "                        qts_subdivisions,\n",
    "                        verbose,\n",
    "                        debuglevel,\n",
    "                        csv_output,\n",
    "                        nc_output_folder,\n",
    "                        assume_short_ts,\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        if parallel_compute:\n",
    "            if verbose:\n",
    "                print(f\"routing ordered reaches for networks of order {nsq} ... \")\n",
    "            if debuglevel <= -2:\n",
    "                print(f\"reaches to be routed include:\")\n",
    "                print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "            # with pool:\n",
    "            # with multiprocessing.Pool() as pool:\n",
    "            results = pool.starmap(compute_network_func, nslist)\n",
    "\n",
    "            if showtiming:\n",
    "                print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "            if percentage_complete:\n",
    "                pbar.update(\n",
    "                    sum(\n",
    "                        len(network[1][\"all_segments\"]) for network in ordered_networks[nsq]\n",
    "                    )\n",
    "                )\n",
    "                # print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "\n",
    "        max_courant = 0\n",
    "        maxa = []\n",
    "        for result in results:\n",
    "            for seg in result:\n",
    "                maxa.extend(result[seg][:, 8:9])\n",
    "        max_courant = max(maxa)\n",
    "        print(f\"max_courant: {max_courant}\")\n",
    "\n",
    "        if (\n",
    "            nsq > 0\n",
    "        ):  # We skip this step for zero-order networks, i.e., those that have no downstream dependents\n",
    "            flowveldepth_connect = (\n",
    "                {}\n",
    "            )  # There is no need to preserve previously passed on values -- so we clear the dictionary\n",
    "            for i, (terminal_segment, network) in enumerate(ordered_networks[nsq]):\n",
    "                # seg = network[\"reaches\"][network[\"terminal_reach\"]][\"reach_tail\"]\n",
    "                seg = terminal_segment\n",
    "                flowveldepth_connect[seg] = {}\n",
    "                flowveldepth_connect[seg] = results[i][seg]\n",
    "                # TODO: The value passed here could be much more specific to\n",
    "                # TODO: exactly and only the most recent time step for the passing reach\n",
    "\n",
    "    if parallel_compute:\n",
    "        pool.close()\n",
    "\n",
    "    if percentage_complete:\n",
    "        pbar.close()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordered reach computation complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - main_start_time))\n",
    "    if verbose:\n",
    "        print(\"program complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - program_start_time))\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_results_new = {}\n",
    "    seg_courant_maxes = []\n",
    "    time = []\n",
    "    flowval = []  # flowval\n",
    "    velval_list = []  # velval\n",
    "    depthval = []  # depthval\n",
    "    qlatval = []  # qlatval\n",
    "    storageval = []  # storageval\n",
    "    qlatCumval = []  # qlatCumval\n",
    "    kinCelerity = []  # ck\n",
    "    courant = []  # cn\n",
    "    X = []  # X\n",
    "\n",
    "    for result in results:\n",
    "        all_results_new.update(result)\n",
    "\n",
    "    # print(all_results[8780801][1][0])\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # print(all_results)\n",
    "\n",
    "    for key, data in all_results_new.items():\n",
    "        time.extend(data[:, 0])  # time\n",
    "        flowval.extend(data[:, 1])  # flowval\n",
    "        velval_list.extend(data[:, 2])  # velval\n",
    "        depthval.extend(data[:, 3])  # depthval\n",
    "        qlatval.extend(data[:, 4])  # qlatval\n",
    "        storageval.extend(data[:, 5])  # storageval\n",
    "        qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "        kinCelerity.extend(data[:, 7])  # ck\n",
    "        courant.extend(data[:, 8])  # cn\n",
    "        X.extend(data[:, 9])  # X\n",
    "#     print(all_results_new)\n",
    "    single_seg_length = len(all_results_new[933020089][:, 0])\n",
    "\n",
    "    if c_i == \"florence_933020089_dt300.yaml\":\n",
    "        single_seg_length_300 = single_seg_length\n",
    "    else:\n",
    "        single_seg_length_60 = single_seg_length\n",
    "#     else:\n",
    "#         single_seg_length_10 = single_seg_length\n",
    "    print(single_seg_length_300,single_seg_length_60)\n",
    "    # single_seg_length * 611\n",
    "\n",
    "    key_index = all_results.keys()\n",
    "    key_index = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            itertools.repeat(x, single_seg_length) for x in key_index\n",
    "        )\n",
    "    )\n",
    "    data = {\n",
    "        \"key_index\": list(key_index),\n",
    "        \"time\": list(time),\n",
    "        \"flowval\": list(flowval),\n",
    "        \"velval_list\": list(velval_list),\n",
    "        \"depthval\": list(depthval),\n",
    "        \"qlatval\": list(qlatval),\n",
    "        \"storageval\": list(storageval),\n",
    "        \"qlatCumval\": list(qlatCumval),\n",
    "        \"kinCelerity\": list(kinCelerity),\n",
    "        \"courant\": list(courant),\n",
    "        \"X\": list(X),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index(\"key_index\")\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(\"key_index\")\n",
    "\n",
    "\n",
    "    seg_list = []\n",
    "    seg_courant_maxes = []\n",
    "    for seg in all_results_new:\n",
    "        seg_list.append(seg)\n",
    "        seg_courant_maxes.append(max(all_results_new[seg][:, tr.courant_index]))\n",
    "    zipped = zip(seg_list, seg_courant_maxes)\n",
    "    zipped = list(zipped)\n",
    "    res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "    # A.sort(reverse=True)\n",
    "    res = (res)[:3]\n",
    "    # print((res)[:25])\n",
    "\n",
    "    major_segments = []\n",
    "    for x, y in res[:3]:\n",
    "        major_segments.append(x)\n",
    "    # major_segments\n",
    "\n",
    "    df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "\n",
    "    if c_i == \"florence_933020089_dt300.yaml\":\n",
    "        df_indexed_300 = df_filtered.reset_index()\n",
    "    else:\n",
    "        df_indexed_60 = df_filtered.reset_index()\n",
    "    print(df_indexed_300,df_indexed_60)\n",
    "#     else:\n",
    "#         df_indexed_10 = df_filtered.reset_index()\n",
    "\n",
    "test_chart = go.FigureWidget()\n",
    "for x in range(0,3):\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "    )\n",
    "    #     temp_df_range_1 = single_seg_length_10 * (x)\n",
    "    #     temp_df_range_2 = single_seg_length_10 * (x + 1)\n",
    "    # #         print(temp_df_range_1, temp_df_range_2)\n",
    "    #     test_chart.add_scatter(\n",
    "    #         x=df_indexed_10[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "    #         y=df_indexed_10[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "    #         name=\"segment \" + str(df_indexed_10[\"key_index\"][temp_df_range_1]) + \" \" + str(dt),\n",
    "    #     )\n",
    "\n",
    "test_chart.layout.title = \"Timestep Chart 300, 60\"\n",
    "plot(test_chart)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 10080)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_seg_length_300,single_seg_length_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_index</th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8777735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.206769</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>0.341748</td>\n",
       "      <td>9.320413</td>\n",
       "      <td>0.497108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8777735</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.206968</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.020784</td>\n",
       "      <td>0.342073</td>\n",
       "      <td>9.329271</td>\n",
       "      <td>0.497105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8777735</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.207135</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.031175</td>\n",
       "      <td>0.342345</td>\n",
       "      <td>9.336675</td>\n",
       "      <td>0.497101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8777735</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.207273</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.041567</td>\n",
       "      <td>0.342571</td>\n",
       "      <td>9.342841</td>\n",
       "      <td>0.497099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8777735</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.207388</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.051959</td>\n",
       "      <td>0.342759</td>\n",
       "      <td>9.347967</td>\n",
       "      <td>0.497096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>933020027</td>\n",
       "      <td>603300.0</td>\n",
       "      <td>0.058953</td>\n",
       "      <td>0.755009</td>\n",
       "      <td>0.049310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.658967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.211574</td>\n",
       "      <td>36.347221</td>\n",
       "      <td>0.493714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>933020027</td>\n",
       "      <td>603600.0</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>0.754795</td>\n",
       "      <td>0.049287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.658884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.211248</td>\n",
       "      <td>36.337448</td>\n",
       "      <td>0.493717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>933020027</td>\n",
       "      <td>603900.0</td>\n",
       "      <td>0.058867</td>\n",
       "      <td>0.754590</td>\n",
       "      <td>0.049266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.658805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210937</td>\n",
       "      <td>36.328110</td>\n",
       "      <td>0.493719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>933020027</td>\n",
       "      <td>604200.0</td>\n",
       "      <td>0.058826</td>\n",
       "      <td>0.754394</td>\n",
       "      <td>0.049246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.658730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210639</td>\n",
       "      <td>36.319172</td>\n",
       "      <td>0.493722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>933020027</td>\n",
       "      <td>604500.0</td>\n",
       "      <td>0.058788</td>\n",
       "      <td>0.754206</td>\n",
       "      <td>0.049226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.658657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210353</td>\n",
       "      <td>36.310593</td>\n",
       "      <td>0.493724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6048 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
       "0       8777735       0.0  0.004696     0.206769  0.011542  0.000035   \n",
       "1       8777735     300.0  0.004707     0.206968  0.011559  0.000035   \n",
       "2       8777735     600.0  0.004716     0.207135  0.011573  0.000035   \n",
       "3       8777735     900.0  0.004724     0.207273  0.011584  0.000035   \n",
       "4       8777735    1200.0  0.004730     0.207388  0.011594  0.000035   \n",
       "...         ...       ...       ...          ...       ...       ...   \n",
       "6043  933020027  603300.0  0.058953     0.755009  0.049310  0.000000   \n",
       "6044  933020027  603600.0  0.058909     0.754795  0.049287  0.000000   \n",
       "6045  933020027  603900.0  0.058867     0.754590  0.049266  0.000000   \n",
       "6046  933020027  604200.0  0.058826     0.754394  0.049246  0.000000   \n",
       "6047  933020027  604500.0  0.058788     0.754206  0.049226  0.000000   \n",
       "\n",
       "      storageval  qlatCumval  kinCelerity    courant         X  \n",
       "0       0.000012    0.010392     0.341748   9.320413  0.497108  \n",
       "1       0.000021    0.020784     0.342073   9.329271  0.497105  \n",
       "2       0.000030    0.031175     0.342345   9.336675  0.497101  \n",
       "3       0.000036    0.041567     0.342571   9.342841  0.497099  \n",
       "4       0.000042    0.051959     0.342759   9.347967  0.497096  \n",
       "...          ...         ...          ...        ...       ...  \n",
       "6043   90.658967    0.000000     1.211574  36.347221  0.493714  \n",
       "6044   90.658884    0.000000     1.211248  36.337448  0.493717  \n",
       "6045   90.658805    0.000000     1.210937  36.328110  0.493719  \n",
       "6046   90.658730    0.000000     1.210639  36.319172  0.493722  \n",
       "6047   90.658657    0.000000     1.210353  36.310593  0.493724  \n",
       "\n",
       "[6048 rows x 11 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indexed_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_index</th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8777735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.206769</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.341748</td>\n",
       "      <td>1.864082</td>\n",
       "      <td>0.497108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8777735</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.206816</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.341824</td>\n",
       "      <td>1.864496</td>\n",
       "      <td>0.497108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8777735</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.206857</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.341891</td>\n",
       "      <td>1.864862</td>\n",
       "      <td>0.497107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8777735</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.341956</td>\n",
       "      <td>1.865216</td>\n",
       "      <td>0.497106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8777735</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.206935</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>0.342019</td>\n",
       "      <td>1.865557</td>\n",
       "      <td>0.497106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30235</th>\n",
       "      <td>933020027</td>\n",
       "      <td>604500.0</td>\n",
       "      <td>0.058770</td>\n",
       "      <td>0.754123</td>\n",
       "      <td>0.049218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.286447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210227</td>\n",
       "      <td>7.261362</td>\n",
       "      <td>0.493725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30236</th>\n",
       "      <td>933020027</td>\n",
       "      <td>604560.0</td>\n",
       "      <td>0.058763</td>\n",
       "      <td>0.754086</td>\n",
       "      <td>0.049214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.286444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210172</td>\n",
       "      <td>7.261031</td>\n",
       "      <td>0.493726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30237</th>\n",
       "      <td>933020027</td>\n",
       "      <td>604620.0</td>\n",
       "      <td>0.058755</td>\n",
       "      <td>0.754050</td>\n",
       "      <td>0.049210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.286441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210117</td>\n",
       "      <td>7.260703</td>\n",
       "      <td>0.493726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30238</th>\n",
       "      <td>933020027</td>\n",
       "      <td>604680.0</td>\n",
       "      <td>0.058748</td>\n",
       "      <td>0.754015</td>\n",
       "      <td>0.049206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.286438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210063</td>\n",
       "      <td>7.260379</td>\n",
       "      <td>0.493727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30239</th>\n",
       "      <td>933020027</td>\n",
       "      <td>604740.0</td>\n",
       "      <td>0.058741</td>\n",
       "      <td>0.753979</td>\n",
       "      <td>0.049203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.286436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210009</td>\n",
       "      <td>7.260056</td>\n",
       "      <td>0.493727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30240 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
       "0        8777735       0.0  0.004696     0.206769  0.011542  0.000035   \n",
       "1        8777735      60.0  0.004698     0.206816  0.011546  0.000035   \n",
       "2        8777735     120.0  0.004700     0.206857  0.011549  0.000035   \n",
       "3        8777735     180.0  0.004703     0.206897  0.011552  0.000035   \n",
       "4        8777735     240.0  0.004705     0.206935  0.011556  0.000035   \n",
       "...          ...       ...       ...          ...       ...       ...   \n",
       "30235  933020027  604500.0  0.058770     0.754123  0.049218  0.000000   \n",
       "30236  933020027  604560.0  0.058763     0.754086  0.049214  0.000000   \n",
       "30237  933020027  604620.0  0.058755     0.754050  0.049210  0.000000   \n",
       "30238  933020027  604680.0  0.058748     0.754015  0.049206  0.000000   \n",
       "30239  933020027  604740.0  0.058741     0.753979  0.049203  0.000000   \n",
       "\n",
       "       storageval  qlatCumval  kinCelerity   courant         X  \n",
       "0        0.000002    0.002078     0.341748  1.864082  0.497108  \n",
       "1        0.000003    0.004157     0.341824  1.864496  0.497108  \n",
       "2        0.000003    0.006235     0.341891  1.864862  0.497107  \n",
       "3        0.000004    0.008313     0.341956  1.865216  0.497106  \n",
       "4        0.000004    0.010392     0.342019  1.865557  0.497106  \n",
       "...           ...         ...          ...       ...       ...  \n",
       "30235    4.286447    0.000000     1.210227  7.261362  0.493725  \n",
       "30236    4.286444    0.000000     1.210172  7.261031  0.493726  \n",
       "30237    4.286441    0.000000     1.210117  7.260703  0.493726  \n",
       "30238    4.286438    0.000000     1.210063  7.260379  0.493727  \n",
       "30239    4.286436    0.000000     1.210009  7.260056  0.493727  \n",
       "\n",
       "[30240 rows x 11 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indexed_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_input_file_list = [\"florence_933020089_dt300.yaml\",\"florence_933020089_dt60.yaml\"]\n",
    "# # custom_input_file_list = [\"florence_933020089_dt300.yaml\"]\n",
    "# df_indexed_300 = pd.DataFrame()\n",
    "# df_indexed_60 = pd.DataFrame()\n",
    "# # df_indexed_10 = pd.DataFrame()\n",
    "# single_seg_length_300 = 0\n",
    "# single_seg_length_60 = 0\n",
    "# # single_seg_length_10 = 0\n",
    "# for i,c_i in enumerate(custom_input_file_list):\n",
    "#     print(c_i)\n",
    "#     custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "#     custom_input_file = c_i\n",
    "#     all_results_new = tr.route_supernetwork(\n",
    "#         tr.connections_g,\n",
    "#         tr.networks_g,\n",
    "#         tr.qlateral_g,\n",
    "#         tr.waterbodies_df_g,\n",
    "#         tr.waterbody_initial_states_df_g,\n",
    "#         tr.channel_initial_states_df_g,\n",
    "#         custom_input_file=custom_input_folder.joinpath(custom_input_file),\n",
    "#     )\n",
    "    \n",
    "\n",
    "    \n",
    "#     print(len(all_results_new))\n",
    "#     all_results_new = {}\n",
    "#     seg_courant_maxes = []\n",
    "#     time = []\n",
    "#     flowval = []  # flowval\n",
    "#     velval_list = []  # velval\n",
    "#     depthval = []  # depthval\n",
    "#     qlatval = []  # qlatval\n",
    "#     storageval = []  # storageval\n",
    "#     qlatCumval = []  # qlatCumval\n",
    "#     kinCelerity = []  # ck\n",
    "#     courant = []  # cn\n",
    "#     X = []  # X\n",
    "\n",
    "#     for result in results:\n",
    "#         all_results_new.update(result)\n",
    "\n",
    "#     # print(all_results[8780801][1][0])\n",
    "\n",
    "#     df = pd.DataFrame()\n",
    "#     # print(all_results)\n",
    "\n",
    "#     for key, data in all_results_new.items():\n",
    "#         time.extend(data[:, 0])  # time\n",
    "#         flowval.extend(data[:, 1])  # flowval\n",
    "#         velval_list.extend(data[:, 2])  # velval\n",
    "#         depthval.extend(data[:, 3])  # depthval\n",
    "#         qlatval.extend(data[:, 4])  # qlatval\n",
    "#         storageval.extend(data[:, 5])  # storageval\n",
    "#         qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "#         kinCelerity.extend(data[:, 7])  # ck\n",
    "#         courant.extend(data[:, 8])  # cn\n",
    "#         X.extend(data[:, 9])  # X\n",
    "# #     print(all_results_new)\n",
    "#     single_seg_length = len(all_results_new[933020089][:, 0])\n",
    "#     print(single_seg_length)\n",
    "#     if i == 0:\n",
    "#         single_seg_length_300 = single_seg_length\n",
    "#     elif i == 1:\n",
    "#         single_seg_length_60 = single_seg_length\n",
    "# #     else:\n",
    "# #         single_seg_length_10 = single_seg_length\n",
    "\n",
    "#     # single_seg_length * 611\n",
    "\n",
    "#     key_index = all_results.keys()\n",
    "#     key_index = list(\n",
    "#         itertools.chain.from_iterable(\n",
    "#             itertools.repeat(x, single_seg_length) for x in key_index\n",
    "#         )\n",
    "#     )\n",
    "#     data = {\n",
    "#         \"key_index\": list(key_index),\n",
    "#         \"time\": list(time),\n",
    "#         \"flowval\": list(flowval),\n",
    "#         \"velval_list\": list(velval_list),\n",
    "#         \"depthval\": list(depthval),\n",
    "#         \"qlatval\": list(qlatval),\n",
    "#         \"storageval\": list(storageval),\n",
    "#         \"qlatCumval\": list(qlatCumval),\n",
    "#         \"kinCelerity\": list(kinCelerity),\n",
    "#         \"courant\": list(courant),\n",
    "#         \"X\": list(X),\n",
    "#     }\n",
    "#     df = pd.DataFrame(data)\n",
    "#     df = df.set_index(\"key_index\")\n",
    "#     df = df.reset_index()\n",
    "#     df = df.set_index(\"key_index\")\n",
    "\n",
    "\n",
    "#     seg_list = []\n",
    "#     seg_courant_maxes = []\n",
    "#     for seg in all_results_new:\n",
    "#         seg_list.append(seg)\n",
    "#         seg_courant_maxes.append(max(all_results_new[seg][:, tr.courant_index]))\n",
    "#     zipped = zip(seg_list, seg_courant_maxes)\n",
    "#     zipped = list(zipped)\n",
    "#     res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "#     # A.sort(reverse=True)\n",
    "#     res = (res)[:3]\n",
    "#     # print((res)[:25])\n",
    "\n",
    "#     major_segments = []\n",
    "#     for x, y in res[:3]:\n",
    "#         major_segments.append(x)\n",
    "#     # major_segments\n",
    "\n",
    "#     df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "\n",
    "#     if i == 0:\n",
    "#         df_indexed_300 = df_filtered.reset_index()\n",
    "#     elif i == 1:\n",
    "#         df_indexed_60 = df_filtered.reset_index()\n",
    "# #     else:\n",
    "# #         df_indexed_10 = df_filtered.reset_index()\n",
    "\n",
    "# test_chart = go.FigureWidget()\n",
    "# for x in range(0,3):\n",
    "#     temp_df_range_1 = single_seg_length_300 * (x)\n",
    "#     temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "#     #         print(temp_df_range_1, temp_df_range_2)\n",
    "#     test_chart.add_scatter(\n",
    "#         x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "#         y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "#         name=\"segment \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "#     )\n",
    "#     temp_df_range_1 = single_seg_length_60 * (x)\n",
    "#     temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "#     #         print(temp_df_range_1, temp_df_range_2)\n",
    "#     test_chart.add_scatter(\n",
    "#         x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "#         y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "#         name=\"segment \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "#     )\n",
    "#     #     temp_df_range_1 = single_seg_length_10 * (x)\n",
    "#     #     temp_df_range_2 = single_seg_length_10 * (x + 1)\n",
    "#     # #         print(temp_df_range_1, temp_df_range_2)\n",
    "#     #     test_chart.add_scatter(\n",
    "#     #         x=df_indexed_10[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "#     #         y=df_indexed_10[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "#     #         name=\"segment \" + str(df_indexed_10[\"key_index\"][temp_df_range_1]) + \" \" + str(dt),\n",
    "#     #     )\n",
    "\n",
    "# test_chart.layout.title = \"Timestep Chart 300, 60\"\n",
    "# plot(test_chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
