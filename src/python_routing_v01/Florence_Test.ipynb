{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic imports and path management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "root = pathlib.Path(\"../../\").resolve()\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v02\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v01\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_routing_v01\")))\n",
    "sys.path.append(\".\")\n",
    "import nhd_io as nio\n",
    "import compute_nhd_routing_SingleSeg as tr\n",
    "import nhd_network_utilities_v01 as nnu\n",
    "import nhd_reach_utilities as nru\n",
    "\n",
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt60.yaml\"\n",
    "run_pocono2_test = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the primary data input from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(custom_file)\n"
     ]
    }
   ],
   "source": [
    "supernetwork_parameters = None\n",
    "waterbody_parameters = None\n",
    "if custom_input_file:\n",
    "    (\n",
    "        supernetwork_parameters,\n",
    "        waterbody_parameters,\n",
    "        forcing_parameters,\n",
    "        restart_parameters,\n",
    "        output_parameters,\n",
    "        run_parameters,\n",
    "    ) = nio.read_custom_input(custom_input_folder.joinpath(custom_input_file))\n",
    "\n",
    "    break_network_at_waterbodies = run_parameters.get(\n",
    "        \"break_network_at_waterbodies\", None\n",
    "    )\n",
    "\n",
    "    dt = run_parameters.get(\"dt\", None)\n",
    "    nts = run_parameters.get(\"nts\", None)\n",
    "    qts_subdivisions = run_parameters.get(\"qts_subdivisions\", None)\n",
    "    debuglevel = -1 * int(run_parameters.get(\"debuglevel\", 0))\n",
    "    verbose = run_parameters.get(\"verbose\", None)\n",
    "    showtiming = run_parameters.get(\"showtiming\", None)\n",
    "    percentage_complete = run_parameters.get(\"percentage_complete\", None)\n",
    "    do_network_analysis_only = run_parameters.get(\"do_network_analysis_only\", None)\n",
    "    assume_short_ts = run_parameters.get(\"assume_short_ts\", None)\n",
    "    parallel_compute = run_parameters.get(\"parallel_compute\", None)\n",
    "    cpu_pool = run_parameters.get(\"cpu_pool\", None)\n",
    "    sort_networks = run_parameters.get(\"sort_networks\", None)\n",
    "\n",
    "    csv_output = output_parameters.get(\"csv_output\", None)\n",
    "    nc_output_folder = output_parameters.get(\"nc_output_folder\", None)\n",
    "\n",
    "    qlat_const = forcing_parameters.get(\"qlat_const\", None)\n",
    "    qlat_input_file = forcing_parameters.get(\"qlat_input_file\", None)\n",
    "    qlat_input_folder = forcing_parameters.get(\"qlat_input_folder\", None)\n",
    "    qlat_file_pattern_filter = forcing_parameters.get(\"qlat_file_pattern_filter\", None)\n",
    "    qlat_file_index_col = forcing_parameters.get(\"qlat_file_index_col\", None)\n",
    "    qlat_file_value_col = forcing_parameters.get(\"qlat_file_value_col\", None)\n",
    "\n",
    "    wrf_hydro_channel_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_upstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_upstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_downstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_downstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_depth_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_depth_flow_field_name\", None\n",
    "    )\n",
    "\n",
    "    wrf_hydro_waterbody_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file_field_name\", None\n",
    "    )\n",
    "\n",
    "# Any specific commandline arguments will override the file\n",
    "# TODO: There are probably some pathological collisions that could\n",
    "# arise from this ordering ... check these out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_pocono2_test:\n",
    "    if verbose:\n",
    "        print(\"running test case for Pocono_TEST2 domain\")\n",
    "    # Overwrite the following test defaults\n",
    "    supernetwork = \"Pocono_TEST2\"\n",
    "    break_network_at_waterbodies = False\n",
    "    qts_subdivisions = 1  # change qts_subdivisions = 1 as  default\n",
    "    dt = 300 / qts_subdivisions\n",
    "    nts = 144 * qts_subdivisions\n",
    "    csv_output = {\"csv_output_folder\": os.path.join(root, \"test\", \"output\", \"text\")}\n",
    "    nc_output_folder = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "    # test 1. Take lateral flow from re-formatted wrf-hydro output from Pocono Basin simulation\n",
    "    qlat_input_file = os.path.join(\n",
    "        root, r\"test/input/geo/PoconoSampleData2/Pocono_ql_testsamp1_nwm_mc.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.039980411529541016 seconds.\n"
     ]
    }
   ],
   "source": [
    "if showtiming:\n",
    "    program_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"begin program t-route ...\")\n",
    "\n",
    "# STEP 1: Read the supernetwork dataset and build the connections graph\n",
    "if verbose:\n",
    "    print(\"creating supernetwork connections set\")\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "\n",
    "if supernetwork_parameters:\n",
    "    supernetwork_values = nnu.get_nhd_connections(\n",
    "        supernetwork_parameters=supernetwork_parameters,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    test_folder = os.path.join(root, r\"test\")\n",
    "    geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "    supernetwork_parameters, supernetwork_values = nnu.set_networks(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "    waterbody_parameters = nnu.set_waterbody_parameters(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "if verbose:\n",
    "    print(\"supernetwork connections set complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "connections = supernetwork_values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.004998445510864258 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Separate the networks and build the sub-graph of reaches within each network\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"organizing connections into reaches ...\")\n",
    "networks = nru.compose_networks(\n",
    "    supernetwork_values,\n",
    "    break_network_at_waterbodies=break_network_at_waterbodies,\n",
    "    verbose=False,\n",
    "    debuglevel=debuglevel,\n",
    "    showtiming=showtiming,\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(\"reach organization complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.018932104110717773 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 3.838539123535156e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.019091367721557617 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Organize Network for Waterbodies\n",
    "if break_network_at_waterbodies:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"reading waterbody parameter file ...\")\n",
    "\n",
    "    ## STEP 3a: Read waterbody parameter file\n",
    "    waterbodies_values = supernetwork_values[12]\n",
    "    waterbodies_segments = supernetwork_values[13]\n",
    "    connections_tailwaters = supernetwork_values[4]\n",
    "\n",
    "    waterbodies_df = nio.read_waterbody_df(waterbody_parameters, waterbodies_values,)\n",
    "    waterbodies_df = waterbodies_df.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "\n",
    "    nru.order_networks(connections, networks, connections_tailwaters)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbodies complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "    ## STEP 3b: Order subnetworks above and below reservoirs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks ...\")\n",
    "\n",
    "    max_network_seqorder = -1\n",
    "    for network in networks:\n",
    "        max_network_seqorder = max(\n",
    "            networks[network][\"network_seqorder\"], max_network_seqorder\n",
    "        )\n",
    "    ordered_networks = {}\n",
    "\n",
    "    for terminal_segment, network in networks.items():\n",
    "        if network[\"network_seqorder\"] not in ordered_networks:\n",
    "            ordered_networks[network[\"network_seqorder\"]] = []\n",
    "        ordered_networks[network[\"network_seqorder\"]].append(\n",
    "            (terminal_segment, network)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "else:\n",
    "    # If we are not splitting the networks, we can put them all in one order\n",
    "    max_network_seqorder = 0\n",
    "    ordered_networks = {}\n",
    "    ordered_networks[0] = [\n",
    "        (terminal_segment, network) for terminal_segment, network in networks.items()\n",
    "    ]\n",
    "\n",
    "if do_network_analysis_only:\n",
    "    sys.exit()\n",
    "\n",
    "if break_network_at_waterbodies:\n",
    "    ## STEP 3c: Handle Waterbody Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting waterbody initial states ...\")\n",
    "\n",
    "    if wrf_hydro_waterbody_restart_file:\n",
    "\n",
    "        waterbody_initial_states_df = nio.get_reservoir_restart_from_wrf_hydro(\n",
    "            wrf_hydro_waterbody_restart_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file_field_name,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file_field_name,\n",
    "        )\n",
    "    else:\n",
    "        # TODO: Consider adding option to read cold state from route-link file\n",
    "        waterbody_initial_ds_flow_const = 0.0\n",
    "        waterbody_initial_depth_const = 0.0\n",
    "        # Set initial states from cold-state\n",
    "        waterbody_initial_states_df = pd.DataFrame(\n",
    "            0, index=waterbodies_df.index, columns=[\"qd0\", \"h0\",], dtype=\"float32\"\n",
    "        )\n",
    "        # TODO: This assignment could probably by done in the above call\n",
    "        waterbody_initial_states_df[\"qd0\"] = waterbody_initial_ds_flow_const\n",
    "        waterbody_initial_states_df[\"h0\"] = waterbody_initial_depth_const\n",
    "        waterbody_initial_states_df[\"index\"] = range(len(waterbody_initial_states_df))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbody initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.020688295364379883 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Handle Channel Initial States\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"setting channel initial states ...\")\n",
    "\n",
    "if wrf_hydro_channel_restart_file:\n",
    "\n",
    "    channel_initial_states_df = nio.get_stream_restart_from_wrf_hydro(\n",
    "        wrf_hydro_channel_restart_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file_field_name,\n",
    "        wrf_hydro_channel_restart_upstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_downstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_depth_flow_field_name,\n",
    "    )\n",
    "else:\n",
    "    # TODO: Consider adding option to read cold state from route-link file\n",
    "    channel_initial_us_flow_const = 0.0\n",
    "    channel_initial_ds_flow_const = 0.0\n",
    "    channel_initial_depth_const = 0.0\n",
    "    # Set initial states from cold-state\n",
    "    channel_initial_states_df = pd.DataFrame(\n",
    "        0, index=connections.keys(), columns=[\"qu0\", \"qd0\", \"h0\",], dtype=\"float32\"\n",
    "    )\n",
    "    channel_initial_states_df[\"qu0\"] = channel_initial_us_flow_const\n",
    "    channel_initial_states_df[\"qd0\"] = channel_initial_ds_flow_const\n",
    "    channel_initial_states_df[\"h0\"] = channel_initial_depth_const\n",
    "    channel_initial_states_df[\"index\"] = range(len(channel_initial_states_df))\n",
    "\n",
    "if verbose:\n",
    "    print(\"channel initial states complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 5.834100008010864 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Read (or set) QLateral Inputs\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"creating qlateral array ...\")\n",
    "\n",
    "# initialize qlateral dict\n",
    "qlateral = {}\n",
    "\n",
    "if qlat_input_folder:\n",
    "    qlat_files = []\n",
    "    for pattern in qlat_file_pattern_filter:\n",
    "        qlat_files.extend(glob.glob(qlat_input_folder + pattern))\n",
    "    qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "        qlat_files=qlat_files,\n",
    "        index_col=qlat_file_index_col,\n",
    "        value_col=qlat_file_value_col,\n",
    "    )\n",
    "\n",
    "elif qlat_input_file:\n",
    "    qlat_df = nio.get_ql_from_csv(qlat_input_file)\n",
    "\n",
    "else:\n",
    "    qlat_df = pd.DataFrame(\n",
    "        qlat_const, index=connections.keys(), columns=range(nts), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "for index, row in qlat_df.iterrows():\n",
    "    qlateral[index] = row.tolist()\n",
    "\n",
    "if verbose:\n",
    "    print(\"qlateral array complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Sort the ordered networks\n",
    "if sort_networks:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"sorting the ordered networks ...\")\n",
    "\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        sort_ordered_network(ordered_networks[nsq], True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"sorting complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the pool after we create the static global objects (and collect the garbage)\n",
    "if parallel_compute:\n",
    "    import gc\n",
    "\n",
    "    gc.collect()\n",
    "    pool = multiprocessing.Pool(cpu_pool)\n",
    "\n",
    "flowveldepth_connect = (\n",
    "    {}\n",
    ")  # dict to contain values to transfer from upstream to downstream networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1108 [05:26<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|████▏     | 467/1108 [00:28<00:39, 16.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 28.96821355819702 seconds.\n",
      "max_courant: [5.51265717]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 499/1108 [00:41<01:36,  6.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 41.32278394699097 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1108/1108 [01:31<00:00,  7.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 91.25727224349976 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [01:33<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [25.36383247]\n",
      "ordered reach computation complete\n",
      "... in 93.82181358337402 seconds.\n",
      "program complete\n",
      "... in 99.94432353973389 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################### Main Execution Loop across ordered networks\n",
    "if showtiming:\n",
    "    main_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"executing routing computation ...\")\n",
    "\n",
    "compute_network_func = tr.compute_network\n",
    "\n",
    "tr.connections_g = connections\n",
    "tr.networks_g = networks\n",
    "tr.qlateral_g = qlateral\n",
    "tr.waterbodies_df_g = waterbodies_df\n",
    "tr.waterbody_initial_states_df_g = waterbody_initial_states_df\n",
    "tr.channel_initial_states_df_g = channel_initial_states_df\n",
    "\n",
    "progress_count = 0\n",
    "percentage_complete = True\n",
    "if percentage_complete:\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        for terminal_segment, network in ordered_networks[nsq]:\n",
    "            progress_count += len(network[\"all_segments\"])\n",
    "    pbar = tqdm(total=(progress_count))\n",
    "\n",
    "for nsq in range(max_network_seqorder, -1, -1):\n",
    "\n",
    "    if parallel_compute:\n",
    "        nslist = []\n",
    "    results = []\n",
    "\n",
    "    current_index_total = 0\n",
    "\n",
    "    for terminal_segment, network in ordered_networks[nsq]:\n",
    "\n",
    "        if percentage_complete:\n",
    "            if current_index_total == 0:\n",
    "                pbar.update(0)\n",
    "\n",
    "        if break_network_at_waterbodies:\n",
    "            waterbody = waterbodies_segments.get(terminal_segment)\n",
    "        else:\n",
    "            waterbody = None\n",
    "        if not parallel_compute:  # serial execution\n",
    "            if showtiming:\n",
    "                start_time = time.time()\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"routing ordered reaches for terminal segment {terminal_segment} ...\"\n",
    "                )\n",
    "\n",
    "            results.append(\n",
    "                compute_network_func(\n",
    "                    flowveldepth_connect=flowveldepth_connect,\n",
    "                    terminal_segment=terminal_segment,\n",
    "                    supernetwork_parameters=supernetwork_parameters,\n",
    "                    waterbody_parameters=waterbody_parameters,\n",
    "                    waterbody=waterbody,\n",
    "                    nts=nts,\n",
    "                    dt=dt,\n",
    "                    qts_subdivisions=qts_subdivisions,\n",
    "                    verbose=verbose,\n",
    "                    debuglevel=debuglevel,\n",
    "                    csv_output=csv_output,\n",
    "                    nc_output_folder=nc_output_folder,\n",
    "                    assume_short_ts=assume_short_ts,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if showtiming:\n",
    "                print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "            if percentage_complete:\n",
    "                pbar.update(len(network[\"all_segments\"]))\n",
    "\n",
    "        else:  # parallel execution\n",
    "            nslist.append(\n",
    "                [\n",
    "                    flowveldepth_connect,\n",
    "                    terminal_segment,\n",
    "                    supernetwork_parameters,  # TODO: This should probably be global...\n",
    "                    waterbody_parameters,\n",
    "                    waterbody,\n",
    "                    nts,\n",
    "                    dt,\n",
    "                    qts_subdivisions,\n",
    "                    verbose,\n",
    "                    debuglevel,\n",
    "                    csv_output,\n",
    "                    nc_output_folder,\n",
    "                    assume_short_ts,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    if parallel_compute:\n",
    "        if verbose:\n",
    "            print(f\"routing ordered reaches for networks of order {nsq} ... \")\n",
    "        if debuglevel <= -2:\n",
    "            print(f\"reaches to be routed include:\")\n",
    "            print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "        # with pool:\n",
    "        # with multiprocessing.Pool() as pool:\n",
    "        results = pool.starmap(compute_network_func, nslist)\n",
    "\n",
    "        if showtiming:\n",
    "            print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "        if percentage_complete:\n",
    "            pbar.update(\n",
    "                sum(\n",
    "                    len(network[1][\"all_segments\"]) for network in ordered_networks[nsq]\n",
    "                )\n",
    "            )\n",
    "            # print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "\n",
    "    max_courant = 0\n",
    "    maxa = []\n",
    "    for result in results:\n",
    "        for seg in result:\n",
    "            maxa.extend(result[seg][:, 8:9])\n",
    "    max_courant = max(maxa)\n",
    "    print(f\"max_courant: {max_courant}\")\n",
    "\n",
    "    if (\n",
    "        nsq > 0\n",
    "    ):  # We skip this step for zero-order networks, i.e., those that have no downstream dependents\n",
    "        flowveldepth_connect = (\n",
    "            {}\n",
    "        )  # There is no need to preserve previously passed on values -- so we clear the dictionary\n",
    "        for i, (terminal_segment, network) in enumerate(ordered_networks[nsq]):\n",
    "            # seg = network[\"reaches\"][network[\"terminal_reach\"]][\"reach_tail\"]\n",
    "            seg = terminal_segment\n",
    "            flowveldepth_connect[seg] = {}\n",
    "            flowveldepth_connect[seg] = results[i][seg]\n",
    "            # TODO: The value passed here could be much more specific to\n",
    "            # TODO: exactly and only the most recent time step for the passing reach\n",
    "\n",
    "if parallel_compute:\n",
    "    pool.close()\n",
    "\n",
    "if percentage_complete:\n",
    "    pbar.close()\n",
    "\n",
    "if verbose:\n",
    "    print(\"ordered reach computation complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - main_start_time))\n",
    "if verbose:\n",
    "    print(\"program complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - program_start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the main dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results)\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "all_results = {}\n",
    "seg_courant_maxes = []\n",
    "time = []\n",
    "flowval = []  # flowval\n",
    "velval_list = []  # velval\n",
    "depthval = []  # depthval\n",
    "qlatval = []  # qlatval\n",
    "storageval = []  # storageval\n",
    "qlatCumval = []  # qlatCumval\n",
    "kinCelerity = []  # ck\n",
    "courant = []  # cn\n",
    "X = []  # X\n",
    "\n",
    "for result in results:\n",
    "    all_results.update(result)\n",
    "\n",
    "# print(all_results[8780801][1][0])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# print(all_results)\n",
    "\n",
    "for key, data in all_results.items():\n",
    "    time.extend(data[:, 0])  # time\n",
    "    flowval.extend(data[:, 1])  # flowval\n",
    "    velval_list.extend(data[:, 2])  # velval\n",
    "    depthval.extend(data[:, 3])  # depthval\n",
    "    qlatval.extend(data[:, 4])  # qlatval\n",
    "    storageval.extend(data[:, 5])  # storageval\n",
    "    qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "    kinCelerity.extend(data[:, 7])  # ck\n",
    "    courant.extend(data[:, 8])  # cn\n",
    "    X.extend(data[:, 9])  # X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6158880"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_seg_length = len(all_results[933020089][:, 0])\n",
    "single_seg_length * 611\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6158880"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>6.984919e-09</td>\n",
       "      <td>1.062422e-02</td>\n",
       "      <td>0.055861</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>0.499502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033788</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.309672e-08</td>\n",
       "      <td>2.124843e-02</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.017565</td>\n",
       "      <td>0.499503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033795</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.833541e-08</td>\n",
       "      <td>3.187265e-02</td>\n",
       "      <td>0.055926</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>0.499503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033797</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>2.357410e-08</td>\n",
       "      <td>4.249686e-02</td>\n",
       "      <td>0.055929</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.499503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033797</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>2.793968e-08</td>\n",
       "      <td>5.312108e-02</td>\n",
       "      <td>0.055930</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.499503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>604500.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.123872e+06</td>\n",
       "      <td>1.368457e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>604560.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.123924e+06</td>\n",
       "      <td>1.368466e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>604620.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.123977e+06</td>\n",
       "      <td>1.368475e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>604680.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.124030e+06</td>\n",
       "      <td>1.368483e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>604740.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.124083e+06</td>\n",
       "      <td>1.368492e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6158880 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time   flowval  velval_list  depthval   qlatval    storageval  \\\n",
       "key_index                                                                      \n",
       "8780801         0.0  0.000177     0.033756  0.004995  0.000177  6.984919e-09   \n",
       "8780801        60.0  0.000177     0.033788  0.005002  0.000177  1.309672e-08   \n",
       "8780801       120.0  0.000177     0.033795  0.005004  0.000177  1.833541e-08   \n",
       "8780801       180.0  0.000177     0.033797  0.005004  0.000177  2.357410e-08   \n",
       "8780801       240.0  0.000177     0.033797  0.005004  0.000177  2.793968e-08   \n",
       "...             ...       ...          ...       ...       ...           ...   \n",
       "8778465    604500.0  0.000036     0.000000  0.000000  0.149393  8.123872e+06   \n",
       "8778465    604560.0  0.000036     0.000000  0.000000  0.149393  8.123924e+06   \n",
       "8778465    604620.0  0.000036     0.000000  0.000000  0.149393  8.123977e+06   \n",
       "8778465    604680.0  0.000036     0.000000  0.000000  0.149393  8.124030e+06   \n",
       "8778465    604740.0  0.000036     0.000000  0.000000  0.149393  8.124083e+06   \n",
       "\n",
       "             qlatCumval  kinCelerity   courant         X  \n",
       "key_index                                                 \n",
       "8780801    1.062422e-02     0.055861  0.017548  0.499502  \n",
       "8780801    2.124843e-02     0.055914  0.017565  0.499503  \n",
       "8780801    3.187265e-02     0.055926  0.017568  0.499503  \n",
       "8780801    4.249686e-02     0.055929  0.017569  0.499503  \n",
       "8780801    5.312108e-02     0.055930  0.017569  0.499503  \n",
       "...                 ...          ...       ...       ...  \n",
       "8778465    1.368457e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368466e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368475e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368483e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368492e+06     0.000000  0.000000  0.000000  \n",
       "\n",
       "[6158880 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_index = all_results.keys()\n",
    "key_index = list(\n",
    "    itertools.chain.from_iterable(\n",
    "        itertools.repeat(x, single_seg_length) for x in key_index\n",
    "    )\n",
    ")\n",
    "data = {\n",
    "    \"key_index\": list(key_index),\n",
    "    \"time\": list(time),\n",
    "    \"flowval\": list(flowval),\n",
    "    \"velval_list\": list(velval_list),\n",
    "    \"depthval\": list(depthval),\n",
    "    \"qlatval\": list(qlatval),\n",
    "    \"storageval\": list(storageval),\n",
    "    \"qlatCumval\": list(qlatCumval),\n",
    "    \"kinCelerity\": list(kinCelerity),\n",
    "    \"courant\": list(courant),\n",
    "    \"X\": list(X),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index(\"key_index\")\n",
    "df = df.reset_index()\n",
    "df = df.set_index(\"key_index\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /home/jacob.hreha/jupyter/lib/python3.6/site-packages (4.9.0)\n",
      "Requirement already satisfied: six in /home/jacob.hreha/jupyter/lib/python3.6/site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/jacob.hreha/jupyter/lib/python3.6/site-packages (from plotly) (1.3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 25 courants based on our work this morning and their segment IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(933020027, 25.363832473754883), (8777735, 14.950478553771973), (933020017, 9.564001083374023), (8778581, 8.574037551879883), (933020059, 7.254691123962402), (933020061, 4.696855068206787), (8780597, 3.591726064682007), (933020020, 2.8707876205444336), (933020058, 2.4734983444213867), (933020023, 2.1059963703155518), (8777485, 1.860101580619812), (933020036, 1.6248382329940796), (8778795, 1.6150635480880737), (8778021, 1.4462398290634155), (8777339, 1.393180251121521), (8777867, 1.353600263595581), (8777477, 1.3393661975860596), (8780495, 1.263046383857727), (8777861, 1.1583272218704224), (8777481, 1.149632215499878), (8780607, 1.0738232135772705), (933020050, 1.0441739559173584), (8779003, 0.9976801872253418), (8780751, 0.9917784929275513), (8778947, 0.9753884673118591)]\n"
     ]
    }
   ],
   "source": [
    "seg_list = []\n",
    "seg_courant_maxes = []\n",
    "for seg in all_results:\n",
    "    seg_list.append(seg)\n",
    "    seg_courant_maxes.append(max(all_results[seg][:, tr.courant_index]))\n",
    "zipped = zip(seg_list, seg_courant_maxes)\n",
    "zipped = list(zipped)\n",
    "res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "# A.sort(reverse=True)\n",
    "res = (res)[:25]\n",
    "print((res)[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of those IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[933020027,\n",
       " 8777735,\n",
       " 933020017,\n",
       " 8778581,\n",
       " 933020059,\n",
       " 933020061,\n",
       " 8780597,\n",
       " 933020020,\n",
       " 933020058,\n",
       " 933020023,\n",
       " 8777485,\n",
       " 933020036,\n",
       " 8778795,\n",
       " 8778021,\n",
       " 8777339,\n",
       " 8777867,\n",
       " 8777477,\n",
       " 8780495,\n",
       " 8777861,\n",
       " 8777481,\n",
       " 8780607,\n",
       " 933020050,\n",
       " 8779003,\n",
       " 8780751,\n",
       " 8778947]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_segments = []\n",
    "for x, y in res[:25]:\n",
    "    major_segments.append(x)\n",
    "major_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the above segment IDs from the original df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.206769</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.341748</td>\n",
       "      <td>1.864082</td>\n",
       "      <td>0.497108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.206816</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.341824</td>\n",
       "      <td>1.864496</td>\n",
       "      <td>0.497108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.206857</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.341891</td>\n",
       "      <td>1.864862</td>\n",
       "      <td>0.497107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.341956</td>\n",
       "      <td>1.865216</td>\n",
       "      <td>0.497106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.206935</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>0.342019</td>\n",
       "      <td>1.865557</td>\n",
       "      <td>0.497106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>604500.0</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.134758</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.222323</td>\n",
       "      <td>45.049644</td>\n",
       "      <td>0.220286</td>\n",
       "      <td>0.145244</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>604560.0</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.134757</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.222370</td>\n",
       "      <td>45.049644</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.145242</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>604620.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134755</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.222416</td>\n",
       "      <td>45.049644</td>\n",
       "      <td>0.220281</td>\n",
       "      <td>0.145240</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>604680.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134754</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.222463</td>\n",
       "      <td>45.049644</td>\n",
       "      <td>0.220279</td>\n",
       "      <td>0.145239</td>\n",
       "      <td>0.492949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>604740.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134752</td>\n",
       "      <td>0.029786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.222510</td>\n",
       "      <td>45.049644</td>\n",
       "      <td>0.220276</td>\n",
       "      <td>0.145237</td>\n",
       "      <td>0.492949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time   flowval  velval_list  depthval   qlatval  storageval  \\\n",
       "key_index                                                                    \n",
       "8777735         0.0  0.004696     0.206769  0.011542  0.000035    0.000002   \n",
       "8777735        60.0  0.004698     0.206816  0.011546  0.000035    0.000003   \n",
       "8777735       120.0  0.004700     0.206857  0.011549  0.000035    0.000003   \n",
       "8777735       180.0  0.004703     0.206897  0.011552  0.000035    0.000004   \n",
       "8777735       240.0  0.004705     0.206935  0.011556  0.000035    0.000004   \n",
       "...             ...       ...          ...       ...       ...         ...   \n",
       "8780751    604500.0  0.008624     0.134758  0.029789  0.000000  -15.222323   \n",
       "8780751    604560.0  0.008624     0.134757  0.029788  0.000000  -15.222370   \n",
       "8780751    604620.0  0.008623     0.134755  0.029788  0.000000  -15.222416   \n",
       "8780751    604680.0  0.008623     0.134754  0.029787  0.000000  -15.222463   \n",
       "8780751    604740.0  0.008623     0.134752  0.029786  0.000000  -15.222510   \n",
       "\n",
       "           qlatCumval  kinCelerity   courant         X  \n",
       "key_index                                               \n",
       "8777735      0.002078     0.341748  1.864082  0.497108  \n",
       "8777735      0.004157     0.341824  1.864496  0.497108  \n",
       "8777735      0.006235     0.341891  1.864862  0.497107  \n",
       "8777735      0.008313     0.341956  1.865216  0.497106  \n",
       "8777735      0.010392     0.342019  1.865557  0.497106  \n",
       "...               ...          ...       ...       ...  \n",
       "8780751     45.049644     0.220286  0.145244  0.492948  \n",
       "8780751     45.049644     0.220284  0.145242  0.492948  \n",
       "8780751     45.049644     0.220281  0.145240  0.492948  \n",
       "8780751     45.049644     0.220279  0.145239  0.492949  \n",
       "8780751     45.049644     0.220276  0.145237  0.492949  \n",
       "\n",
       "[252000 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>933020027</th>\n",
       "      <td>302400.0</td>\n",
       "      <td>15.181515</td>\n",
       "      <td>4.458032</td>\n",
       "      <td>1.180036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.131263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.227305</td>\n",
       "      <td>25.363832</td>\n",
       "      <td>0.40232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time    flowval  velval_list  depthval  qlatval  storageval  \\\n",
       "key_index                                                                    \n",
       "933020027  302400.0  15.181515     4.458032  1.180036      0.0   58.131263   \n",
       "\n",
       "           qlatCumval  kinCelerity    courant        X  \n",
       "key_index                                               \n",
       "933020027         0.0     4.227305  25.363832  0.40232  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"courant\"] == 25.363832473754883]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated plotter based on filtered dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10080\n",
      "10080 20160\n",
      "20160 30240\n",
      "30240 40320\n",
      "40320 50400\n",
      "50400 60480\n",
      "60480 70560\n",
      "70560 80640\n",
      "80640 90720\n",
      "90720 100800\n",
      "100800 110880\n",
      "110880 120960\n",
      "120960 131040\n",
      "131040 141120\n",
      "141120 151200\n",
      "151200 161280\n",
      "161280 171360\n",
      "171360 181440\n",
      "181440 191520\n",
      "191520 201600\n",
      "201600 211680\n",
      "211680 221760\n",
      "221760 231840\n",
      "231840 241920\n",
      "241920 252000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "import plotly.io as pio\n",
    "\n",
    "df_indexed = df_filtered.reset_index()\n",
    "test_chart = go.FigureWidget()\n",
    "for x in range(0, 25):\n",
    "    temp_df_range_1 = single_seg_length * (x)\n",
    "    temp_df_range_2 = single_seg_length * (x + 1)\n",
    "    print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed[\"key_index\"][temp_df_range_1]),\n",
    "    )\n",
    "test_chart.layout.title = \"Timestep Chart \" + str(dt)\n",
    "plot(test_chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.7866103649139404 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.004475593566894531 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.015440702438354492 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 0.00012683868408203125 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.018262147903442383 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.019921064376831055 seconds.\n",
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 5.826689958572388 seconds.\n",
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n",
      "... complete in 6.935623645782471 seconds.\n",
      "max_courant: [27.53112221]\n",
      "routing ordered reaches for networks of order 1 ... \n",
      "... complete in 9.475980758666992 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n",
      "... complete in 19.156185626983643 seconds.\n",
      "max_courant: [126.81378174]\n",
      "ordered reach computation complete\n",
      "... in 18.554224014282227 seconds.\n",
      "program complete\n",
      "... in 26.389421463012695 seconds.\n"
     ]
    }
   ],
   "source": [
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt300.yaml\"\n",
    "all_results = tr.route_supernetwork(\n",
    "    tr.connections_g,\n",
    "    tr.networks_g,\n",
    "    tr.qlateral_g,\n",
    "    tr.waterbodies_df_g,\n",
    "    tr.waterbody_initial_states_df_g,\n",
    "    tr.channel_initial_states_df_g,\n",
    "    custom_input_file=custom_input_folder.joinpath(custom_input_file),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.02681756019592285 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.003945350646972656 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.013126611709594727 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 2.2172927856445312e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.014851808547973633 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.017706632614135742 seconds.\n",
      "creating qlateral array ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qlateral array complete\n",
      "... in 5.478479385375977 seconds.\n",
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n",
      "... complete in 6.991853713989258 seconds.\n",
      "max_courant: [27.53112221]\n",
      "routing ordered reaches for networks of order 1 ... \n",
      "... complete in 9.450271606445312 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n",
      "... complete in 19.268580675125122 seconds.\n",
      "max_courant: [126.81378174]\n",
      "ordered reach computation complete\n",
      "... in 18.68150782585144 seconds.\n",
      "program complete\n",
      "... in 25.390630960464478 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.5714733600616455 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.0040130615234375 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.013519287109375 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 2.47955322265625e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.015557050704956055 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.0167696475982666 seconds.\n",
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 5.510070562362671 seconds.\n",
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n",
      "... complete in 29.96049165725708 seconds.\n",
      "max_courant: [5.51265717]\n",
      "routing ordered reaches for networks of order 1 ... \n",
      "... complete in 42.98240113258362 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n",
      "... complete in 91.62962865829468 seconds.\n",
      "max_courant: [25.36383247]\n",
      "ordered reach computation complete\n",
      "... in 93.24933743476868 seconds.\n",
      "program complete\n",
      "... in 100.54020357131958 seconds.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'single_seg_length_10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b3c38cf90da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"segment \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_indexed_60\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"key_index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp_df_range_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     )\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtemp_df_range_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_seg_length_10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0mtemp_df_range_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_seg_length_10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;31m#         print(temp_df_range_1, temp_df_range_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'single_seg_length_10' is not defined"
     ]
    }
   ],
   "source": [
    "custom_input_file_list = [\"florence_933020089_dt300.yaml\",\"florence_933020089_dt60.yaml\"]\n",
    "df_indexed_300 = pd.DataFrame()\n",
    "df_indexed_60 = pd.DataFrame()\n",
    "# df_indexed_10 = pd.DataFrame()\n",
    "single_seg_length_300 = 0\n",
    "single_seg_length_60 = 0\n",
    "# single_seg_length_10 = 0\n",
    "for c_i in custom_input_file_list:\n",
    "    custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "    custom_input_file = c_i\n",
    "    all_results = tr.route_supernetwork(\n",
    "        tr.connections_g,\n",
    "        tr.networks_g,\n",
    "        tr.qlateral_g,\n",
    "        tr.waterbodies_df_g,\n",
    "        tr.waterbody_initial_states_df_g,\n",
    "        tr.channel_initial_states_df_g,\n",
    "        custom_input_file=custom_input_folder.joinpath(custom_input_file),\n",
    "    )\n",
    "    all_results = {}\n",
    "    seg_courant_maxes = []\n",
    "    time = []\n",
    "    flowval = []  # flowval\n",
    "    velval_list = []  # velval\n",
    "    depthval = []  # depthval\n",
    "    qlatval = []  # qlatval\n",
    "    storageval = []  # storageval\n",
    "    qlatCumval = []  # qlatCumval\n",
    "    kinCelerity = []  # ck\n",
    "    courant = []  # cn\n",
    "    X = []  # X\n",
    "\n",
    "    for result in results:\n",
    "        all_results.update(result)\n",
    "\n",
    "    # print(all_results[8780801][1][0])\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # print(all_results)\n",
    "\n",
    "    for key, data in all_results.items():\n",
    "        time.extend(data[:, 0])  # time\n",
    "        flowval.extend(data[:, 1])  # flowval\n",
    "        velval_list.extend(data[:, 2])  # velval\n",
    "        depthval.extend(data[:, 3])  # depthval\n",
    "        qlatval.extend(data[:, 4])  # qlatval\n",
    "        storageval.extend(data[:, 5])  # storageval\n",
    "        qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "        kinCelerity.extend(data[:, 7])  # ck\n",
    "        courant.extend(data[:, 8])  # cn\n",
    "        X.extend(data[:, 9])  # X\n",
    "\n",
    "    single_seg_length = len(all_results[933020089][:, 0])\n",
    "    \n",
    "    if c_i == \"florence_933020089_dt300.yaml\":\n",
    "        single_seg_length_300 = single_seg_length\n",
    "    elif c_i == \"florence_933020089_dt60.yaml\":\n",
    "        single_seg_length_60 = single_seg_length\n",
    "    else:\n",
    "        single_seg_length_10 = single_seg_length\n",
    "\n",
    "    # single_seg_length * 611\n",
    "\n",
    "    key_index = all_results.keys()\n",
    "    key_index = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            itertools.repeat(x, single_seg_length) for x in key_index\n",
    "        )\n",
    "    )\n",
    "    data = {\n",
    "        \"key_index\": list(key_index),\n",
    "        \"time\": list(time),\n",
    "        \"flowval\": list(flowval),\n",
    "        \"velval_list\": list(velval_list),\n",
    "        \"depthval\": list(depthval),\n",
    "        \"qlatval\": list(qlatval),\n",
    "        \"storageval\": list(storageval),\n",
    "        \"qlatCumval\": list(qlatCumval),\n",
    "        \"kinCelerity\": list(kinCelerity),\n",
    "        \"courant\": list(courant),\n",
    "        \"X\": list(X),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index(\"key_index\")\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(\"key_index\")\n",
    "\n",
    "\n",
    "    seg_list = []\n",
    "    seg_courant_maxes = []\n",
    "    for seg in all_results:\n",
    "        seg_list.append(seg)\n",
    "        seg_courant_maxes.append(max(all_results[seg][:, tr.courant_index]))\n",
    "    zipped = zip(seg_list, seg_courant_maxes)\n",
    "    zipped = list(zipped)\n",
    "    res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "    # A.sort(reverse=True)\n",
    "    res = (res)[:3]\n",
    "    # print((res)[:25])\n",
    "\n",
    "    major_segments = []\n",
    "    for x, y in res[:3]:\n",
    "        major_segments.append(x)\n",
    "    # major_segments\n",
    "\n",
    "    df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "\n",
    "    if c_i == \"florence_933020089_dt300.yaml\":\n",
    "        df_indexed_300 = df_filtered.reset_index()\n",
    "    elif c_i == \"florence_933020089_dt60.yaml\":\n",
    "        df_indexed_60 = df_filtered.reset_index()\n",
    "    else:\n",
    "        df_indexed_10 = df_filtered.reset_index()\n",
    "\n",
    "test_chart = go.FigureWidget()\n",
    "for x in range(0, 3):\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "#         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(dt),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "#         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(dt),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_10 * (x)\n",
    "    temp_df_range_2 = single_seg_length_10 * (x + 1)\n",
    "#         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_10[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_10[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed_10[\"key_index\"][temp_df_range_1]) + \" \" + str(dt),\n",
    "    )\n",
    "\n",
    "test_chart.layout.title = \"Timestep Chart 300, 60, 10\"\n",
    "plot(test_chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_indexed_300 \n",
    "# df_indexed_60 \n",
    "# df_indexed_10 \n",
    "single_seg_length_300\n",
    "# single_seg_length_60 \n",
    "# single_seg_length_10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
