{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic imports and path management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "root = pathlib.Path(\"../../\").resolve()\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v02\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v01\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_routing_v01\")))\n",
    "sys.path.append(\".\")\n",
    "import nhd_io as nio\n",
    "import compute_nhd_routing_SingleSeg as tr\n",
    "import nhd_network_utilities_v01 as nnu\n",
    "import nhd_reach_utilities as nru\n",
    "\n",
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt60.yaml\"\n",
    "run_pocono2_test = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the primary data input from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(custom_file)\n"
     ]
    }
   ],
   "source": [
    "supernetwork_parameters = None\n",
    "waterbody_parameters = None\n",
    "if custom_input_file:\n",
    "    (\n",
    "        supernetwork_parameters,\n",
    "        waterbody_parameters,\n",
    "        forcing_parameters,\n",
    "        restart_parameters,\n",
    "        output_parameters,\n",
    "        run_parameters,\n",
    "    ) = nio.read_custom_input(custom_input_folder.joinpath(custom_input_file))\n",
    "\n",
    "    break_network_at_waterbodies = run_parameters.get(\n",
    "        \"break_network_at_waterbodies\", None\n",
    "    )\n",
    "\n",
    "    dt = run_parameters.get(\"dt\", None)\n",
    "    nts = run_parameters.get(\"nts\", None)\n",
    "    qts_subdivisions = run_parameters.get(\"qts_subdivisions\", None)\n",
    "    debuglevel = -1 * int(run_parameters.get(\"debuglevel\", 0))\n",
    "    verbose = run_parameters.get(\"verbose\", None)\n",
    "    showtiming = run_parameters.get(\"showtiming\", None)\n",
    "    percentage_complete = run_parameters.get(\"percentage_complete\", None)\n",
    "    do_network_analysis_only = run_parameters.get(\"do_network_analysis_only\", None)\n",
    "    assume_short_ts = run_parameters.get(\"assume_short_ts\", None)\n",
    "    parallel_compute = run_parameters.get(\"parallel_compute\", None)\n",
    "    cpu_pool = run_parameters.get(\"cpu_pool\", None)\n",
    "    sort_networks = run_parameters.get(\"sort_networks\", None)\n",
    "\n",
    "    csv_output = output_parameters.get(\"csv_output\", None)\n",
    "    nc_output_folder = output_parameters.get(\"nc_output_folder\", None)\n",
    "\n",
    "    qlat_const = forcing_parameters.get(\"qlat_const\", None)\n",
    "    qlat_input_file = forcing_parameters.get(\"qlat_input_file\", None)\n",
    "    qlat_input_folder = forcing_parameters.get(\"qlat_input_folder\", None)\n",
    "    qlat_file_pattern_filter = forcing_parameters.get(\"qlat_file_pattern_filter\", None)\n",
    "    qlat_file_index_col = forcing_parameters.get(\"qlat_file_index_col\", None)\n",
    "    qlat_file_value_col = forcing_parameters.get(\"qlat_file_value_col\", None)\n",
    "\n",
    "    wrf_hydro_channel_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_upstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_upstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_downstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_downstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_depth_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_depth_flow_field_name\", None\n",
    "    )\n",
    "\n",
    "    wrf_hydro_waterbody_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file_field_name\", None\n",
    "    )\n",
    "\n",
    "# Any specific commandline arguments will override the file\n",
    "# TODO: There are probably some pathological collisions that could\n",
    "# arise from this ordering ... check these out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_pocono2_test:\n",
    "    if verbose:\n",
    "        print(\"running test case for Pocono_TEST2 domain\")\n",
    "    # Overwrite the following test defaults\n",
    "    supernetwork = \"Pocono_TEST2\"\n",
    "    break_network_at_waterbodies = False\n",
    "    qts_subdivisions = 1  # change qts_subdivisions = 1 as  default\n",
    "    dt = 300 / qts_subdivisions\n",
    "    nts = 144 * qts_subdivisions\n",
    "    csv_output = {\"csv_output_folder\": os.path.join(root, \"test\", \"output\", \"text\")}\n",
    "    nc_output_folder = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "    # test 1. Take lateral flow from re-formatted wrf-hydro output from Pocono Basin simulation\n",
    "    qlat_input_file = os.path.join(\n",
    "        root, r\"test/input/geo/PoconoSampleData2/Pocono_ql_testsamp1_nwm_mc.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.03888821601867676 seconds.\n"
     ]
    }
   ],
   "source": [
    "if showtiming:\n",
    "    program_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"begin program t-route ...\")\n",
    "\n",
    "# STEP 1: Read the supernetwork dataset and build the connections graph\n",
    "if verbose:\n",
    "    print(\"creating supernetwork connections set\")\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "\n",
    "if supernetwork_parameters:\n",
    "    supernetwork_values = nnu.get_nhd_connections(\n",
    "        supernetwork_parameters=supernetwork_parameters,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    test_folder = os.path.join(root, r\"test\")\n",
    "    geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "    supernetwork_parameters, supernetwork_values = nnu.set_networks(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "    waterbody_parameters = nnu.set_waterbody_parameters(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "if verbose:\n",
    "    print(\"supernetwork connections set complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "connections = supernetwork_values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.004379987716674805 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Separate the networks and build the sub-graph of reaches within each network\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"organizing connections into reaches ...\")\n",
    "networks = nru.compose_networks(\n",
    "    supernetwork_values,\n",
    "    break_network_at_waterbodies=break_network_at_waterbodies,\n",
    "    verbose=False,\n",
    "    debuglevel=debuglevel,\n",
    "    showtiming=showtiming,\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(\"reach organization complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.017271041870117188 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 3.7670135498046875e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.01991748809814453 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Organize Network for Waterbodies\n",
    "if break_network_at_waterbodies:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"reading waterbody parameter file ...\")\n",
    "\n",
    "    ## STEP 3a: Read waterbody parameter file\n",
    "    waterbodies_values = supernetwork_values[12]\n",
    "    waterbodies_segments = supernetwork_values[13]\n",
    "    connections_tailwaters = supernetwork_values[4]\n",
    "\n",
    "    waterbodies_df = nio.read_waterbody_df(waterbody_parameters, waterbodies_values,)\n",
    "    waterbodies_df = waterbodies_df.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "\n",
    "    nru.order_networks(connections, networks, connections_tailwaters)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbodies complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "    ## STEP 3b: Order subnetworks above and below reservoirs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks ...\")\n",
    "\n",
    "    max_network_seqorder = -1\n",
    "    for network in networks:\n",
    "        max_network_seqorder = max(\n",
    "            networks[network][\"network_seqorder\"], max_network_seqorder\n",
    "        )\n",
    "    ordered_networks = {}\n",
    "\n",
    "    for terminal_segment, network in networks.items():\n",
    "        if network[\"network_seqorder\"] not in ordered_networks:\n",
    "            ordered_networks[network[\"network_seqorder\"]] = []\n",
    "        ordered_networks[network[\"network_seqorder\"]].append(\n",
    "            (terminal_segment, network)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "else:\n",
    "    # If we are not splitting the networks, we can put them all in one order\n",
    "    max_network_seqorder = 0\n",
    "    ordered_networks = {}\n",
    "    ordered_networks[0] = [\n",
    "        (terminal_segment, network) for terminal_segment, network in networks.items()\n",
    "    ]\n",
    "\n",
    "if do_network_analysis_only:\n",
    "    sys.exit()\n",
    "\n",
    "if break_network_at_waterbodies:\n",
    "    ## STEP 3c: Handle Waterbody Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting waterbody initial states ...\")\n",
    "\n",
    "    if wrf_hydro_waterbody_restart_file:\n",
    "\n",
    "        waterbody_initial_states_df = nio.get_reservoir_restart_from_wrf_hydro(\n",
    "            wrf_hydro_waterbody_restart_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file_field_name,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file_field_name,\n",
    "        )\n",
    "    else:\n",
    "        # TODO: Consider adding option to read cold state from route-link file\n",
    "        waterbody_initial_ds_flow_const = 0.0\n",
    "        waterbody_initial_depth_const = 0.0\n",
    "        # Set initial states from cold-state\n",
    "        waterbody_initial_states_df = pd.DataFrame(\n",
    "            0, index=waterbodies_df.index, columns=[\"qd0\", \"h0\",], dtype=\"float32\"\n",
    "        )\n",
    "        # TODO: This assignment could probably by done in the above call\n",
    "        waterbody_initial_states_df[\"qd0\"] = waterbody_initial_ds_flow_const\n",
    "        waterbody_initial_states_df[\"h0\"] = waterbody_initial_depth_const\n",
    "        waterbody_initial_states_df[\"index\"] = range(len(waterbody_initial_states_df))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbody initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.02246999740600586 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Handle Channel Initial States\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"setting channel initial states ...\")\n",
    "\n",
    "if wrf_hydro_channel_restart_file:\n",
    "\n",
    "    channel_initial_states_df = nio.get_stream_restart_from_wrf_hydro(\n",
    "        wrf_hydro_channel_restart_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file_field_name,\n",
    "        wrf_hydro_channel_restart_upstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_downstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_depth_flow_field_name,\n",
    "    )\n",
    "else:\n",
    "    # TODO: Consider adding option to read cold state from route-link file\n",
    "    channel_initial_us_flow_const = 0.0\n",
    "    channel_initial_ds_flow_const = 0.0\n",
    "    channel_initial_depth_const = 0.0\n",
    "    # Set initial states from cold-state\n",
    "    channel_initial_states_df = pd.DataFrame(\n",
    "        0, index=connections.keys(), columns=[\"qu0\", \"qd0\", \"h0\",], dtype=\"float32\"\n",
    "    )\n",
    "    channel_initial_states_df[\"qu0\"] = channel_initial_us_flow_const\n",
    "    channel_initial_states_df[\"qd0\"] = channel_initial_ds_flow_const\n",
    "    channel_initial_states_df[\"h0\"] = channel_initial_depth_const\n",
    "    channel_initial_states_df[\"index\"] = range(len(channel_initial_states_df))\n",
    "\n",
    "if verbose:\n",
    "    print(\"channel initial states complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 6.396091938018799 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Read (or set) QLateral Inputs\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"creating qlateral array ...\")\n",
    "\n",
    "# initialize qlateral dict\n",
    "qlateral = {}\n",
    "\n",
    "if qlat_input_folder:\n",
    "    qlat_files = []\n",
    "    for pattern in qlat_file_pattern_filter:\n",
    "        qlat_files.extend(glob.glob(qlat_input_folder + pattern))\n",
    "    qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "        qlat_files=qlat_files,\n",
    "        index_col=qlat_file_index_col,\n",
    "        value_col=qlat_file_value_col,\n",
    "    )\n",
    "\n",
    "elif qlat_input_file:\n",
    "    qlat_df = nio.get_ql_from_csv(qlat_input_file)\n",
    "\n",
    "else:\n",
    "    qlat_df = pd.DataFrame(\n",
    "        qlat_const, index=connections.keys(), columns=range(nts), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "for index, row in qlat_df.iterrows():\n",
    "    qlateral[index] = row.tolist()\n",
    "\n",
    "if verbose:\n",
    "    print(\"qlateral array complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Sort the ordered networks\n",
    "if sort_networks:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"sorting the ordered networks ...\")\n",
    "\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        sort_ordered_network(ordered_networks[nsq], True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"sorting complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the pool after we create the static global objects (and collect the garbage)\n",
    "if parallel_compute:\n",
    "    import gc\n",
    "\n",
    "    gc.collect()\n",
    "    pool = multiprocessing.Pool(cpu_pool)\n",
    "\n",
    "flowveldepth_connect = (\n",
    "    {}\n",
    ")  # dict to contain values to transfer from upstream to downstream networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1108 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 467/1108 [00:35<00:48, 13.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 35.58297324180603 seconds.\n",
      "max_courant: [5.51265717]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 467/1108 [00:48<00:48, 13.19it/s]\u001b[A\n",
      " 45%|████▌     | 499/1108 [00:49<01:53,  5.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 49.79691505432129 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1108/1108 [01:50<00:00,  6.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 111.17425584793091 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [01:54<00:00,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [25.36383247]\n",
      "ordered reach computation complete\n",
      "... in 114.53386664390564 seconds.\n",
      "program complete\n",
      "... in 121.2260513305664 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################### Main Execution Loop across ordered networks\n",
    "if showtiming:\n",
    "    main_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"executing routing computation ...\")\n",
    "\n",
    "compute_network_func = tr.compute_network\n",
    "\n",
    "tr.connections_g = connections\n",
    "tr.networks_g = networks\n",
    "tr.qlateral_g = qlateral\n",
    "tr.waterbodies_df_g = waterbodies_df\n",
    "tr.waterbody_initial_states_df_g = waterbody_initial_states_df\n",
    "tr.channel_initial_states_df_g = channel_initial_states_df\n",
    "\n",
    "progress_count = 0\n",
    "percentage_complete = True\n",
    "if percentage_complete:\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        for terminal_segment, network in ordered_networks[nsq]:\n",
    "            progress_count += len(network[\"all_segments\"])\n",
    "    pbar = tqdm(total=(progress_count))\n",
    "\n",
    "for nsq in range(max_network_seqorder, -1, -1):\n",
    "\n",
    "    if parallel_compute:\n",
    "        nslist = []\n",
    "    results = []\n",
    "\n",
    "    current_index_total = 0\n",
    "\n",
    "    for terminal_segment, network in ordered_networks[nsq]:\n",
    "\n",
    "        if percentage_complete:\n",
    "            if current_index_total == 0:\n",
    "                pbar.update(0)\n",
    "\n",
    "        if break_network_at_waterbodies:\n",
    "            waterbody = waterbodies_segments.get(terminal_segment)\n",
    "        else:\n",
    "            waterbody = None\n",
    "        if not parallel_compute:  # serial execution\n",
    "            if showtiming:\n",
    "                start_time = time.time()\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"routing ordered reaches for terminal segment {terminal_segment} ...\"\n",
    "                )\n",
    "\n",
    "            results.append(\n",
    "                compute_network_func(\n",
    "                    flowveldepth_connect=flowveldepth_connect,\n",
    "                    terminal_segment=terminal_segment,\n",
    "                    supernetwork_parameters=supernetwork_parameters,\n",
    "                    waterbody_parameters=waterbody_parameters,\n",
    "                    waterbody=waterbody,\n",
    "                    nts=nts,\n",
    "                    dt=dt,\n",
    "                    qts_subdivisions=qts_subdivisions,\n",
    "                    verbose=verbose,\n",
    "                    debuglevel=debuglevel,\n",
    "                    csv_output=csv_output,\n",
    "                    nc_output_folder=nc_output_folder,\n",
    "                    assume_short_ts=assume_short_ts,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if showtiming:\n",
    "                print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "            if percentage_complete:\n",
    "                pbar.update(len(network[\"all_segments\"]))\n",
    "\n",
    "        else:  # parallel execution\n",
    "            nslist.append(\n",
    "                [\n",
    "                    flowveldepth_connect,\n",
    "                    terminal_segment,\n",
    "                    supernetwork_parameters,  # TODO: This should probably be global...\n",
    "                    waterbody_parameters,\n",
    "                    waterbody,\n",
    "                    nts,\n",
    "                    dt,\n",
    "                    qts_subdivisions,\n",
    "                    verbose,\n",
    "                    debuglevel,\n",
    "                    csv_output,\n",
    "                    nc_output_folder,\n",
    "                    assume_short_ts,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    if parallel_compute:\n",
    "        if verbose:\n",
    "            print(f\"routing ordered reaches for networks of order {nsq} ... \")\n",
    "        if debuglevel <= -2:\n",
    "            print(f\"reaches to be routed include:\")\n",
    "            print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "        # with pool:\n",
    "        # with multiprocessing.Pool() as pool:\n",
    "        results = pool.starmap(compute_network_func, nslist)\n",
    "\n",
    "        if showtiming:\n",
    "            print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "        if percentage_complete:\n",
    "            pbar.update(\n",
    "                sum(\n",
    "                    len(network[1][\"all_segments\"]) for network in ordered_networks[nsq]\n",
    "                )\n",
    "            )\n",
    "            # print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "\n",
    "    max_courant = 0\n",
    "    maxa = []\n",
    "    for result in results:\n",
    "        for seg in result:\n",
    "            maxa.extend(result[seg][:, 8:9])\n",
    "    max_courant = max(maxa)\n",
    "    print(f\"max_courant: {max_courant}\")\n",
    "\n",
    "    if (\n",
    "        nsq > 0\n",
    "    ):  # We skip this step for zero-order networks, i.e., those that have no downstream dependents\n",
    "        flowveldepth_connect = (\n",
    "            {}\n",
    "        )  # There is no need to preserve previously passed on values -- so we clear the dictionary\n",
    "        for i, (terminal_segment, network) in enumerate(ordered_networks[nsq]):\n",
    "            # seg = network[\"reaches\"][network[\"terminal_reach\"]][\"reach_tail\"]\n",
    "            seg = terminal_segment\n",
    "            flowveldepth_connect[seg] = {}\n",
    "            flowveldepth_connect[seg] = results[i][seg]\n",
    "            # TODO: The value passed here could be much more specific to\n",
    "            # TODO: exactly and only the most recent time step for the passing reach\n",
    "\n",
    "if parallel_compute:\n",
    "    pool.close()\n",
    "\n",
    "if percentage_complete:\n",
    "    pbar.close()\n",
    "\n",
    "if verbose:\n",
    "    print(\"ordered reach computation complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - main_start_time))\n",
    "if verbose:\n",
    "    print(\"program complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - program_start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the main dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results)\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "all_results = {}\n",
    "seg_courant_maxes = []\n",
    "time = []\n",
    "flowval = []  # flowval\n",
    "velval_list = []  # velval\n",
    "depthval = []  # depthval\n",
    "qlatval = []  # qlatval\n",
    "storageval = []  # storageval\n",
    "qlatCumval = []  # qlatCumval\n",
    "kinCelerity = []  # ck\n",
    "courant = []  # cn\n",
    "X = []  # X\n",
    "\n",
    "for result in results:\n",
    "    all_results.update(result)\n",
    "\n",
    "# print(all_results[8780801][1][0])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# print(all_results)\n",
    "\n",
    "for key, data in all_results.items():\n",
    "    time.extend(data[:, 0])  # time\n",
    "    flowval.extend(data[:, 1])  # flowval\n",
    "    velval_list.extend(data[:, 2])  # velval\n",
    "    depthval.extend(data[:, 3])  # depthval\n",
    "    qlatval.extend(data[:, 4])  # qlatval\n",
    "    storageval.extend(data[:, 5])  # storageval\n",
    "    qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "    kinCelerity.extend(data[:, 7])  # ck\n",
    "    courant.extend(data[:, 8])  # cn\n",
    "    X.extend(data[:, 9])  # X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8798400"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_seg_length = len(all_results[933020089][:, 0])\n",
    "single_seg_length * 611\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8798400"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034005</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-3.929017e-08</td>\n",
       "      <td>1.079874e-02</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>0.499495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-7.508788e-08</td>\n",
       "      <td>2.159748e-02</td>\n",
       "      <td>0.056322</td>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.499496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034044</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-1.082662e-07</td>\n",
       "      <td>3.239622e-02</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>0.017696</td>\n",
       "      <td>0.499496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-1.388253e-07</td>\n",
       "      <td>4.319496e-02</td>\n",
       "      <td>0.056336</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>0.499496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-1.667649e-07</td>\n",
       "      <td>5.399370e-02</td>\n",
       "      <td>0.056337</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>0.499496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863700.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135146e+06</td>\n",
       "      <td>1.368751e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863760.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135199e+06</td>\n",
       "      <td>1.368760e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863820.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135252e+06</td>\n",
       "      <td>1.368769e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863880.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135305e+06</td>\n",
       "      <td>1.368778e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863940.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135357e+06</td>\n",
       "      <td>1.368787e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8798400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time   flowval  velval_list  depthval   qlatval    storageval  \\\n",
       "key_index                                                                      \n",
       "8780801         0.0  0.000180     0.034005  0.005051  0.000180 -3.929017e-08   \n",
       "8780801        60.0  0.000180     0.034037  0.005058  0.000180 -7.508788e-08   \n",
       "8780801       120.0  0.000180     0.034044  0.005060  0.000180 -1.082662e-07   \n",
       "8780801       180.0  0.000180     0.034046  0.005060  0.000180 -1.388253e-07   \n",
       "8780801       240.0  0.000180     0.034046  0.005060  0.000180 -1.667649e-07   \n",
       "...             ...       ...          ...       ...       ...           ...   \n",
       "8778465    863700.0  0.000036     0.000000  0.000000  0.149393  8.135146e+06   \n",
       "8778465    863760.0  0.000036     0.000000  0.000000  0.149393  8.135199e+06   \n",
       "8778465    863820.0  0.000036     0.000000  0.000000  0.149393  8.135252e+06   \n",
       "8778465    863880.0  0.000036     0.000000  0.000000  0.149393  8.135305e+06   \n",
       "8778465    863940.0  0.000036     0.000000  0.000000  0.149393  8.135357e+06   \n",
       "\n",
       "             qlatCumval  kinCelerity   courant         X  \n",
       "key_index                                                 \n",
       "8780801    1.079874e-02     0.056269  0.017676  0.499495  \n",
       "8780801    2.159748e-02     0.056322  0.017693  0.499496  \n",
       "8780801    3.239622e-02     0.056334  0.017696  0.499496  \n",
       "8780801    4.319496e-02     0.056336  0.017697  0.499496  \n",
       "8780801    5.399370e-02     0.056337  0.017697  0.499496  \n",
       "...                 ...          ...       ...       ...  \n",
       "8778465    1.368751e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368760e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368769e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368778e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368787e+06     0.000000  0.000000  0.000000  \n",
       "\n",
       "[8798400 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_index = all_results.keys()\n",
    "key_index = list(\n",
    "    itertools.chain.from_iterable(\n",
    "        itertools.repeat(x, single_seg_length) for x in key_index\n",
    "    )\n",
    ")\n",
    "data = {\n",
    "    \"key_index\": list(key_index),\n",
    "    \"time\": list(time),\n",
    "    \"flowval\": list(flowval),\n",
    "    \"velval_list\": list(velval_list),\n",
    "    \"depthval\": list(depthval),\n",
    "    \"qlatval\": list(qlatval),\n",
    "    \"storageval\": list(storageval),\n",
    "    \"qlatCumval\": list(qlatCumval),\n",
    "    \"kinCelerity\": list(kinCelerity),\n",
    "    \"courant\": list(courant),\n",
    "    \"X\": list(X),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index(\"key_index\")\n",
    "df = df.reset_index()\n",
    "df = df.set_index(\"key_index\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-4.12.0-py2.py3-none-any.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: six in /home/jacob.hreha/anaconda3/lib/python3.7/site-packages (from plotly) (1.14.0)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11430 sha256=955fe8c56e0da1a48727c21349a3bdf87e4a3b4377f30b8a6947f02fff9ed733\n",
      "  Stored in directory: /home/jacob.hreha/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly\n",
      "Successfully installed plotly-4.12.0 retrying-1.3.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/jacob.hreha/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 25 courants based on our work this morning and their segment IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(933020027, 25.363832473754883), (8777735, 14.950478553771973), (933020017, 9.564001083374023), (8778581, 8.574037551879883), (933020059, 7.254691123962402), (933020061, 4.696855068206787), (8780597, 3.591726064682007), (933020020, 2.8707876205444336), (933020058, 2.4734983444213867), (933020023, 2.1059963703155518), (8777485, 1.860101580619812), (933020036, 1.6248382329940796), (8778795, 1.6150635480880737), (8778021, 1.4462398290634155), (8777339, 1.393180251121521), (8777867, 1.353600263595581), (8777477, 1.3393661975860596), (8780495, 1.3077224493026733), (8777861, 1.1583272218704224), (8777481, 1.149632215499878), (8780607, 1.0738232135772705), (8779003, 1.0580987930297852), (933020050, 1.0441739559173584), (8780751, 0.9917784929275513), (8778947, 0.9753884673118591)]\n"
     ]
    }
   ],
   "source": [
    "seg_list = []\n",
    "seg_courant_maxes = []\n",
    "for seg in all_results:\n",
    "    seg_list.append(seg)\n",
    "    seg_courant_maxes.append(max(all_results[seg][:, tr.courant_index]))\n",
    "zipped = zip(seg_list, seg_courant_maxes)\n",
    "zipped = list(zipped)\n",
    "res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "# A.sort(reverse=True)\n",
    "res = (res)[:25]\n",
    "print((res)[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of those IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[933020027,\n",
       " 8777735,\n",
       " 933020017,\n",
       " 8778581,\n",
       " 933020059,\n",
       " 933020061,\n",
       " 8780597,\n",
       " 933020020,\n",
       " 933020058,\n",
       " 933020023,\n",
       " 8777485,\n",
       " 933020036,\n",
       " 8778795,\n",
       " 8778021,\n",
       " 8777339,\n",
       " 8777867,\n",
       " 8777477,\n",
       " 8780495,\n",
       " 8777861,\n",
       " 8777481,\n",
       " 8780607,\n",
       " 8779003,\n",
       " 933020050,\n",
       " 8780751,\n",
       " 8778947]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_segments = []\n",
    "for x, y in res[:25]:\n",
    "    major_segments.append(x)\n",
    "major_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the above segment IDs from the original df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185580</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-6.722985e-08</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.307107</td>\n",
       "      <td>1.675127</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185576</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-4.190952e-08</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.307099</td>\n",
       "      <td>1.675087</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185573</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-4.627509e-08</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.307094</td>\n",
       "      <td>1.675061</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185570</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-6.810296e-08</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.307090</td>\n",
       "      <td>1.675035</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-7.770723e-08</td>\n",
       "      <td>0.010456</td>\n",
       "      <td>0.307085</td>\n",
       "      <td>1.675010</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863700.0</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.134758</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558339e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220286</td>\n",
       "      <td>0.145244</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863760.0</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.134757</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558343e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.145242</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863820.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134755</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558348e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220281</td>\n",
       "      <td>0.145240</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863880.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134754</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558353e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220279</td>\n",
       "      <td>0.145239</td>\n",
       "      <td>0.492949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863940.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134752</td>\n",
       "      <td>0.029786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558357e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220276</td>\n",
       "      <td>0.145237</td>\n",
       "      <td>0.492949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time   flowval  velval_list  depthval   qlatval    storageval  \\\n",
       "key_index                                                                      \n",
       "8777735         0.0  0.004196     0.185580  0.009796  0.000035 -6.722985e-08   \n",
       "8777735        60.0  0.004196     0.185576  0.009795  0.000035 -4.190952e-08   \n",
       "8777735       120.0  0.004196     0.185573  0.009795  0.000035 -4.627509e-08   \n",
       "8777735       180.0  0.004196     0.185570  0.009795  0.000035 -6.810296e-08   \n",
       "8777735       240.0  0.004196     0.185567  0.009794  0.000035 -7.770723e-08   \n",
       "...             ...       ...          ...       ...       ...           ...   \n",
       "8780751    863700.0  0.008624     0.134758  0.029789  0.000000 -1.558339e+01   \n",
       "8780751    863760.0  0.008624     0.134757  0.029788  0.000000 -1.558343e+01   \n",
       "8780751    863820.0  0.008623     0.134755  0.029788  0.000000 -1.558348e+01   \n",
       "8780751    863880.0  0.008623     0.134754  0.029787  0.000000 -1.558353e+01   \n",
       "8780751    863940.0  0.008623     0.134752  0.029786  0.000000 -1.558357e+01   \n",
       "\n",
       "           qlatCumval  kinCelerity   courant         X  \n",
       "key_index                                               \n",
       "8777735      0.002091     0.307107  1.675127  0.498455  \n",
       "8777735      0.004183     0.307099  1.675087  0.498455  \n",
       "8777735      0.006274     0.307094  1.675061  0.498455  \n",
       "8777735      0.008365     0.307090  1.675035  0.498455  \n",
       "8777735      0.010456     0.307085  1.675010  0.498455  \n",
       "...               ...          ...       ...       ...  \n",
       "8780751     50.799377     0.220286  0.145244  0.492948  \n",
       "8780751     50.799377     0.220284  0.145242  0.492948  \n",
       "8780751     50.799377     0.220281  0.145240  0.492948  \n",
       "8780751     50.799377     0.220279  0.145239  0.492949  \n",
       "8780751     50.799377     0.220276  0.145237  0.492949  \n",
       "\n",
       "[360000 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>933020027</td>\n",
       "      <td>561600.0</td>\n",
       "      <td>15.181515</td>\n",
       "      <td>4.458032</td>\n",
       "      <td>1.180036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.131255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.227305</td>\n",
       "      <td>25.363832</td>\n",
       "      <td>0.40232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time    flowval  velval_list  depthval  qlatval  storageval  \\\n",
       "key_index                                                                    \n",
       "933020027  561600.0  15.181515     4.458032  1.180036      0.0   58.131255   \n",
       "\n",
       "           qlatCumval  kinCelerity    courant        X  \n",
       "key_index                                               \n",
       "933020027         0.0     4.227305  25.363832  0.40232  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"courant\"] == 25.363832473754883]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated plotter based on filtered dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 14400\n",
      "14400 28800\n",
      "28800 43200\n",
      "43200 57600\n",
      "57600 72000\n",
      "72000 86400\n",
      "86400 100800\n",
      "100800 115200\n",
      "115200 129600\n",
      "129600 144000\n",
      "144000 158400\n",
      "158400 172800\n",
      "172800 187200\n",
      "187200 201600\n",
      "201600 216000\n",
      "216000 230400\n",
      "230400 244800\n",
      "244800 259200\n",
      "259200 273600\n",
      "273600 288000\n",
      "288000 302400\n",
      "302400 316800\n",
      "316800 331200\n",
      "331200 345600\n",
      "345600 360000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "import plotly.io as pio\n",
    "\n",
    "df_indexed = df_filtered.reset_index()\n",
    "test_chart = go.FigureWidget()\n",
    "for x in range(0, 25):\n",
    "    temp_df_range_1 = single_seg_length * (x)\n",
    "    temp_df_range_2 = single_seg_length * (x + 1)\n",
    "    print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed[\"key_index\"][temp_df_range_1]),\n",
    "    )\n",
    "test_chart.layout.title = \"Timestep Chart \" + str(dt)\n",
    "plot(test_chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.04615497589111328 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.007277727127075195 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.022621631622314453 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 4.4345855712890625e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.0272982120513916 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.029682159423828125 seconds.\n",
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 8.037819862365723 seconds.\n",
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n",
      "... complete in 9.12061858177185 seconds.\n",
      "max_courant: [27.53112221]\n",
      "routing ordered reaches for networks of order 1 ... \n",
      "... complete in 11.953770399093628 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n",
      "... complete in 24.70727014541626 seconds.\n",
      "max_courant: [126.81378174]\n",
      "ordered reach computation complete\n",
      "... in 23.734419584274292 seconds.\n",
      "program complete\n",
      "... in 33.576523303985596 seconds.\n"
     ]
    }
   ],
   "source": [
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt300.yaml\"\n",
    "all_results = tr.route_supernetwork(\n",
    "    tr.connections_g,\n",
    "    tr.networks_g,\n",
    "    tr.qlateral_g,\n",
    "    tr.waterbodies_df_g,\n",
    "    tr.waterbody_initial_states_df_g,\n",
    "    tr.channel_initial_states_df_g,\n",
    "    custom_input_file=custom_input_folder.joinpath(custom_input_file),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "florence_933020089_dt300.yaml\n",
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.03426241874694824 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.003715991973876953 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.016068458557128906 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 3.0279159545898438e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.017216205596923828 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.01768350601196289 seconds.\n",
      "creating qlateral array ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qlateral array complete\n",
      "... in 8.201142072677612 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1108 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 467/1108 [00:07<00:09, 64.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 9.088607788085938 seconds.\n",
      "max_courant: [27.53112221]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 499/1108 [00:11<00:28, 21.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 12.854177236557007 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1108/1108 [00:23<00:00, 26.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 25.183329820632935 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [00:24<00:00, 45.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [126.81378174]\n",
      "ordered reach computation complete\n",
      "... in 24.119707345962524 seconds.\n",
      "program complete\n",
      "... in 34.19549369812012 seconds.\n",
      "      key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0       8777735       0.0  0.004196     0.185580  0.009796  0.000035   \n",
      "1       8777735     300.0  0.004196     0.185566  0.009794  0.000035   \n",
      "2       8777735     600.0  0.004195     0.185552  0.009793  0.000035   \n",
      "3       8777735     900.0  0.004194     0.185539  0.009792  0.000035   \n",
      "4       8777735    1200.0  0.004193     0.185527  0.009791  0.000035   \n",
      "...         ...       ...       ...          ...       ...       ...   \n",
      "8635  933020027  862500.0  0.058953     0.755009  0.049310  0.000000   \n",
      "8636  933020027  862800.0  0.058909     0.754795  0.049287  0.000000   \n",
      "8637  933020027  863100.0  0.058867     0.754590  0.049266  0.000000   \n",
      "8638  933020027  863400.0  0.058826     0.754394  0.049246  0.000000   \n",
      "8639  933020027  863700.0  0.058788     0.754206  0.049226  0.000000   \n",
      "\n",
      "        storageval  qlatCumval  kinCelerity    courant         X  \n",
      "0    -3.361492e-07    0.010456     0.307107   8.375633  0.498455  \n",
      "1    -6.897608e-07    0.020913     0.307083   8.375002  0.498455  \n",
      "2    -8.949428e-07    0.031369     0.307061   8.374394  0.498455  \n",
      "3    -1.292210e-06    0.041826     0.307039   8.373803  0.498456  \n",
      "4    -1.654553e-06    0.052282     0.307019   8.373238  0.498456  \n",
      "...            ...         ...          ...        ...       ...  \n",
      "8635  9.065894e+01    0.000000     1.211574  36.347221  0.493714  \n",
      "8636  9.065886e+01    0.000000     1.211248  36.337448  0.493717  \n",
      "8637  9.065878e+01    0.000000     1.210937  36.328110  0.493719  \n",
      "8638  9.065871e+01    0.000000     1.210639  36.319172  0.493722  \n",
      "8639  9.065863e+01    0.000000     1.210353  36.310593  0.493724  \n",
      "\n",
      "[8640 rows x 11 columns] Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "florence_933020089_dt60.yaml\n",
      "begin program t-route ...\n",
      "creating supernetwork connections set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supernetwork connections set complete\n",
      "... in 0.029515504837036133 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.20309901237487793 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.014076709747314453 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 2.5033950805664062e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.014064311981201172 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.015584230422973633 seconds.\n",
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 6.2634851932525635 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1108 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 467/1108 [00:35<00:49, 12.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 36.67781901359558 seconds.\n",
      "max_courant: [5.51265717]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 499/1108 [00:50<01:56,  5.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 51.25721836090088 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1108/1108 [01:51<00:00,  6.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 112.29779148101807 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [01:55<00:00,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [25.36383247]\n",
      "ordered reach computation complete\n",
      "... in 115.23613929748535 seconds.\n",
      "program complete\n",
      "... in 122.44014620780945 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0       8777735       0.0  0.004196     0.185580  0.009796  0.000035   \n",
      "1       8777735     300.0  0.004196     0.185566  0.009794  0.000035   \n",
      "2       8777735     600.0  0.004195     0.185552  0.009793  0.000035   \n",
      "3       8777735     900.0  0.004194     0.185539  0.009792  0.000035   \n",
      "4       8777735    1200.0  0.004193     0.185527  0.009791  0.000035   \n",
      "...         ...       ...       ...          ...       ...       ...   \n",
      "8635  933020027  862500.0  0.058953     0.755009  0.049310  0.000000   \n",
      "8636  933020027  862800.0  0.058909     0.754795  0.049287  0.000000   \n",
      "8637  933020027  863100.0  0.058867     0.754590  0.049266  0.000000   \n",
      "8638  933020027  863400.0  0.058826     0.754394  0.049246  0.000000   \n",
      "8639  933020027  863700.0  0.058788     0.754206  0.049226  0.000000   \n",
      "\n",
      "        storageval  qlatCumval  kinCelerity    courant         X  \n",
      "0    -3.361492e-07    0.010456     0.307107   8.375633  0.498455  \n",
      "1    -6.897608e-07    0.020913     0.307083   8.375002  0.498455  \n",
      "2    -8.949428e-07    0.031369     0.307061   8.374394  0.498455  \n",
      "3    -1.292210e-06    0.041826     0.307039   8.373803  0.498456  \n",
      "4    -1.654553e-06    0.052282     0.307019   8.373238  0.498456  \n",
      "...            ...         ...          ...        ...       ...  \n",
      "8635  9.065894e+01    0.000000     1.211574  36.347221  0.493714  \n",
      "8636  9.065886e+01    0.000000     1.211248  36.337448  0.493717  \n",
      "8637  9.065878e+01    0.000000     1.210937  36.328110  0.493719  \n",
      "8638  9.065871e+01    0.000000     1.210639  36.319172  0.493722  \n",
      "8639  9.065863e+01    0.000000     1.210353  36.310593  0.493724  \n",
      "\n",
      "[8640 rows x 11 columns]        key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0        8777735       0.0  0.004196     0.185580  0.009796  0.000035   \n",
      "1        8777735      60.0  0.004196     0.185576  0.009795  0.000035   \n",
      "2        8777735     120.0  0.004196     0.185573  0.009795  0.000035   \n",
      "3        8777735     180.0  0.004196     0.185570  0.009795  0.000035   \n",
      "4        8777735     240.0  0.004196     0.185567  0.009794  0.000035   \n",
      "...          ...       ...       ...          ...       ...       ...   \n",
      "43195  933020027  863700.0  0.058770     0.754123  0.049218  0.000000   \n",
      "43196  933020027  863760.0  0.058763     0.754086  0.049214  0.000000   \n",
      "43197  933020027  863820.0  0.058755     0.754050  0.049210  0.000000   \n",
      "43198  933020027  863880.0  0.058748     0.754015  0.049206  0.000000   \n",
      "43199  933020027  863940.0  0.058741     0.753979  0.049203  0.000000   \n",
      "\n",
      "         storageval  qlatCumval  kinCelerity   courant         X  \n",
      "0     -6.722985e-08    0.002091     0.307107  1.675127  0.498455  \n",
      "1     -4.190952e-08    0.004183     0.307099  1.675087  0.498455  \n",
      "2     -4.627509e-08    0.006274     0.307094  1.675061  0.498455  \n",
      "3     -6.810296e-08    0.008365     0.307090  1.675035  0.498455  \n",
      "4     -7.770723e-08    0.010456     0.307085  1.675010  0.498455  \n",
      "...             ...         ...          ...       ...       ...  \n",
      "43195  4.286438e+00    0.000000     1.210227  7.261362  0.493725  \n",
      "43196  4.286436e+00    0.000000     1.210172  7.261031  0.493726  \n",
      "43197  4.286433e+00    0.000000     1.210117  7.260703  0.493726  \n",
      "43198  4.286430e+00    0.000000     1.210063  7.260379  0.493727  \n",
      "43199  4.286428e+00    0.000000     1.210009  7.260056  0.493727  \n",
      "\n",
      "[43200 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_input_file_list = [\"florence_933020089_dt300.yaml\",\"florence_933020089_dt60.yaml\"]\n",
    "from plotly.subplots import make_subplots\n",
    "df_indexed_300 = pd.DataFrame()\n",
    "df_indexed_60 = pd.DataFrame()\n",
    "for c_i in (custom_input_file_list):\n",
    "    print(c_i)\n",
    "    import pathlib\n",
    "    import sys\n",
    "    import time\n",
    "    import glob\n",
    "    from tqdm import tqdm\n",
    "    import multiprocessing\n",
    "\n",
    "    root = pathlib.Path(\"../../\").resolve()\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_framework_v02\")))\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_framework_v01\")))\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_routing_v01\")))\n",
    "    sys.path.append(\".\")\n",
    "    import nhd_io as nio\n",
    "    import compute_nhd_routing_SingleSeg as tr\n",
    "    import nhd_network_utilities_v01 as nnu\n",
    "    import nhd_reach_utilities as nru\n",
    "\n",
    "    custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "    custom_input_file = c_i\n",
    "    run_pocono2_test = None\n",
    "\n",
    "    supernetwork_parameters = None\n",
    "    waterbody_parameters = None\n",
    "    if custom_input_file:\n",
    "        (\n",
    "            supernetwork_parameters,\n",
    "            waterbody_parameters,\n",
    "            forcing_parameters,\n",
    "            restart_parameters,\n",
    "            output_parameters,\n",
    "            run_parameters,\n",
    "        ) = nio.read_custom_input(custom_input_folder.joinpath(custom_input_file))\n",
    "\n",
    "        break_network_at_waterbodies = run_parameters.get(\n",
    "            \"break_network_at_waterbodies\", None\n",
    "        )\n",
    "\n",
    "        dt = run_parameters.get(\"dt\", None)\n",
    "        nts = run_parameters.get(\"nts\", None)\n",
    "        qts_subdivisions = run_parameters.get(\"qts_subdivisions\", None)\n",
    "        debuglevel = -1 * int(run_parameters.get(\"debuglevel\", 0))\n",
    "        verbose = run_parameters.get(\"verbose\", None)\n",
    "        showtiming = run_parameters.get(\"showtiming\", None)\n",
    "        percentage_complete = run_parameters.get(\"percentage_complete\", None)\n",
    "        do_network_analysis_only = run_parameters.get(\"do_network_analysis_only\", None)\n",
    "        assume_short_ts = run_parameters.get(\"assume_short_ts\", None)\n",
    "        parallel_compute = run_parameters.get(\"parallel_compute\", None)\n",
    "        cpu_pool = run_parameters.get(\"cpu_pool\", None)\n",
    "        sort_networks = run_parameters.get(\"sort_networks\", None)\n",
    "\n",
    "        csv_output = output_parameters.get(\"csv_output\", None)\n",
    "        nc_output_folder = output_parameters.get(\"nc_output_folder\", None)\n",
    "\n",
    "        qlat_const = forcing_parameters.get(\"qlat_const\", None)\n",
    "        qlat_input_file = forcing_parameters.get(\"qlat_input_file\", None)\n",
    "        qlat_input_folder = forcing_parameters.get(\"qlat_input_folder\", None)\n",
    "        qlat_file_pattern_filter = forcing_parameters.get(\"qlat_file_pattern_filter\", None)\n",
    "        qlat_file_index_col = forcing_parameters.get(\"qlat_file_index_col\", None)\n",
    "        qlat_file_value_col = forcing_parameters.get(\"qlat_file_value_col\", None)\n",
    "\n",
    "        wrf_hydro_channel_restart_file = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_file\", None\n",
    "        )\n",
    "        wrf_hydro_channel_ID_crosswalk_file = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_ID_crosswalk_file\", None\n",
    "        )\n",
    "        wrf_hydro_channel_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_ID_crosswalk_file_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_upstream_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_upstream_flow_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_downstream_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_downstream_flow_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_depth_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_depth_flow_field_name\", None\n",
    "        )\n",
    "\n",
    "        wrf_hydro_waterbody_restart_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_restart_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_ID_crosswalk_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_ID_crosswalk_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_ID_crosswalk_file_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_crosswalk_filter_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_crosswalk_filter_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_crosswalk_filter_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_crosswalk_filter_file_field_name\", None\n",
    "        )\n",
    "\n",
    "    # Any specific commandline arguments will override the file\n",
    "    # TODO: There are probably some pathological collisions that could\n",
    "    # arise from this ordering ... check these out.\n",
    "\n",
    "    if run_pocono2_test:\n",
    "        if verbose:\n",
    "            print(\"running test case for Pocono_TEST2 domain\")\n",
    "        # Overwrite the following test defaults\n",
    "        supernetwork = \"Pocono_TEST2\"\n",
    "        break_network_at_waterbodies = False\n",
    "        qts_subdivisions = 1  # change qts_subdivisions = 1 as  default\n",
    "        dt = 300 / qts_subdivisions\n",
    "        nts = 144 * qts_subdivisions\n",
    "        csv_output = {\"csv_output_folder\": os.path.join(root, \"test\", \"output\", \"text\")}\n",
    "        nc_output_folder = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "        # test 1. Take lateral flow from re-formatted wrf-hydro output from Pocono Basin simulation\n",
    "        qlat_input_file = os.path.join(\n",
    "            root, r\"test/input/geo/PoconoSampleData2/Pocono_ql_testsamp1_nwm_mc.csv\"\n",
    "        )\n",
    "    if showtiming:\n",
    "        program_start_time = time.time()\n",
    "    if verbose:\n",
    "        print(f\"begin program t-route ...\")\n",
    "\n",
    "    # STEP 1: Read the supernetwork dataset and build the connections graph\n",
    "    if verbose:\n",
    "        print(\"creating supernetwork connections set\")\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "\n",
    "    if supernetwork_parameters:\n",
    "        supernetwork_values = nnu.get_nhd_connections(\n",
    "            supernetwork_parameters=supernetwork_parameters,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        test_folder = os.path.join(root, r\"test\")\n",
    "        geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "        supernetwork_parameters, supernetwork_values = nnu.set_networks(\n",
    "            supernetwork=supernetwork,\n",
    "            geo_input_folder=geo_input_folder,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "        waterbody_parameters = nnu.set_waterbody_parameters(\n",
    "            supernetwork=supernetwork,\n",
    "            geo_input_folder=geo_input_folder,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"supernetwork connections set complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    connections = supernetwork_values[0]\n",
    "    # STEP 2: Separate the networks and build the sub-graph of reaches within each network\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"organizing connections into reaches ...\")\n",
    "    networks = nru.compose_networks(\n",
    "        supernetwork_values,\n",
    "        break_network_at_waterbodies=break_network_at_waterbodies,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "        showtiming=showtiming,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"reach organization complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 3: Organize Network for Waterbodies\n",
    "    if break_network_at_waterbodies:\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"reading waterbody parameter file ...\")\n",
    "\n",
    "        ## STEP 3a: Read waterbody parameter file\n",
    "        waterbodies_values = supernetwork_values[12]\n",
    "        waterbodies_segments = supernetwork_values[13]\n",
    "        connections_tailwaters = supernetwork_values[4]\n",
    "\n",
    "        waterbodies_df = nio.read_waterbody_df(waterbody_parameters, waterbodies_values,)\n",
    "        waterbodies_df = waterbodies_df.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "\n",
    "        nru.order_networks(connections, networks, connections_tailwaters)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"waterbodies complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "\n",
    "        ## STEP 3b: Order subnetworks above and below reservoirs\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"ordering waterbody subnetworks ...\")\n",
    "\n",
    "        max_network_seqorder = -1\n",
    "        for network in networks:\n",
    "            max_network_seqorder = max(\n",
    "                networks[network][\"network_seqorder\"], max_network_seqorder\n",
    "            )\n",
    "        ordered_networks = {}\n",
    "\n",
    "        for terminal_segment, network in networks.items():\n",
    "            if network[\"network_seqorder\"] not in ordered_networks:\n",
    "                ordered_networks[network[\"network_seqorder\"]] = []\n",
    "            ordered_networks[network[\"network_seqorder\"]].append(\n",
    "                (terminal_segment, network)\n",
    "            )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"ordering waterbody subnetworks complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "\n",
    "    else:\n",
    "        # If we are not splitting the networks, we can put them all in one order\n",
    "        max_network_seqorder = 0\n",
    "        ordered_networks = {}\n",
    "        ordered_networks[0] = [\n",
    "            (terminal_segment, network) for terminal_segment, network in networks.items()\n",
    "        ]\n",
    "\n",
    "    if do_network_analysis_only:\n",
    "        sys.exit()\n",
    "\n",
    "    if break_network_at_waterbodies:\n",
    "        ## STEP 3c: Handle Waterbody Initial States\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"setting waterbody initial states ...\")\n",
    "\n",
    "        if wrf_hydro_waterbody_restart_file:\n",
    "\n",
    "            waterbody_initial_states_df = nio.get_reservoir_restart_from_wrf_hydro(\n",
    "                wrf_hydro_waterbody_restart_file,\n",
    "                wrf_hydro_waterbody_ID_crosswalk_file,\n",
    "                wrf_hydro_waterbody_ID_crosswalk_file_field_name,\n",
    "                wrf_hydro_waterbody_crosswalk_filter_file,\n",
    "                wrf_hydro_waterbody_crosswalk_filter_file_field_name,\n",
    "            )\n",
    "        else:\n",
    "            # TODO: Consider adding option to read cold state from route-link file\n",
    "            waterbody_initial_ds_flow_const = 0.0\n",
    "            waterbody_initial_depth_const = 0.0\n",
    "            # Set initial states from cold-state\n",
    "            waterbody_initial_states_df = pd.DataFrame(\n",
    "                0, index=waterbodies_df.index, columns=[\"qd0\", \"h0\",], dtype=\"float32\"\n",
    "            )\n",
    "            # TODO: This assignment could probably by done in the above call\n",
    "            waterbody_initial_states_df[\"qd0\"] = waterbody_initial_ds_flow_const\n",
    "            waterbody_initial_states_df[\"h0\"] = waterbody_initial_depth_const\n",
    "            waterbody_initial_states_df[\"index\"] = range(len(waterbody_initial_states_df))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"waterbody initial states complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "    # STEP 4: Handle Channel Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting channel initial states ...\")\n",
    "\n",
    "    if wrf_hydro_channel_restart_file:\n",
    "\n",
    "        channel_initial_states_df = nio.get_stream_restart_from_wrf_hydro(\n",
    "            wrf_hydro_channel_restart_file,\n",
    "            wrf_hydro_channel_ID_crosswalk_file,\n",
    "            wrf_hydro_channel_ID_crosswalk_file_field_name,\n",
    "            wrf_hydro_channel_restart_upstream_flow_field_name,\n",
    "            wrf_hydro_channel_restart_downstream_flow_field_name,\n",
    "            wrf_hydro_channel_restart_depth_flow_field_name,\n",
    "        )\n",
    "    else:\n",
    "        # TODO: Consider adding option to read cold state from route-link file\n",
    "        channel_initial_us_flow_const = 0.0\n",
    "        channel_initial_ds_flow_const = 0.0\n",
    "        channel_initial_depth_const = 0.0\n",
    "        # Set initial states from cold-state\n",
    "        channel_initial_states_df = pd.DataFrame(\n",
    "            0, index=connections.keys(), columns=[\"qu0\", \"qd0\", \"h0\",], dtype=\"float32\"\n",
    "        )\n",
    "        channel_initial_states_df[\"qu0\"] = channel_initial_us_flow_const\n",
    "        channel_initial_states_df[\"qd0\"] = channel_initial_ds_flow_const\n",
    "        channel_initial_states_df[\"h0\"] = channel_initial_depth_const\n",
    "        channel_initial_states_df[\"index\"] = range(len(channel_initial_states_df))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"channel initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 5: Read (or set) QLateral Inputs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"creating qlateral array ...\")\n",
    "\n",
    "    # initialize qlateral dict\n",
    "    qlateral = {}\n",
    "\n",
    "    if qlat_input_folder:\n",
    "        qlat_files = []\n",
    "        for pattern in qlat_file_pattern_filter:\n",
    "            qlat_files.extend(glob.glob(qlat_input_folder + pattern))\n",
    "        qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "            qlat_files=qlat_files,\n",
    "            index_col=qlat_file_index_col,\n",
    "            value_col=qlat_file_value_col,\n",
    "        )\n",
    "\n",
    "    elif qlat_input_file:\n",
    "        qlat_df = nio.get_ql_from_csv(qlat_input_file)\n",
    "\n",
    "    else:\n",
    "        qlat_df = pd.DataFrame(\n",
    "            qlat_const, index=connections.keys(), columns=range(nts), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "    for index, row in qlat_df.iterrows():\n",
    "        qlateral[index] = row.tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"qlateral array complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 6: Sort the ordered networks\n",
    "    if sort_networks:\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"sorting the ordered networks ...\")\n",
    "\n",
    "        for nsq in range(max_network_seqorder, -1, -1):\n",
    "            sort_ordered_network(ordered_networks[nsq], True)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"sorting complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "    # Define the pool after we create the static global objects (and collect the garbage)\n",
    "    if parallel_compute:\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "        pool = multiprocessing.Pool(cpu_pool)\n",
    "\n",
    "    flowveldepth_connect = (\n",
    "        {}\n",
    "    )  # dict to contain values to transfer from upstream to downstream networks\n",
    "    ################### Main Execution Loop across ordered networks\n",
    "    if showtiming:\n",
    "        main_start_time = time.time()\n",
    "    if verbose:\n",
    "        print(f\"executing routing computation ...\")\n",
    "\n",
    "    compute_network_func = tr.compute_network\n",
    "\n",
    "    tr.connections_g = connections\n",
    "    tr.networks_g = networks\n",
    "    tr.qlateral_g = qlateral\n",
    "    tr.waterbodies_df_g = waterbodies_df\n",
    "    tr.waterbody_initial_states_df_g = waterbody_initial_states_df\n",
    "    tr.channel_initial_states_df_g = channel_initial_states_df\n",
    "\n",
    "    progress_count = 0\n",
    "    percentage_complete = True\n",
    "    if percentage_complete:\n",
    "        for nsq in range(max_network_seqorder, -1, -1):\n",
    "            for terminal_segment, network in ordered_networks[nsq]:\n",
    "                progress_count += len(network[\"all_segments\"])\n",
    "        pbar = tqdm(total=(progress_count))\n",
    "\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "\n",
    "        if parallel_compute:\n",
    "            nslist = []\n",
    "        results = []\n",
    "\n",
    "        current_index_total = 0\n",
    "\n",
    "        for terminal_segment, network in ordered_networks[nsq]:\n",
    "\n",
    "            if percentage_complete:\n",
    "                if current_index_total == 0:\n",
    "                    pbar.update(0)\n",
    "\n",
    "            if break_network_at_waterbodies:\n",
    "                waterbody = waterbodies_segments.get(terminal_segment)\n",
    "            else:\n",
    "                waterbody = None\n",
    "            if not parallel_compute:  # serial execution\n",
    "                if showtiming:\n",
    "                    start_time = time.time()\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"routing ordered reaches for terminal segment {terminal_segment} ...\"\n",
    "                    )\n",
    "\n",
    "                results.append(\n",
    "                    compute_network_func(\n",
    "                        flowveldepth_connect=flowveldepth_connect,\n",
    "                        terminal_segment=terminal_segment,\n",
    "                        supernetwork_parameters=supernetwork_parameters,\n",
    "                        waterbody_parameters=waterbody_parameters,\n",
    "                        waterbody=waterbody,\n",
    "                        nts=nts,\n",
    "                        dt=dt,\n",
    "                        qts_subdivisions=qts_subdivisions,\n",
    "                        verbose=verbose,\n",
    "                        debuglevel=debuglevel,\n",
    "                        csv_output=csv_output,\n",
    "                        nc_output_folder=nc_output_folder,\n",
    "                        assume_short_ts=assume_short_ts,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if showtiming:\n",
    "                    print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "                if percentage_complete:\n",
    "                    pbar.update(len(network[\"all_segments\"]))\n",
    "\n",
    "            else:  # parallel execution\n",
    "                nslist.append(\n",
    "                    [\n",
    "                        flowveldepth_connect,\n",
    "                        terminal_segment,\n",
    "                        supernetwork_parameters,  # TODO: This should probably be global...\n",
    "                        waterbody_parameters,\n",
    "                        waterbody,\n",
    "                        nts,\n",
    "                        dt,\n",
    "                        qts_subdivisions,\n",
    "                        verbose,\n",
    "                        debuglevel,\n",
    "                        csv_output,\n",
    "                        nc_output_folder,\n",
    "                        assume_short_ts,\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        if parallel_compute:\n",
    "            if verbose:\n",
    "                print(f\"routing ordered reaches for networks of order {nsq} ... \")\n",
    "            if debuglevel <= -2:\n",
    "                print(f\"reaches to be routed include:\")\n",
    "                print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "            # with pool:\n",
    "            # with multiprocessing.Pool() as pool:\n",
    "            results = pool.starmap(compute_network_func, nslist)\n",
    "\n",
    "            if showtiming:\n",
    "                print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "            if percentage_complete:\n",
    "                pbar.update(\n",
    "                    sum(\n",
    "                        len(network[1][\"all_segments\"]) for network in ordered_networks[nsq]\n",
    "                    )\n",
    "                )\n",
    "                # print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "\n",
    "        max_courant = 0\n",
    "        maxa = []\n",
    "        for result in results:\n",
    "            for seg in result:\n",
    "                maxa.extend(result[seg][:, 8:9])\n",
    "        max_courant = max(maxa)\n",
    "        print(f\"max_courant: {max_courant}\")\n",
    "\n",
    "        if (\n",
    "            nsq > 0\n",
    "        ):  # We skip this step for zero-order networks, i.e., those that have no downstream dependents\n",
    "            flowveldepth_connect = (\n",
    "                {}\n",
    "            )  # There is no need to preserve previously passed on values -- so we clear the dictionary\n",
    "            for i, (terminal_segment, network) in enumerate(ordered_networks[nsq]):\n",
    "                # seg = network[\"reaches\"][network[\"terminal_reach\"]][\"reach_tail\"]\n",
    "                seg = terminal_segment\n",
    "                flowveldepth_connect[seg] = {}\n",
    "                flowveldepth_connect[seg] = results[i][seg]\n",
    "                # TODO: The value passed here could be much more specific to\n",
    "                # TODO: exactly and only the most recent time step for the passing reach\n",
    "\n",
    "    if parallel_compute:\n",
    "        pool.close()\n",
    "\n",
    "    if percentage_complete:\n",
    "        pbar.close()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordered reach computation complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - main_start_time))\n",
    "    if verbose:\n",
    "        print(\"program complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - program_start_time))\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_results_new = {}\n",
    "    seg_courant_maxes = []\n",
    "    time = []\n",
    "    flowval = []  # flowval\n",
    "    velval_list = []  # velval\n",
    "    depthval = []  # depthval\n",
    "    qlatval = []  # qlatval\n",
    "    storageval = []  # storageval\n",
    "    qlatCumval = []  # qlatCumval\n",
    "    kinCelerity = []  # ck\n",
    "    courant = []  # cn\n",
    "    X = []  # X\n",
    "\n",
    "    for result in results:\n",
    "        all_results_new.update(result)\n",
    "    \n",
    "    # print(all_results[8780801][1][0])\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # print(all_results)\n",
    "\n",
    "    for key, data in all_results_new.items():\n",
    "        time.extend(data[:, 0])  # time\n",
    "        flowval.extend(data[:, 1])  # flowval\n",
    "        velval_list.extend(data[:, 2])  # velval\n",
    "        depthval.extend(data[:, 3])  # depthval\n",
    "        qlatval.extend(data[:, 4])  # qlatval\n",
    "        storageval.extend(data[:, 5])  # storageval\n",
    "        qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "        kinCelerity.extend(data[:, 7])  # ck\n",
    "        courant.extend(data[:, 8])  # cn\n",
    "        X.extend(data[:, 9])  # X\n",
    "#     print(all_results_new)\n",
    "    single_seg_length = len(all_results_new[933020089][:, 0])\n",
    "\n",
    "    if c_i == \"florence_933020089_dt300.yaml\":\n",
    "        single_seg_length_300 = single_seg_length\n",
    "    else:\n",
    "        single_seg_length_60 = single_seg_length\n",
    "#     else:\n",
    "#         single_seg_length_10 = single_seg_length\n",
    "#     print(single_seg_length_300,single_seg_length_60)\n",
    "    # single_seg_length * 611\n",
    "\n",
    "    key_index = all_results.keys()\n",
    "    key_index = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            itertools.repeat(x, single_seg_length) for x in key_index\n",
    "        )\n",
    "    )\n",
    "    data = {\n",
    "        \"key_index\": list(key_index),\n",
    "        \"time\": list(time),\n",
    "        \"flowval\": list(flowval),\n",
    "        \"velval_list\": list(velval_list),\n",
    "        \"depthval\": list(depthval),\n",
    "        \"qlatval\": list(qlatval),\n",
    "        \"storageval\": list(storageval),\n",
    "        \"qlatCumval\": list(qlatCumval),\n",
    "        \"kinCelerity\": list(kinCelerity),\n",
    "        \"courant\": list(courant),\n",
    "        \"X\": list(X),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index(\"key_index\")\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(\"key_index\")\n",
    "\n",
    "\n",
    "    seg_list = []\n",
    "    seg_courant_maxes = []\n",
    "    for seg in all_results_new:\n",
    "        seg_list.append(seg)\n",
    "        seg_courant_maxes.append(max(all_results_new[seg][:, tr.courant_index]))\n",
    "    zipped = zip(seg_list, seg_courant_maxes)\n",
    "    zipped = list(zipped)\n",
    "    res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "    # A.sort(reverse=True)\n",
    "    res = (res)[:3]\n",
    "    # print((res)[:25])\n",
    "\n",
    "    major_segments = []\n",
    "    for x, y in res[:3]:\n",
    "        major_segments.append(x)\n",
    "    # major_segments\n",
    "\n",
    "    df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "\n",
    "    if c_i == \"florence_933020089_dt300.yaml\":\n",
    "        df_indexed_300 = df_filtered.reset_index()\n",
    "    else:\n",
    "        df_indexed_60 = df_filtered.reset_index()\n",
    "    print(df_indexed_300,df_indexed_60)\n",
    "#     else:\n",
    "#         df_indexed_10 = df_filtered.reset_index()\n",
    "\n",
    "test_chart = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "# test_chart = go.FigureWidget()\n",
    "for x in range(0,len(major_segments)):\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment flowval \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment flowval \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"courant\"],secondary_y=True,\n",
    "        name=\"segment courant \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"courant\"],secondary_y=True,\n",
    "        name=\"segment courant \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "    )\n",
    "# test_chart.update_yaxes(title_text=\"<b>primary</b> yaxis title\", secondary_y=False)\n",
    "# test_chart.update_yaxes(title_text=\"<b>secondary</b> yaxis title\", secondary_y=True)\n",
    "\n",
    "test_chart.layout.title = \"Timestep Chart 300, 60\"\n",
    "plot(test_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "test_chart = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "# test_chart = go.FigureWidget()\n",
    "\n",
    "for x in range(0,len(major_segments)):\n",
    "    r = lambda: random.randint(0,255)\n",
    "    temp_color1 = ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "    temp_color2 = ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "#     print(temp_color1,temp_color2)\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"flowval\"],line_color=temp_color1,\n",
    "        name=\"segment flowval \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"flowval\"],line_color=temp_color2,\n",
    "        name=\"segment flowval \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"courant\"],line_color=temp_color1,secondary_y=True,\n",
    "        name=\"segment courant \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"courant\"],\n",
    "        line_color=temp_color2,\n",
    "        secondary_y=True,\n",
    "        name=\"segment courant \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "    )\n",
    "test_chart.update_yaxes(title_text=\"Flow Value\", secondary_y=False)\n",
    "# test_chart.update_yaxes(title_text=\"Courant Value\", secondary_y=True)\n",
    "test_chart.update_xaxes(title_text=\"Time Step\")\n",
    "test_chart.layout.title = \"Timestep Chart 300, 60\"\n",
    "plot(test_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#A79870'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "r = lambda: random.randint(0,255)\n",
    "gen1 = ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "gen1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths = df_indexed_300\n",
    "lengths_temp = []\n",
    "for i, j in df_lengths.iterrows(): \n",
    "    lengths_temp.append(supernetwork_values[0][j['key_index']]['length'])\n",
    "df_lengths['lengths'] = pd.Series(lengths_temp, index=df_lengths.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lengths.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths = df_lengths.reset_index(drop=True)\n",
    "df_lengths = df_lengths.set_index('key_index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(major_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = []\n",
    "courant_list = []\n",
    "flowval_list = []\n",
    "for i in major_segments:\n",
    "    length_list.append(df_lengths.loc[i]['lengths'][:1].values[0])\n",
    "    courant_list.append(df_lengths.loc[i]['courant'][:1].values[0])\n",
    "    flowval_list.append(df_lengths.loc[i]['flowval'][:1].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.227744102478027,\n",
       " 8.375633239746094,\n",
       " 1.4919893741607666,\n",
       " 3.5384578704833984,\n",
       " 2.722485065460205,\n",
       " 4.67125129699707,\n",
       " 1.958962321281433,\n",
       " 1.6834832429885864,\n",
       " 4.80889892578125,\n",
       " 1.0520790815353394,\n",
       " 0.5376074314117432,\n",
       " 0.49882617592811584,\n",
       " 0.17622336745262146,\n",
       " 2.33585524559021,\n",
       " 0.43409964442253113,\n",
       " 1.903039813041687,\n",
       " 0.3100087344646454,\n",
       " 0.4152270555496216,\n",
       " 1.5580898523330688,\n",
       " 0.3247401714324951,\n",
       " 0.6226049661636353,\n",
       " 0.6581174731254578,\n",
       " 0.735342800617218,\n",
       " 0.35107898712158203,\n",
       " 0.2029656171798706]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         8777735\n",
       "1         8777735\n",
       "2         8777735\n",
       "3         8777735\n",
       "4         8777735\n",
       "           ...   \n",
       "359995    8780751\n",
       "359996    8780751\n",
       "359997    8780751\n",
       "359998    8780751\n",
       "359999    8780751\n",
       "Name: key_index, Length: 360000, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indexed_60['key_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table1 = zip(length_list,major_segments)\n",
    "# table2 = sorted(table1, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = length_list\n",
    "a = major_segments\n",
    "c = courant_list\n",
    "d = flowval_list\n",
    "res = \"\\n\".join(\"{}      {}      {}       {}\".format(w   , x  , y   , z  ) for w, x, y, z in sorted(zip(c, d, b, a),reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.227744102478027      0.004060585051774979      10.0       933020027\n",
      "8.375633239746094      0.0041962782852351665      11.0       8777735\n",
      "4.80889892578125      6.211640357971191      5.0       933020058\n",
      "4.67125129699707      0.005805434659123421      17.0       933020061\n",
      "3.5384578704833984      2.412903308868408      5.0       8778581\n",
      "2.722485065460205      0.0026232698000967503      17.0       933020059\n",
      "2.33585524559021      0.6656259894371033      114.0       8778021\n",
      "1.958962321281433      0.008839867077767849      54.0       8780597\n",
      "1.903039813041687      1.610382318496704      166.0       8777867\n",
      "1.6834832429885864      0.0018756598001345992      28.0       933020020\n",
      "1.5580898523330688      1.6185015439987183      177.0       8777861\n",
      "1.4919893741607666      6.569494416908128e-06      11.0       933020017\n",
      "1.0520790815353394      0.009235578589141369      57.0       933020023\n",
      "0.735342800617218      0.0011249413946643472      46.0       933020050\n",
      "0.6581174731254578      0.14307114481925964      23.0       8779003\n",
      "0.6226049661636353      0.05031493678689003      152.0       8780607\n",
      "0.5376074314117432      0.00017483932606410235      42.0       8777485\n",
      "0.49882617592811584      0.006104861386120319      14.0       933020036\n",
      "0.43409964442253113      0.007608350366353989      164.0       8777339\n",
      "0.4152270555496216      0.0002334142627660185      75.0       8780495\n",
      "0.35107898712158203      0.0015799697721377015      91.0       8780751\n",
      "0.3247401714324951      0.0027858661487698555      145.0       8777481\n",
      "0.3100087344646454      6.194291199790314e-05      54.0       8777477\n",
      "0.2029656171798706      0.00011678047303576022      172.0       8778947\n",
      "0.17622336745262146      5.3605999710271135e-05      126.0       8778795\n"
     ]
    }
   ],
   "source": [
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chart = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "test_chart.add_scatter(\n",
    "    x=length_list,\n",
    "    y=courant_list,\n",
    "    name=\"courant\" + \" \" + str(300),\n",
    "    mode='markers',  \n",
    ")\n",
    "test_chart.add_scatter(\n",
    "    x=length_list,\n",
    "    y=flowval_list,\n",
    "    name=\"flowval\" + \" \" + str(300),\n",
    "    mode='markers',  \n",
    ")\n",
    "# test_chart.update_yaxes(title_text=\"Flow Value\", secondary_y=False)\n",
    "# test_chart.update_yaxes(title_text=\"Courant Value\", secondary_y=True)\n",
    "test_chart.update_xaxes(title_text=\"Length\", )\n",
    "\n",
    "test_chart.layout.title = \"Top 25 Values by Length - 300 \"\n",
    "plot(test_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
