{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic imports and path management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "root = pathlib.Path(\"../../\").resolve()\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v02\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v01\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_routing_v01\")))\n",
    "sys.path.append(\".\")\n",
    "import nhd_io as nio\n",
    "import compute_nhd_routing_SingleSeg as tr\n",
    "import nhd_network_utilities_v01 as nnu\n",
    "import nhd_reach_utilities as nru\n",
    "\n",
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt60.yaml\"\n",
    "run_pocono2_test = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the primary data input from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(custom_file)\n"
     ]
    }
   ],
   "source": [
    "supernetwork_parameters = None\n",
    "waterbody_parameters = None\n",
    "if custom_input_file:\n",
    "    (\n",
    "        supernetwork_parameters,\n",
    "        waterbody_parameters,\n",
    "        forcing_parameters,\n",
    "        restart_parameters,\n",
    "        output_parameters,\n",
    "        run_parameters,\n",
    "    ) = nio.read_custom_input(custom_input_folder.joinpath(custom_input_file))\n",
    "\n",
    "    break_network_at_waterbodies = run_parameters.get(\n",
    "        \"break_network_at_waterbodies\", None\n",
    "    )\n",
    "\n",
    "    dt = run_parameters.get(\"dt\", None)\n",
    "    nts = run_parameters.get(\"nts\", None)\n",
    "    qts_subdivisions = run_parameters.get(\"qts_subdivisions\", None)\n",
    "    debuglevel = -1 * int(run_parameters.get(\"debuglevel\", 0))\n",
    "    verbose = run_parameters.get(\"verbose\", None)\n",
    "    showtiming = run_parameters.get(\"showtiming\", None)\n",
    "    percentage_complete = run_parameters.get(\"percentage_complete\", None)\n",
    "    do_network_analysis_only = run_parameters.get(\"do_network_analysis_only\", None)\n",
    "    assume_short_ts = run_parameters.get(\"assume_short_ts\", None)\n",
    "    parallel_compute = run_parameters.get(\"parallel_compute\", None)\n",
    "    cpu_pool = run_parameters.get(\"cpu_pool\", None)\n",
    "    sort_networks = run_parameters.get(\"sort_networks\", None)\n",
    "\n",
    "    csv_output = output_parameters.get(\"csv_output\", None)\n",
    "    nc_output_folder = output_parameters.get(\"nc_output_folder\", None)\n",
    "\n",
    "    qlat_const = forcing_parameters.get(\"qlat_const\", None)\n",
    "    qlat_input_file = forcing_parameters.get(\"qlat_input_file\", None)\n",
    "    qlat_input_folder = forcing_parameters.get(\"qlat_input_folder\", None)\n",
    "    qlat_file_pattern_filter = forcing_parameters.get(\"qlat_file_pattern_filter\", None)\n",
    "    qlat_file_index_col = forcing_parameters.get(\"qlat_file_index_col\", None)\n",
    "    qlat_file_value_col = forcing_parameters.get(\"qlat_file_value_col\", None)\n",
    "\n",
    "    wrf_hydro_channel_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_upstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_upstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_downstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_downstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_depth_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_depth_flow_field_name\", None\n",
    "    )\n",
    "\n",
    "    wrf_hydro_waterbody_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file_field_name\", None\n",
    "    )\n",
    "\n",
    "# Any specific commandline arguments will override the file\n",
    "# TODO: There are probably some pathological collisions that could\n",
    "# arise from this ordering ... check these out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_pocono2_test:\n",
    "    if verbose:\n",
    "        print(\"running test case for Pocono_TEST2 domain\")\n",
    "    # Overwrite the following test defaults\n",
    "    supernetwork = \"Pocono_TEST2\"\n",
    "    break_network_at_waterbodies = False\n",
    "    qts_subdivisions = 1  # change qts_subdivisions = 1 as  default\n",
    "    dt = 300 / qts_subdivisions\n",
    "    nts = 144 * qts_subdivisions\n",
    "    csv_output = {\"csv_output_folder\": os.path.join(root, \"test\", \"output\", \"text\")}\n",
    "    nc_output_folder = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "    # test 1. Take lateral flow from re-formatted wrf-hydro output from Pocono Basin simulation\n",
    "    qlat_input_file = os.path.join(\n",
    "        root, r\"test/input/geo/PoconoSampleData2/Pocono_ql_testsamp1_nwm_mc.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.03888821601867676 seconds.\n"
     ]
    }
   ],
   "source": [
    "if showtiming:\n",
    "    program_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"begin program t-route ...\")\n",
    "\n",
    "# STEP 1: Read the supernetwork dataset and build the connections graph\n",
    "if verbose:\n",
    "    print(\"creating supernetwork connections set\")\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "\n",
    "if supernetwork_parameters:\n",
    "    supernetwork_values = nnu.get_nhd_connections(\n",
    "        supernetwork_parameters=supernetwork_parameters,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    test_folder = os.path.join(root, r\"test\")\n",
    "    geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "    supernetwork_parameters, supernetwork_values = nnu.set_networks(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "    waterbody_parameters = nnu.set_waterbody_parameters(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "if verbose:\n",
    "    print(\"supernetwork connections set complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "connections = supernetwork_values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.004379987716674805 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Separate the networks and build the sub-graph of reaches within each network\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"organizing connections into reaches ...\")\n",
    "networks = nru.compose_networks(\n",
    "    supernetwork_values,\n",
    "    break_network_at_waterbodies=break_network_at_waterbodies,\n",
    "    verbose=False,\n",
    "    debuglevel=debuglevel,\n",
    "    showtiming=showtiming,\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(\"reach organization complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.017271041870117188 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 3.7670135498046875e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.01991748809814453 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Organize Network for Waterbodies\n",
    "if break_network_at_waterbodies:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"reading waterbody parameter file ...\")\n",
    "\n",
    "    ## STEP 3a: Read waterbody parameter file\n",
    "    waterbodies_values = supernetwork_values[12]\n",
    "    waterbodies_segments = supernetwork_values[13]\n",
    "    connections_tailwaters = supernetwork_values[4]\n",
    "\n",
    "    waterbodies_df = nio.read_waterbody_df(waterbody_parameters, waterbodies_values,)\n",
    "    waterbodies_df = waterbodies_df.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "\n",
    "    nru.order_networks(connections, networks, connections_tailwaters)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbodies complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "    ## STEP 3b: Order subnetworks above and below reservoirs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks ...\")\n",
    "\n",
    "    max_network_seqorder = -1\n",
    "    for network in networks:\n",
    "        max_network_seqorder = max(\n",
    "            networks[network][\"network_seqorder\"], max_network_seqorder\n",
    "        )\n",
    "    ordered_networks = {}\n",
    "\n",
    "    for terminal_segment, network in networks.items():\n",
    "        if network[\"network_seqorder\"] not in ordered_networks:\n",
    "            ordered_networks[network[\"network_seqorder\"]] = []\n",
    "        ordered_networks[network[\"network_seqorder\"]].append(\n",
    "            (terminal_segment, network)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "else:\n",
    "    # If we are not splitting the networks, we can put them all in one order\n",
    "    max_network_seqorder = 0\n",
    "    ordered_networks = {}\n",
    "    ordered_networks[0] = [\n",
    "        (terminal_segment, network) for terminal_segment, network in networks.items()\n",
    "    ]\n",
    "\n",
    "if do_network_analysis_only:\n",
    "    sys.exit()\n",
    "\n",
    "if break_network_at_waterbodies:\n",
    "    ## STEP 3c: Handle Waterbody Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting waterbody initial states ...\")\n",
    "\n",
    "    if wrf_hydro_waterbody_restart_file:\n",
    "\n",
    "        waterbody_initial_states_df = nio.get_reservoir_restart_from_wrf_hydro(\n",
    "            wrf_hydro_waterbody_restart_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file_field_name,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file_field_name,\n",
    "        )\n",
    "    else:\n",
    "        # TODO: Consider adding option to read cold state from route-link file\n",
    "        waterbody_initial_ds_flow_const = 0.0\n",
    "        waterbody_initial_depth_const = 0.0\n",
    "        # Set initial states from cold-state\n",
    "        waterbody_initial_states_df = pd.DataFrame(\n",
    "            0, index=waterbodies_df.index, columns=[\"qd0\", \"h0\",], dtype=\"float32\"\n",
    "        )\n",
    "        # TODO: This assignment could probably by done in the above call\n",
    "        waterbody_initial_states_df[\"qd0\"] = waterbody_initial_ds_flow_const\n",
    "        waterbody_initial_states_df[\"h0\"] = waterbody_initial_depth_const\n",
    "        waterbody_initial_states_df[\"index\"] = range(len(waterbody_initial_states_df))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbody initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.02246999740600586 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Handle Channel Initial States\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"setting channel initial states ...\")\n",
    "\n",
    "if wrf_hydro_channel_restart_file:\n",
    "\n",
    "    channel_initial_states_df = nio.get_stream_restart_from_wrf_hydro(\n",
    "        wrf_hydro_channel_restart_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file_field_name,\n",
    "        wrf_hydro_channel_restart_upstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_downstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_depth_flow_field_name,\n",
    "    )\n",
    "else:\n",
    "    # TODO: Consider adding option to read cold state from route-link file\n",
    "    channel_initial_us_flow_const = 0.0\n",
    "    channel_initial_ds_flow_const = 0.0\n",
    "    channel_initial_depth_const = 0.0\n",
    "    # Set initial states from cold-state\n",
    "    channel_initial_states_df = pd.DataFrame(\n",
    "        0, index=connections.keys(), columns=[\"qu0\", \"qd0\", \"h0\",], dtype=\"float32\"\n",
    "    )\n",
    "    channel_initial_states_df[\"qu0\"] = channel_initial_us_flow_const\n",
    "    channel_initial_states_df[\"qd0\"] = channel_initial_ds_flow_const\n",
    "    channel_initial_states_df[\"h0\"] = channel_initial_depth_const\n",
    "    channel_initial_states_df[\"index\"] = range(len(channel_initial_states_df))\n",
    "\n",
    "if verbose:\n",
    "    print(\"channel initial states complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 6.396091938018799 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Read (or set) QLateral Inputs\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"creating qlateral array ...\")\n",
    "\n",
    "# initialize qlateral dict\n",
    "qlateral = {}\n",
    "\n",
    "if qlat_input_folder:\n",
    "    qlat_files = []\n",
    "    for pattern in qlat_file_pattern_filter:\n",
    "        qlat_files.extend(glob.glob(qlat_input_folder + pattern))\n",
    "    qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "        qlat_files=qlat_files,\n",
    "        index_col=qlat_file_index_col,\n",
    "        value_col=qlat_file_value_col,\n",
    "    )\n",
    "\n",
    "elif qlat_input_file:\n",
    "    qlat_df = nio.get_ql_from_csv(qlat_input_file)\n",
    "\n",
    "else:\n",
    "    qlat_df = pd.DataFrame(\n",
    "        qlat_const, index=connections.keys(), columns=range(nts), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "for index, row in qlat_df.iterrows():\n",
    "    qlateral[index] = row.tolist()\n",
    "\n",
    "if verbose:\n",
    "    print(\"qlateral array complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Sort the ordered networks\n",
    "if sort_networks:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"sorting the ordered networks ...\")\n",
    "\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        sort_ordered_network(ordered_networks[nsq], True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"sorting complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the pool after we create the static global objects (and collect the garbage)\n",
    "if parallel_compute:\n",
    "    import gc\n",
    "\n",
    "    gc.collect()\n",
    "    pool = multiprocessing.Pool(cpu_pool)\n",
    "\n",
    "flowveldepth_connect = (\n",
    "    {}\n",
    ")  # dict to contain values to transfer from upstream to downstream networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1108 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 467/1108 [00:35<00:48, 13.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 35.58297324180603 seconds.\n",
      "max_courant: [5.51265717]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 467/1108 [00:48<00:48, 13.19it/s]\u001b[A\n",
      " 45%|████▌     | 499/1108 [00:49<01:53,  5.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 49.79691505432129 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1108/1108 [01:50<00:00,  6.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 111.17425584793091 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [01:54<00:00,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [25.36383247]\n",
      "ordered reach computation complete\n",
      "... in 114.53386664390564 seconds.\n",
      "program complete\n",
      "... in 121.2260513305664 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################### Main Execution Loop across ordered networks\n",
    "if showtiming:\n",
    "    main_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"executing routing computation ...\")\n",
    "\n",
    "compute_network_func = tr.compute_network\n",
    "\n",
    "tr.connections_g = connections\n",
    "tr.networks_g = networks\n",
    "tr.qlateral_g = qlateral\n",
    "tr.waterbodies_df_g = waterbodies_df\n",
    "tr.waterbody_initial_states_df_g = waterbody_initial_states_df\n",
    "tr.channel_initial_states_df_g = channel_initial_states_df\n",
    "\n",
    "progress_count = 0\n",
    "percentage_complete = True\n",
    "if percentage_complete:\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        for terminal_segment, network in ordered_networks[nsq]:\n",
    "            progress_count += len(network[\"all_segments\"])\n",
    "    pbar = tqdm(total=(progress_count))\n",
    "\n",
    "for nsq in range(max_network_seqorder, -1, -1):\n",
    "\n",
    "    if parallel_compute:\n",
    "        nslist = []\n",
    "    results = []\n",
    "\n",
    "    current_index_total = 0\n",
    "\n",
    "    for terminal_segment, network in ordered_networks[nsq]:\n",
    "\n",
    "        if percentage_complete:\n",
    "            if current_index_total == 0:\n",
    "                pbar.update(0)\n",
    "\n",
    "        if break_network_at_waterbodies:\n",
    "            waterbody = waterbodies_segments.get(terminal_segment)\n",
    "        else:\n",
    "            waterbody = None\n",
    "        if not parallel_compute:  # serial execution\n",
    "            if showtiming:\n",
    "                start_time = time.time()\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"routing ordered reaches for terminal segment {terminal_segment} ...\"\n",
    "                )\n",
    "\n",
    "            results.append(\n",
    "                compute_network_func(\n",
    "                    flowveldepth_connect=flowveldepth_connect,\n",
    "                    terminal_segment=terminal_segment,\n",
    "                    supernetwork_parameters=supernetwork_parameters,\n",
    "                    waterbody_parameters=waterbody_parameters,\n",
    "                    waterbody=waterbody,\n",
    "                    nts=nts,\n",
    "                    dt=dt,\n",
    "                    qts_subdivisions=qts_subdivisions,\n",
    "                    verbose=verbose,\n",
    "                    debuglevel=debuglevel,\n",
    "                    csv_output=csv_output,\n",
    "                    nc_output_folder=nc_output_folder,\n",
    "                    assume_short_ts=assume_short_ts,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if showtiming:\n",
    "                print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "            if percentage_complete:\n",
    "                pbar.update(len(network[\"all_segments\"]))\n",
    "\n",
    "        else:  # parallel execution\n",
    "            nslist.append(\n",
    "                [\n",
    "                    flowveldepth_connect,\n",
    "                    terminal_segment,\n",
    "                    supernetwork_parameters,  # TODO: This should probably be global...\n",
    "                    waterbody_parameters,\n",
    "                    waterbody,\n",
    "                    nts,\n",
    "                    dt,\n",
    "                    qts_subdivisions,\n",
    "                    verbose,\n",
    "                    debuglevel,\n",
    "                    csv_output,\n",
    "                    nc_output_folder,\n",
    "                    assume_short_ts,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    if parallel_compute:\n",
    "        if verbose:\n",
    "            print(f\"routing ordered reaches for networks of order {nsq} ... \")\n",
    "        if debuglevel <= -2:\n",
    "            print(f\"reaches to be routed include:\")\n",
    "            print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "        # with pool:\n",
    "        # with multiprocessing.Pool() as pool:\n",
    "        results = pool.starmap(compute_network_func, nslist)\n",
    "\n",
    "        if showtiming:\n",
    "            print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "        if percentage_complete:\n",
    "            pbar.update(\n",
    "                sum(\n",
    "                    len(network[1][\"all_segments\"]) for network in ordered_networks[nsq]\n",
    "                )\n",
    "            )\n",
    "            # print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "\n",
    "    max_courant = 0\n",
    "    maxa = []\n",
    "    for result in results:\n",
    "        for seg in result:\n",
    "            maxa.extend(result[seg][:, 8:9])\n",
    "    max_courant = max(maxa)\n",
    "    print(f\"max_courant: {max_courant}\")\n",
    "\n",
    "    if (\n",
    "        nsq > 0\n",
    "    ):  # We skip this step for zero-order networks, i.e., those that have no downstream dependents\n",
    "        flowveldepth_connect = (\n",
    "            {}\n",
    "        )  # There is no need to preserve previously passed on values -- so we clear the dictionary\n",
    "        for i, (terminal_segment, network) in enumerate(ordered_networks[nsq]):\n",
    "            # seg = network[\"reaches\"][network[\"terminal_reach\"]][\"reach_tail\"]\n",
    "            seg = terminal_segment\n",
    "            flowveldepth_connect[seg] = {}\n",
    "            flowveldepth_connect[seg] = results[i][seg]\n",
    "            # TODO: The value passed here could be much more specific to\n",
    "            # TODO: exactly and only the most recent time step for the passing reach\n",
    "\n",
    "if parallel_compute:\n",
    "    pool.close()\n",
    "\n",
    "if percentage_complete:\n",
    "    pbar.close()\n",
    "\n",
    "if verbose:\n",
    "    print(\"ordered reach computation complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - main_start_time))\n",
    "if verbose:\n",
    "    print(\"program complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - program_start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the main dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results)\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "all_results = {}\n",
    "seg_courant_maxes = []\n",
    "time = []\n",
    "flowval = []  # flowval\n",
    "velval_list = []  # velval\n",
    "depthval = []  # depthval\n",
    "qlatval = []  # qlatval\n",
    "storageval = []  # storageval\n",
    "qlatCumval = []  # qlatCumval\n",
    "kinCelerity = []  # ck\n",
    "courant = []  # cn\n",
    "X = []  # X\n",
    "\n",
    "for result in results:\n",
    "    all_results.update(result)\n",
    "\n",
    "# print(all_results[8780801][1][0])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# print(all_results)\n",
    "\n",
    "for key, data in all_results.items():\n",
    "    time.extend(data[:, 0])  # time\n",
    "    flowval.extend(data[:, 1])  # flowval\n",
    "    velval_list.extend(data[:, 2])  # velval\n",
    "    depthval.extend(data[:, 3])  # depthval\n",
    "    qlatval.extend(data[:, 4])  # qlatval\n",
    "    storageval.extend(data[:, 5])  # storageval\n",
    "    qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "    kinCelerity.extend(data[:, 7])  # ck\n",
    "    courant.extend(data[:, 8])  # cn\n",
    "    X.extend(data[:, 9])  # X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8798400"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_seg_length = len(all_results[933020089][:, 0])\n",
    "single_seg_length * 611\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8798400"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034005</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-3.929017e-08</td>\n",
       "      <td>1.079874e-02</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>0.499495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-7.508788e-08</td>\n",
       "      <td>2.159748e-02</td>\n",
       "      <td>0.056322</td>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.499496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034044</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-1.082662e-07</td>\n",
       "      <td>3.239622e-02</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>0.017696</td>\n",
       "      <td>0.499496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-1.388253e-07</td>\n",
       "      <td>4.319496e-02</td>\n",
       "      <td>0.056336</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>0.499496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780801</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-1.667649e-07</td>\n",
       "      <td>5.399370e-02</td>\n",
       "      <td>0.056337</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>0.499496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863700.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135146e+06</td>\n",
       "      <td>1.368751e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863760.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135199e+06</td>\n",
       "      <td>1.368760e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863820.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135252e+06</td>\n",
       "      <td>1.368769e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863880.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135305e+06</td>\n",
       "      <td>1.368778e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8778465</td>\n",
       "      <td>863940.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>8.135357e+06</td>\n",
       "      <td>1.368787e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8798400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time   flowval  velval_list  depthval   qlatval    storageval  \\\n",
       "key_index                                                                      \n",
       "8780801         0.0  0.000180     0.034005  0.005051  0.000180 -3.929017e-08   \n",
       "8780801        60.0  0.000180     0.034037  0.005058  0.000180 -7.508788e-08   \n",
       "8780801       120.0  0.000180     0.034044  0.005060  0.000180 -1.082662e-07   \n",
       "8780801       180.0  0.000180     0.034046  0.005060  0.000180 -1.388253e-07   \n",
       "8780801       240.0  0.000180     0.034046  0.005060  0.000180 -1.667649e-07   \n",
       "...             ...       ...          ...       ...       ...           ...   \n",
       "8778465    863700.0  0.000036     0.000000  0.000000  0.149393  8.135146e+06   \n",
       "8778465    863760.0  0.000036     0.000000  0.000000  0.149393  8.135199e+06   \n",
       "8778465    863820.0  0.000036     0.000000  0.000000  0.149393  8.135252e+06   \n",
       "8778465    863880.0  0.000036     0.000000  0.000000  0.149393  8.135305e+06   \n",
       "8778465    863940.0  0.000036     0.000000  0.000000  0.149393  8.135357e+06   \n",
       "\n",
       "             qlatCumval  kinCelerity   courant         X  \n",
       "key_index                                                 \n",
       "8780801    1.079874e-02     0.056269  0.017676  0.499495  \n",
       "8780801    2.159748e-02     0.056322  0.017693  0.499496  \n",
       "8780801    3.239622e-02     0.056334  0.017696  0.499496  \n",
       "8780801    4.319496e-02     0.056336  0.017697  0.499496  \n",
       "8780801    5.399370e-02     0.056337  0.017697  0.499496  \n",
       "...                 ...          ...       ...       ...  \n",
       "8778465    1.368751e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368760e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368769e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368778e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.368787e+06     0.000000  0.000000  0.000000  \n",
       "\n",
       "[8798400 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_index = all_results.keys()\n",
    "key_index = list(\n",
    "    itertools.chain.from_iterable(\n",
    "        itertools.repeat(x, single_seg_length) for x in key_index\n",
    "    )\n",
    ")\n",
    "data = {\n",
    "    \"key_index\": list(key_index),\n",
    "    \"time\": list(time),\n",
    "    \"flowval\": list(flowval),\n",
    "    \"velval_list\": list(velval_list),\n",
    "    \"depthval\": list(depthval),\n",
    "    \"qlatval\": list(qlatval),\n",
    "    \"storageval\": list(storageval),\n",
    "    \"qlatCumval\": list(qlatCumval),\n",
    "    \"kinCelerity\": list(kinCelerity),\n",
    "    \"courant\": list(courant),\n",
    "    \"X\": list(X),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index(\"key_index\")\n",
    "df = df.reset_index()\n",
    "df = df.set_index(\"key_index\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-4.12.0-py2.py3-none-any.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: six in /home/jacob.hreha/anaconda3/lib/python3.7/site-packages (from plotly) (1.14.0)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11430 sha256=955fe8c56e0da1a48727c21349a3bdf87e4a3b4377f30b8a6947f02fff9ed733\n",
      "  Stored in directory: /home/jacob.hreha/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly\n",
      "Successfully installed plotly-4.12.0 retrying-1.3.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/jacob.hreha/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 25 courants based on our work this morning and their segment IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(933020027, 25.363832473754883), (8777735, 14.950478553771973), (933020017, 9.564001083374023), (8778581, 8.574037551879883), (933020059, 7.254691123962402), (933020061, 4.696855068206787), (8780597, 3.591726064682007), (933020020, 2.8707876205444336), (933020058, 2.4734983444213867), (933020023, 2.1059963703155518), (8777485, 1.860101580619812), (933020036, 1.6248382329940796), (8778795, 1.6150635480880737), (8778021, 1.4462398290634155), (8777339, 1.393180251121521), (8777867, 1.353600263595581), (8777477, 1.3393661975860596), (8780495, 1.3077224493026733), (8777861, 1.1583272218704224), (8777481, 1.149632215499878), (8780607, 1.0738232135772705), (8779003, 1.0580987930297852), (933020050, 1.0441739559173584), (8780751, 0.9917784929275513), (8778947, 0.9753884673118591)]\n"
     ]
    }
   ],
   "source": [
    "seg_list = []\n",
    "seg_courant_maxes = []\n",
    "for seg in all_results:\n",
    "    seg_list.append(seg)\n",
    "    seg_courant_maxes.append(max(all_results[seg][:, tr.courant_index]))\n",
    "zipped = zip(seg_list, seg_courant_maxes)\n",
    "zipped = list(zipped)\n",
    "res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "# A.sort(reverse=True)\n",
    "res = (res)[:25]\n",
    "print((res)[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of those IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[933020027,\n",
       " 8777735,\n",
       " 933020017,\n",
       " 8778581,\n",
       " 933020059,\n",
       " 933020061,\n",
       " 8780597,\n",
       " 933020020,\n",
       " 933020058,\n",
       " 933020023,\n",
       " 8777485,\n",
       " 933020036,\n",
       " 8778795,\n",
       " 8778021,\n",
       " 8777339,\n",
       " 8777867,\n",
       " 8777477,\n",
       " 8780495,\n",
       " 8777861,\n",
       " 8777481,\n",
       " 8780607,\n",
       " 8779003,\n",
       " 933020050,\n",
       " 8780751,\n",
       " 8778947]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_segments = []\n",
    "for x, y in res[:25]:\n",
    "    major_segments.append(x)\n",
    "major_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the above segment IDs from the original df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185580</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-6.722985e-08</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.307107</td>\n",
       "      <td>1.675127</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185576</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-4.190952e-08</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.307099</td>\n",
       "      <td>1.675087</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185573</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-4.627509e-08</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.307094</td>\n",
       "      <td>1.675061</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185570</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-6.810296e-08</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.307090</td>\n",
       "      <td>1.675035</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8777735</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-7.770723e-08</td>\n",
       "      <td>0.010456</td>\n",
       "      <td>0.307085</td>\n",
       "      <td>1.675010</td>\n",
       "      <td>0.498455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863700.0</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.134758</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558339e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220286</td>\n",
       "      <td>0.145244</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863760.0</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.134757</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558343e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.145242</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863820.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134755</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558348e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220281</td>\n",
       "      <td>0.145240</td>\n",
       "      <td>0.492948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863880.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134754</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558353e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220279</td>\n",
       "      <td>0.145239</td>\n",
       "      <td>0.492949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780751</td>\n",
       "      <td>863940.0</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.134752</td>\n",
       "      <td>0.029786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558357e+01</td>\n",
       "      <td>50.799377</td>\n",
       "      <td>0.220276</td>\n",
       "      <td>0.145237</td>\n",
       "      <td>0.492949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time   flowval  velval_list  depthval   qlatval    storageval  \\\n",
       "key_index                                                                      \n",
       "8777735         0.0  0.004196     0.185580  0.009796  0.000035 -6.722985e-08   \n",
       "8777735        60.0  0.004196     0.185576  0.009795  0.000035 -4.190952e-08   \n",
       "8777735       120.0  0.004196     0.185573  0.009795  0.000035 -4.627509e-08   \n",
       "8777735       180.0  0.004196     0.185570  0.009795  0.000035 -6.810296e-08   \n",
       "8777735       240.0  0.004196     0.185567  0.009794  0.000035 -7.770723e-08   \n",
       "...             ...       ...          ...       ...       ...           ...   \n",
       "8780751    863700.0  0.008624     0.134758  0.029789  0.000000 -1.558339e+01   \n",
       "8780751    863760.0  0.008624     0.134757  0.029788  0.000000 -1.558343e+01   \n",
       "8780751    863820.0  0.008623     0.134755  0.029788  0.000000 -1.558348e+01   \n",
       "8780751    863880.0  0.008623     0.134754  0.029787  0.000000 -1.558353e+01   \n",
       "8780751    863940.0  0.008623     0.134752  0.029786  0.000000 -1.558357e+01   \n",
       "\n",
       "           qlatCumval  kinCelerity   courant         X  \n",
       "key_index                                               \n",
       "8777735      0.002091     0.307107  1.675127  0.498455  \n",
       "8777735      0.004183     0.307099  1.675087  0.498455  \n",
       "8777735      0.006274     0.307094  1.675061  0.498455  \n",
       "8777735      0.008365     0.307090  1.675035  0.498455  \n",
       "8777735      0.010456     0.307085  1.675010  0.498455  \n",
       "...               ...          ...       ...       ...  \n",
       "8780751     50.799377     0.220286  0.145244  0.492948  \n",
       "8780751     50.799377     0.220284  0.145242  0.492948  \n",
       "8780751     50.799377     0.220281  0.145240  0.492948  \n",
       "8780751     50.799377     0.220279  0.145239  0.492949  \n",
       "8780751     50.799377     0.220276  0.145237  0.492949  \n",
       "\n",
       "[360000 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>933020027</td>\n",
       "      <td>561600.0</td>\n",
       "      <td>15.181515</td>\n",
       "      <td>4.458032</td>\n",
       "      <td>1.180036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.131255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.227305</td>\n",
       "      <td>25.363832</td>\n",
       "      <td>0.40232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time    flowval  velval_list  depthval  qlatval  storageval  \\\n",
       "key_index                                                                    \n",
       "933020027  561600.0  15.181515     4.458032  1.180036      0.0   58.131255   \n",
       "\n",
       "           qlatCumval  kinCelerity    courant        X  \n",
       "key_index                                               \n",
       "933020027         0.0     4.227305  25.363832  0.40232  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"courant\"] == 25.363832473754883]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated plotter based on filtered dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 14400\n",
      "14400 28800\n",
      "28800 43200\n",
      "43200 57600\n",
      "57600 72000\n",
      "72000 86400\n",
      "86400 100800\n",
      "100800 115200\n",
      "115200 129600\n",
      "129600 144000\n",
      "144000 158400\n",
      "158400 172800\n",
      "172800 187200\n",
      "187200 201600\n",
      "201600 216000\n",
      "216000 230400\n",
      "230400 244800\n",
      "244800 259200\n",
      "259200 273600\n",
      "273600 288000\n",
      "288000 302400\n",
      "302400 316800\n",
      "316800 331200\n",
      "331200 345600\n",
      "345600 360000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "import plotly.io as pio\n",
    "\n",
    "df_indexed = df_filtered.reset_index()\n",
    "test_chart = go.FigureWidget()\n",
    "for x in range(0, 25):\n",
    "    temp_df_range_1 = single_seg_length * (x)\n",
    "    temp_df_range_2 = single_seg_length * (x + 1)\n",
    "    print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment \" + str(df_indexed[\"key_index\"][temp_df_range_1]),\n",
    "    )\n",
    "test_chart.layout.title = \"Timestep Chart \" + str(dt)\n",
    "plot(test_chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.04615497589111328 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.007277727127075195 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.022621631622314453 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 4.4345855712890625e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.0272982120513916 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.029682159423828125 seconds.\n",
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 8.037819862365723 seconds.\n",
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n",
      "... complete in 9.12061858177185 seconds.\n",
      "max_courant: [27.53112221]\n",
      "routing ordered reaches for networks of order 1 ... \n",
      "... complete in 11.953770399093628 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n",
      "... complete in 24.70727014541626 seconds.\n",
      "max_courant: [126.81378174]\n",
      "ordered reach computation complete\n",
      "... in 23.734419584274292 seconds.\n",
      "program complete\n",
      "... in 33.576523303985596 seconds.\n"
     ]
    }
   ],
   "source": [
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt300.yaml\"\n",
    "all_results = tr.route_supernetwork(\n",
    "    tr.connections_g,\n",
    "    tr.networks_g,\n",
    "    tr.qlateral_g,\n",
    "    tr.waterbodies_df_g,\n",
    "    tr.waterbody_initial_states_df_g,\n",
    "    tr.channel_initial_states_df_g,\n",
    "    custom_input_file=custom_input_folder.joinpath(custom_input_file),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "florence_933020089_dt60.yaml\n",
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.02855849266052246 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.004696369171142578 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.014914751052856445 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 4.363059997558594e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.017179250717163086 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.018418550491333008 seconds.\n",
      "creating qlateral array ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qlateral array complete\n",
      "... in 7.231583595275879 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1108 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|████▏     | 467/1108 [00:44<01:01, 10.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 45.39464354515076 seconds.\n",
      "max_courant: [5.51265717]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|████▌     | 499/1108 [01:01<02:14,  4.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 61.81171536445618 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1108/1108 [02:22<00:00,  5.13it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 143.57751870155334 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [02:26<00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [25.36383247]\n",
      "ordered reach computation complete\n",
      "... in 146.69346976280212 seconds.\n",
      "program complete\n",
      "... in 154.7804775238037 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []         key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0         8777735       0.0  0.004196     0.185580  0.009796  0.000035   \n",
      "1         8777735      60.0  0.004196     0.185576  0.009795  0.000035   \n",
      "2         8777735     120.0  0.004196     0.185573  0.009795  0.000035   \n",
      "3         8777735     180.0  0.004196     0.185570  0.009795  0.000035   \n",
      "4         8777735     240.0  0.004196     0.185567  0.009794  0.000035   \n",
      "...           ...       ...       ...          ...       ...       ...   \n",
      "359995    8780751  863700.0  0.008624     0.134758  0.029789  0.000000   \n",
      "359996    8780751  863760.0  0.008624     0.134757  0.029788  0.000000   \n",
      "359997    8780751  863820.0  0.008623     0.134755  0.029788  0.000000   \n",
      "359998    8780751  863880.0  0.008623     0.134754  0.029787  0.000000   \n",
      "359999    8780751  863940.0  0.008623     0.134752  0.029786  0.000000   \n",
      "\n",
      "          storageval  qlatCumval  kinCelerity   courant         X  \n",
      "0      -6.722985e-08    0.002091     0.307107  1.675127  0.498455  \n",
      "1      -4.190952e-08    0.004183     0.307099  1.675087  0.498455  \n",
      "2      -4.627509e-08    0.006274     0.307094  1.675061  0.498455  \n",
      "3      -6.810296e-08    0.008365     0.307090  1.675035  0.498455  \n",
      "4      -7.770723e-08    0.010456     0.307085  1.675010  0.498455  \n",
      "...              ...         ...          ...       ...       ...  \n",
      "359995 -1.558339e+01   50.799377     0.220286  0.145244  0.492948  \n",
      "359996 -1.558343e+01   50.799377     0.220284  0.145242  0.492948  \n",
      "359997 -1.558348e+01   50.799377     0.220281  0.145240  0.492948  \n",
      "359998 -1.558353e+01   50.799377     0.220279  0.145239  0.492949  \n",
      "359999 -1.558357e+01   50.799377     0.220276  0.145237  0.492949  \n",
      "\n",
      "[360000 rows x 11 columns]\n",
      "florence_933020089_dt300.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.032993316650390625 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 1.0221493244171143 seconds.\n",
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.015247106552124023 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 4.076957702636719e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.017312049865722656 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.020360708236694336 seconds.\n",
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 8.384053230285645 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1108 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|████▏     | 467/1108 [00:08<00:11, 53.99it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 10.942792415618896 seconds.\n",
      "max_courant: [27.53112221]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|████▌     | 499/1108 [00:12<00:32, 18.70it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 15.264461040496826 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|████▌     | 499/1108 [00:29<00:32, 18.70it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing segment output to --> ../../test/output/text/933020089.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1108/1108 [00:32<00:00, 21.22it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 34.94488573074341 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [00:33<00:00, 32.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [126.81378174]\n",
      "ordered reach computation complete\n",
      "... in 33.65221977233887 seconds.\n",
      "program complete\n",
      "... in 45.40995812416077 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0        8777735       0.0  0.004196     0.185580  0.009796  0.000035   \n",
      "1        8777735     300.0  0.004196     0.185566  0.009794  0.000035   \n",
      "2        8777735     600.0  0.004195     0.185552  0.009793  0.000035   \n",
      "3        8777735     900.0  0.004194     0.185539  0.009792  0.000035   \n",
      "4        8777735    1200.0  0.004193     0.185527  0.009791  0.000035   \n",
      "...          ...       ...       ...          ...       ...       ...   \n",
      "71995    8780751  862500.0  0.008629     0.134789  0.029799  0.000000   \n",
      "71996    8780751  862800.0  0.008628     0.134782  0.029797  0.000000   \n",
      "71997    8780751  863100.0  0.008627     0.134775  0.029794  0.000000   \n",
      "71998    8780751  863400.0  0.008625     0.134767  0.029792  0.000000   \n",
      "71999    8780751  863700.0  0.008624     0.134759  0.029789  0.000000   \n",
      "\n",
      "         storageval  qlatCumval  kinCelerity   courant         X  \n",
      "0     -3.361492e-07    0.010456     0.307107  8.375633  0.498455  \n",
      "1     -6.897608e-07    0.020913     0.307083  8.375002  0.498455  \n",
      "2     -8.949428e-07    0.031369     0.307061  8.374394  0.498455  \n",
      "3     -1.292210e-06    0.041826     0.307039  8.373803  0.498456  \n",
      "4     -1.654553e-06    0.052282     0.307019  8.373238  0.498456  \n",
      "...             ...         ...          ...       ...       ...  \n",
      "71995  1.420508e+02   50.799377     0.220335  0.726379  0.492946  \n",
      "71996  1.420508e+02   50.799377     0.220324  0.726342  0.492947  \n",
      "71997  1.420507e+02   50.799377     0.220312  0.726303  0.492947  \n",
      "71998  1.420506e+02   50.799377     0.220300  0.726264  0.492948  \n",
      "71999  1.420505e+02   50.799377     0.220288  0.726223  0.492948  \n",
      "\n",
      "[72000 rows x 11 columns]         key_index      time   flowval  velval_list  depthval   qlatval  \\\n",
      "0         8777735       0.0  0.004196     0.185580  0.009796  0.000035   \n",
      "1         8777735      60.0  0.004196     0.185576  0.009795  0.000035   \n",
      "2         8777735     120.0  0.004196     0.185573  0.009795  0.000035   \n",
      "3         8777735     180.0  0.004196     0.185570  0.009795  0.000035   \n",
      "4         8777735     240.0  0.004196     0.185567  0.009794  0.000035   \n",
      "...           ...       ...       ...          ...       ...       ...   \n",
      "359995    8780751  863700.0  0.008624     0.134758  0.029789  0.000000   \n",
      "359996    8780751  863760.0  0.008624     0.134757  0.029788  0.000000   \n",
      "359997    8780751  863820.0  0.008623     0.134755  0.029788  0.000000   \n",
      "359998    8780751  863880.0  0.008623     0.134754  0.029787  0.000000   \n",
      "359999    8780751  863940.0  0.008623     0.134752  0.029786  0.000000   \n",
      "\n",
      "          storageval  qlatCumval  kinCelerity   courant         X  \n",
      "0      -6.722985e-08    0.002091     0.307107  1.675127  0.498455  \n",
      "1      -4.190952e-08    0.004183     0.307099  1.675087  0.498455  \n",
      "2      -4.627509e-08    0.006274     0.307094  1.675061  0.498455  \n",
      "3      -6.810296e-08    0.008365     0.307090  1.675035  0.498455  \n",
      "4      -7.770723e-08    0.010456     0.307085  1.675010  0.498455  \n",
      "...              ...         ...          ...       ...       ...  \n",
      "359995 -1.558339e+01   50.799377     0.220286  0.145244  0.492948  \n",
      "359996 -1.558343e+01   50.799377     0.220284  0.145242  0.492948  \n",
      "359997 -1.558348e+01   50.799377     0.220281  0.145240  0.492948  \n",
      "359998 -1.558353e+01   50.799377     0.220279  0.145239  0.492949  \n",
      "359999 -1.558357e+01   50.799377     0.220276  0.145237  0.492949  \n",
      "\n",
      "[360000 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_input_file_list = [\"florence_933020089_dt60.yaml\",\"florence_933020089_dt300.yaml\"]\n",
    "from plotly.subplots import make_subplots\n",
    "df_indexed_300 = pd.DataFrame()\n",
    "df_indexed_60 = pd.DataFrame()\n",
    "for c_i in (custom_input_file_list):\n",
    "    print(c_i)\n",
    "    import pathlib\n",
    "    import sys\n",
    "    import time\n",
    "    import glob\n",
    "    from tqdm import tqdm\n",
    "    import multiprocessing\n",
    "\n",
    "    root = pathlib.Path(\"../../\").resolve()\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_framework_v02\")))\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_framework_v01\")))\n",
    "    sys.path.append(str(root.joinpath(\"src\", \"python_routing_v01\")))\n",
    "    sys.path.append(\".\")\n",
    "    import nhd_io as nio\n",
    "    import compute_nhd_routing_SingleSeg as tr\n",
    "    import nhd_network_utilities_v01 as nnu\n",
    "    import nhd_reach_utilities as nru\n",
    "\n",
    "    custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "    custom_input_file = c_i\n",
    "    run_pocono2_test = None\n",
    "\n",
    "    supernetwork_parameters = None\n",
    "    waterbody_parameters = None\n",
    "    if custom_input_file:\n",
    "        (\n",
    "            supernetwork_parameters,\n",
    "            waterbody_parameters,\n",
    "            forcing_parameters,\n",
    "            restart_parameters,\n",
    "            output_parameters,\n",
    "            run_parameters,\n",
    "        ) = nio.read_custom_input(custom_input_folder.joinpath(custom_input_file))\n",
    "\n",
    "        break_network_at_waterbodies = run_parameters.get(\n",
    "            \"break_network_at_waterbodies\", None\n",
    "        )\n",
    "\n",
    "        dt = run_parameters.get(\"dt\", None)\n",
    "        nts = run_parameters.get(\"nts\", None)\n",
    "        qts_subdivisions = run_parameters.get(\"qts_subdivisions\", None)\n",
    "        debuglevel = -1 * int(run_parameters.get(\"debuglevel\", 0))\n",
    "        verbose = run_parameters.get(\"verbose\", None)\n",
    "        showtiming = run_parameters.get(\"showtiming\", None)\n",
    "        percentage_complete = run_parameters.get(\"percentage_complete\", None)\n",
    "        do_network_analysis_only = run_parameters.get(\"do_network_analysis_only\", None)\n",
    "        assume_short_ts = run_parameters.get(\"assume_short_ts\", None)\n",
    "        parallel_compute = run_parameters.get(\"parallel_compute\", None)\n",
    "        cpu_pool = run_parameters.get(\"cpu_pool\", None)\n",
    "        sort_networks = run_parameters.get(\"sort_networks\", None)\n",
    "\n",
    "        csv_output = output_parameters.get(\"csv_output\", None)\n",
    "        nc_output_folder = output_parameters.get(\"nc_output_folder\", None)\n",
    "\n",
    "        qlat_const = forcing_parameters.get(\"qlat_const\", None)\n",
    "        qlat_input_file = forcing_parameters.get(\"qlat_input_file\", None)\n",
    "        qlat_input_folder = forcing_parameters.get(\"qlat_input_folder\", None)\n",
    "        qlat_file_pattern_filter = forcing_parameters.get(\"qlat_file_pattern_filter\", None)\n",
    "        qlat_file_index_col = forcing_parameters.get(\"qlat_file_index_col\", None)\n",
    "        qlat_file_value_col = forcing_parameters.get(\"qlat_file_value_col\", None)\n",
    "\n",
    "        wrf_hydro_channel_restart_file = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_file\", None\n",
    "        )\n",
    "        wrf_hydro_channel_ID_crosswalk_file = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_ID_crosswalk_file\", None\n",
    "        )\n",
    "        wrf_hydro_channel_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_ID_crosswalk_file_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_upstream_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_upstream_flow_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_downstream_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_downstream_flow_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_channel_restart_depth_flow_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_channel_restart_depth_flow_field_name\", None\n",
    "        )\n",
    "\n",
    "        wrf_hydro_waterbody_restart_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_restart_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_ID_crosswalk_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_ID_crosswalk_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_ID_crosswalk_file_field_name\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_crosswalk_filter_file = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_crosswalk_filter_file\", None\n",
    "        )\n",
    "        wrf_hydro_waterbody_crosswalk_filter_file_field_name = restart_parameters.get(\n",
    "            \"wrf_hydro_waterbody_crosswalk_filter_file_field_name\", None\n",
    "        )\n",
    "\n",
    "    # Any specific commandline arguments will override the file\n",
    "    # TODO: There are probably some pathological collisions that could\n",
    "    # arise from this ordering ... check these out.\n",
    "\n",
    "    if run_pocono2_test:\n",
    "        if verbose:\n",
    "            print(\"running test case for Pocono_TEST2 domain\")\n",
    "        # Overwrite the following test defaults\n",
    "        supernetwork = \"Pocono_TEST2\"\n",
    "        break_network_at_waterbodies = False\n",
    "        qts_subdivisions = 1  # change qts_subdivisions = 1 as  default\n",
    "        dt = 300 / qts_subdivisions\n",
    "        nts = 144 * qts_subdivisions\n",
    "        csv_output = {\"csv_output_folder\": os.path.join(root, \"test\", \"output\", \"text\")}\n",
    "        nc_output_folder = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "        # test 1. Take lateral flow from re-formatted wrf-hydro output from Pocono Basin simulation\n",
    "        qlat_input_file = os.path.join(\n",
    "            root, r\"test/input/geo/PoconoSampleData2/Pocono_ql_testsamp1_nwm_mc.csv\"\n",
    "        )\n",
    "    if showtiming:\n",
    "        program_start_time = time.time()\n",
    "    if verbose:\n",
    "        print(f\"begin program t-route ...\")\n",
    "\n",
    "    # STEP 1: Read the supernetwork dataset and build the connections graph\n",
    "    if verbose:\n",
    "        print(\"creating supernetwork connections set\")\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "\n",
    "    if supernetwork_parameters:\n",
    "        supernetwork_values = nnu.get_nhd_connections(\n",
    "            supernetwork_parameters=supernetwork_parameters,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        test_folder = os.path.join(root, r\"test\")\n",
    "        geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "        supernetwork_parameters, supernetwork_values = nnu.set_networks(\n",
    "            supernetwork=supernetwork,\n",
    "            geo_input_folder=geo_input_folder,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "        waterbody_parameters = nnu.set_waterbody_parameters(\n",
    "            supernetwork=supernetwork,\n",
    "            geo_input_folder=geo_input_folder,\n",
    "            verbose=False,\n",
    "            debuglevel=debuglevel,\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"supernetwork connections set complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    connections = supernetwork_values[0]\n",
    "    # STEP 2: Separate the networks and build the sub-graph of reaches within each network\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"organizing connections into reaches ...\")\n",
    "    networks = nru.compose_networks(\n",
    "        supernetwork_values,\n",
    "        break_network_at_waterbodies=break_network_at_waterbodies,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "        showtiming=showtiming,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"reach organization complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 3: Organize Network for Waterbodies\n",
    "    if break_network_at_waterbodies:\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"reading waterbody parameter file ...\")\n",
    "\n",
    "        ## STEP 3a: Read waterbody parameter file\n",
    "        waterbodies_values = supernetwork_values[12]\n",
    "        waterbodies_segments = supernetwork_values[13]\n",
    "        connections_tailwaters = supernetwork_values[4]\n",
    "\n",
    "        waterbodies_df = nio.read_waterbody_df(waterbody_parameters, waterbodies_values,)\n",
    "        waterbodies_df = waterbodies_df.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "\n",
    "        nru.order_networks(connections, networks, connections_tailwaters)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"waterbodies complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "\n",
    "        ## STEP 3b: Order subnetworks above and below reservoirs\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"ordering waterbody subnetworks ...\")\n",
    "\n",
    "        max_network_seqorder = -1\n",
    "        for network in networks:\n",
    "            max_network_seqorder = max(\n",
    "                networks[network][\"network_seqorder\"], max_network_seqorder\n",
    "            )\n",
    "        ordered_networks = {}\n",
    "\n",
    "        for terminal_segment, network in networks.items():\n",
    "            if network[\"network_seqorder\"] not in ordered_networks:\n",
    "                ordered_networks[network[\"network_seqorder\"]] = []\n",
    "            ordered_networks[network[\"network_seqorder\"]].append(\n",
    "                (terminal_segment, network)\n",
    "            )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"ordering waterbody subnetworks complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "\n",
    "    else:\n",
    "        # If we are not splitting the networks, we can put them all in one order\n",
    "        max_network_seqorder = 0\n",
    "        ordered_networks = {}\n",
    "        ordered_networks[0] = [\n",
    "            (terminal_segment, network) for terminal_segment, network in networks.items()\n",
    "        ]\n",
    "\n",
    "    if do_network_analysis_only:\n",
    "        sys.exit()\n",
    "\n",
    "    if break_network_at_waterbodies:\n",
    "        ## STEP 3c: Handle Waterbody Initial States\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"setting waterbody initial states ...\")\n",
    "\n",
    "        if wrf_hydro_waterbody_restart_file:\n",
    "\n",
    "            waterbody_initial_states_df = nio.get_reservoir_restart_from_wrf_hydro(\n",
    "                wrf_hydro_waterbody_restart_file,\n",
    "                wrf_hydro_waterbody_ID_crosswalk_file,\n",
    "                wrf_hydro_waterbody_ID_crosswalk_file_field_name,\n",
    "                wrf_hydro_waterbody_crosswalk_filter_file,\n",
    "                wrf_hydro_waterbody_crosswalk_filter_file_field_name,\n",
    "            )\n",
    "        else:\n",
    "            # TODO: Consider adding option to read cold state from route-link file\n",
    "            waterbody_initial_ds_flow_const = 0.0\n",
    "            waterbody_initial_depth_const = 0.0\n",
    "            # Set initial states from cold-state\n",
    "            waterbody_initial_states_df = pd.DataFrame(\n",
    "                0, index=waterbodies_df.index, columns=[\"qd0\", \"h0\",], dtype=\"float32\"\n",
    "            )\n",
    "            # TODO: This assignment could probably by done in the above call\n",
    "            waterbody_initial_states_df[\"qd0\"] = waterbody_initial_ds_flow_const\n",
    "            waterbody_initial_states_df[\"h0\"] = waterbody_initial_depth_const\n",
    "            waterbody_initial_states_df[\"index\"] = range(len(waterbody_initial_states_df))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"waterbody initial states complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "    # STEP 4: Handle Channel Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting channel initial states ...\")\n",
    "\n",
    "    if wrf_hydro_channel_restart_file:\n",
    "\n",
    "        channel_initial_states_df = nio.get_stream_restart_from_wrf_hydro(\n",
    "            wrf_hydro_channel_restart_file,\n",
    "            wrf_hydro_channel_ID_crosswalk_file,\n",
    "            wrf_hydro_channel_ID_crosswalk_file_field_name,\n",
    "            wrf_hydro_channel_restart_upstream_flow_field_name,\n",
    "            wrf_hydro_channel_restart_downstream_flow_field_name,\n",
    "            wrf_hydro_channel_restart_depth_flow_field_name,\n",
    "        )\n",
    "    else:\n",
    "        # TODO: Consider adding option to read cold state from route-link file\n",
    "        channel_initial_us_flow_const = 0.0\n",
    "        channel_initial_ds_flow_const = 0.0\n",
    "        channel_initial_depth_const = 0.0\n",
    "        # Set initial states from cold-state\n",
    "        channel_initial_states_df = pd.DataFrame(\n",
    "            0, index=connections.keys(), columns=[\"qu0\", \"qd0\", \"h0\",], dtype=\"float32\"\n",
    "        )\n",
    "        channel_initial_states_df[\"qu0\"] = channel_initial_us_flow_const\n",
    "        channel_initial_states_df[\"qd0\"] = channel_initial_ds_flow_const\n",
    "        channel_initial_states_df[\"h0\"] = channel_initial_depth_const\n",
    "        channel_initial_states_df[\"index\"] = range(len(channel_initial_states_df))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"channel initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 5: Read (or set) QLateral Inputs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"creating qlateral array ...\")\n",
    "\n",
    "    # initialize qlateral dict\n",
    "    qlateral = {}\n",
    "\n",
    "    if qlat_input_folder:\n",
    "        qlat_files = []\n",
    "        for pattern in qlat_file_pattern_filter:\n",
    "            qlat_files.extend(glob.glob(qlat_input_folder + pattern))\n",
    "        qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "            qlat_files=qlat_files,\n",
    "            index_col=qlat_file_index_col,\n",
    "            value_col=qlat_file_value_col,\n",
    "        )\n",
    "\n",
    "    elif qlat_input_file:\n",
    "        qlat_df = nio.get_ql_from_csv(qlat_input_file)\n",
    "\n",
    "    else:\n",
    "        qlat_df = pd.DataFrame(\n",
    "            qlat_const, index=connections.keys(), columns=range(nts), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "    for index, row in qlat_df.iterrows():\n",
    "        qlateral[index] = row.tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"qlateral array complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    # STEP 6: Sort the ordered networks\n",
    "    if sort_networks:\n",
    "        if showtiming:\n",
    "            start_time = time.time()\n",
    "        if verbose:\n",
    "            print(\"sorting the ordered networks ...\")\n",
    "\n",
    "        for nsq in range(max_network_seqorder, -1, -1):\n",
    "            sort_ordered_network(ordered_networks[nsq], True)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"sorting complete\")\n",
    "        if showtiming:\n",
    "            print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "    # Define the pool after we create the static global objects (and collect the garbage)\n",
    "    if parallel_compute:\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "        pool = multiprocessing.Pool(cpu_pool)\n",
    "\n",
    "    flowveldepth_connect = (\n",
    "        {}\n",
    "    )  # dict to contain values to transfer from upstream to downstream networks\n",
    "    ################### Main Execution Loop across ordered networks\n",
    "    if showtiming:\n",
    "        main_start_time = time.time()\n",
    "    if verbose:\n",
    "        print(f\"executing routing computation ...\")\n",
    "\n",
    "    compute_network_func = tr.compute_network\n",
    "\n",
    "    tr.connections_g = connections\n",
    "    tr.networks_g = networks\n",
    "    tr.qlateral_g = qlateral\n",
    "    tr.waterbodies_df_g = waterbodies_df\n",
    "    tr.waterbody_initial_states_df_g = waterbody_initial_states_df\n",
    "    tr.channel_initial_states_df_g = channel_initial_states_df\n",
    "\n",
    "    progress_count = 0\n",
    "    percentage_complete = True\n",
    "    if percentage_complete:\n",
    "        for nsq in range(max_network_seqorder, -1, -1):\n",
    "            for terminal_segment, network in ordered_networks[nsq]:\n",
    "                progress_count += len(network[\"all_segments\"])\n",
    "        pbar = tqdm(total=(progress_count))\n",
    "\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "\n",
    "        if parallel_compute:\n",
    "            nslist = []\n",
    "        results = []\n",
    "\n",
    "        current_index_total = 0\n",
    "\n",
    "        for terminal_segment, network in ordered_networks[nsq]:\n",
    "\n",
    "            if percentage_complete:\n",
    "                if current_index_total == 0:\n",
    "                    pbar.update(0)\n",
    "\n",
    "            if break_network_at_waterbodies:\n",
    "                waterbody = waterbodies_segments.get(terminal_segment)\n",
    "            else:\n",
    "                waterbody = None\n",
    "            if not parallel_compute:  # serial execution\n",
    "                if showtiming:\n",
    "                    start_time = time.time()\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"routing ordered reaches for terminal segment {terminal_segment} ...\"\n",
    "                    )\n",
    "\n",
    "                results.append(\n",
    "                    compute_network_func(\n",
    "                        flowveldepth_connect=flowveldepth_connect,\n",
    "                        terminal_segment=terminal_segment,\n",
    "                        supernetwork_parameters=supernetwork_parameters,\n",
    "                        waterbody_parameters=waterbody_parameters,\n",
    "                        waterbody=waterbody,\n",
    "                        nts=nts,\n",
    "                        dt=dt,\n",
    "                        qts_subdivisions=qts_subdivisions,\n",
    "                        verbose=verbose,\n",
    "                        debuglevel=debuglevel,\n",
    "                        csv_output=csv_output,\n",
    "                        nc_output_folder=nc_output_folder,\n",
    "                        assume_short_ts=assume_short_ts,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if showtiming:\n",
    "                    print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "                if percentage_complete:\n",
    "                    pbar.update(len(network[\"all_segments\"]))\n",
    "\n",
    "            else:  # parallel execution\n",
    "                nslist.append(\n",
    "                    [\n",
    "                        flowveldepth_connect,\n",
    "                        terminal_segment,\n",
    "                        supernetwork_parameters,  # TODO: This should probably be global...\n",
    "                        waterbody_parameters,\n",
    "                        waterbody,\n",
    "                        nts,\n",
    "                        dt,\n",
    "                        qts_subdivisions,\n",
    "                        verbose,\n",
    "                        debuglevel,\n",
    "                        csv_output,\n",
    "                        nc_output_folder,\n",
    "                        assume_short_ts,\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        if parallel_compute:\n",
    "            if verbose:\n",
    "                print(f\"routing ordered reaches for networks of order {nsq} ... \")\n",
    "            if debuglevel <= -2:\n",
    "                print(f\"reaches to be routed include:\")\n",
    "                print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "            # with pool:\n",
    "            # with multiprocessing.Pool() as pool:\n",
    "            results = pool.starmap(compute_network_func, nslist)\n",
    "\n",
    "            if showtiming:\n",
    "                print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "            if percentage_complete:\n",
    "                pbar.update(\n",
    "                    sum(\n",
    "                        len(network[1][\"all_segments\"]) for network in ordered_networks[nsq]\n",
    "                    )\n",
    "                )\n",
    "                # print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "\n",
    "        max_courant = 0\n",
    "        maxa = []\n",
    "        for result in results:\n",
    "            for seg in result:\n",
    "                maxa.extend(result[seg][:, 8:9])\n",
    "        max_courant = max(maxa)\n",
    "        print(f\"max_courant: {max_courant}\")\n",
    "\n",
    "        if (\n",
    "            nsq > 0\n",
    "        ):  # We skip this step for zero-order networks, i.e., those that have no downstream dependents\n",
    "            flowveldepth_connect = (\n",
    "                {}\n",
    "            )  # There is no need to preserve previously passed on values -- so we clear the dictionary\n",
    "            for i, (terminal_segment, network) in enumerate(ordered_networks[nsq]):\n",
    "                # seg = network[\"reaches\"][network[\"terminal_reach\"]][\"reach_tail\"]\n",
    "                seg = terminal_segment\n",
    "                flowveldepth_connect[seg] = {}\n",
    "                flowveldepth_connect[seg] = results[i][seg]\n",
    "                # TODO: The value passed here could be much more specific to\n",
    "                # TODO: exactly and only the most recent time step for the passing reach\n",
    "\n",
    "    if parallel_compute:\n",
    "        pool.close()\n",
    "\n",
    "    if percentage_complete:\n",
    "        pbar.close()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordered reach computation complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - main_start_time))\n",
    "    if verbose:\n",
    "        print(\"program complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - program_start_time))\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_results_new = {}\n",
    "    seg_courant_maxes = []\n",
    "    time = []\n",
    "    flowval = []  # flowval\n",
    "    velval_list = []  # velval\n",
    "    depthval = []  # depthval\n",
    "    qlatval = []  # qlatval\n",
    "    storageval = []  # storageval\n",
    "    qlatCumval = []  # qlatCumval\n",
    "    kinCelerity = []  # ck\n",
    "    courant = []  # cn\n",
    "    X = []  # X\n",
    "\n",
    "    for result in results:\n",
    "        all_results_new.update(result)\n",
    "    \n",
    "    # print(all_results[8780801][1][0])\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # print(all_results)\n",
    "\n",
    "    for key, data in all_results_new.items():\n",
    "        time.extend(data[:, 0])  # time\n",
    "        flowval.extend(data[:, 1])  # flowval\n",
    "        velval_list.extend(data[:, 2])  # velval\n",
    "        depthval.extend(data[:, 3])  # depthval\n",
    "        qlatval.extend(data[:, 4])  # qlatval\n",
    "        storageval.extend(data[:, 5])  # storageval\n",
    "        qlatCumval.extend(data[:, 6])  # qlatCumval\n",
    "        kinCelerity.extend(data[:, 7])  # ck\n",
    "        courant.extend(data[:, 8])  # cn\n",
    "        X.extend(data[:, 9])  # X\n",
    "#     print(all_results_new)\n",
    "    single_seg_length = len(all_results_new[933020089][:, 0])\n",
    "\n",
    "    if c_i == \"florence_933020089_dt300.yaml\":\n",
    "        single_seg_length_300 = single_seg_length\n",
    "    else:\n",
    "        single_seg_length_60 = single_seg_length\n",
    "#     else:\n",
    "#         single_seg_length_10 = single_seg_length\n",
    "#     print(single_seg_length_300,single_seg_length_60)\n",
    "    # single_seg_length * 611\n",
    "\n",
    "    key_index = all_results.keys()\n",
    "    key_index = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            itertools.repeat(x, single_seg_length) for x in key_index\n",
    "        )\n",
    "    )\n",
    "    data = {\n",
    "        \"key_index\": list(key_index),\n",
    "        \"time\": list(time),\n",
    "        \"flowval\": list(flowval),\n",
    "        \"velval_list\": list(velval_list),\n",
    "        \"depthval\": list(depthval),\n",
    "        \"qlatval\": list(qlatval),\n",
    "        \"storageval\": list(storageval),\n",
    "        \"qlatCumval\": list(qlatCumval),\n",
    "        \"kinCelerity\": list(kinCelerity),\n",
    "        \"courant\": list(courant),\n",
    "        \"X\": list(X),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index(\"key_index\")\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(\"key_index\")\n",
    "\n",
    "\n",
    "    seg_list = []\n",
    "    seg_courant_maxes = []\n",
    "    for seg in all_results_new:\n",
    "        seg_list.append(seg)\n",
    "        seg_courant_maxes.append(max(all_results_new[seg][:, tr.courant_index]))\n",
    "    zipped = zip(seg_list, seg_courant_maxes)\n",
    "    zipped = list(zipped)\n",
    "    res = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "    # A.sort(reverse=True)\n",
    "    res = (res)[:25]\n",
    "    # print((res)[:25])\n",
    "\n",
    "    major_segments = []\n",
    "    for x, y in res[:25]:\n",
    "        major_segments.append(x)\n",
    "    # major_segments\n",
    "\n",
    "    df_filtered = df.loc[df.index.isin(major_segments), :]\n",
    "\n",
    "    if c_i == \"florence_933020089_dt300.yaml\":\n",
    "        df_indexed_300 = df_filtered.reset_index()\n",
    "    else:\n",
    "        df_indexed_60 = df_filtered.reset_index()\n",
    "    print(df_indexed_300,df_indexed_60)\n",
    "#     else:\n",
    "#         df_indexed_10 = df_filtered.reset_index()\n",
    "\n",
    "test_chart = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "# test_chart = go.FigureWidget()\n",
    "for x in range(0,len(major_segments)):\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment flowval \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"flowval\"],\n",
    "        name=\"segment flowval \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"courant\"],secondary_y=True,\n",
    "        name=\"segment courant \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"courant\"],secondary_y=True,\n",
    "        name=\"segment courant \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "    )\n",
    "# test_chart.update_yaxes(title_text=\"<b>primary</b> yaxis title\", secondary_y=False)\n",
    "# test_chart.update_yaxes(title_text=\"<b>secondary</b> yaxis title\", secondary_y=True)\n",
    "\n",
    "test_chart.layout.title = \"Timestep Chart 300, 60\"\n",
    "plot(test_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "test_chart = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "# test_chart = go.FigureWidget()\n",
    "\n",
    "for x in range(0,len(major_segments)):\n",
    "    r = lambda: random.randint(0,255)\n",
    "    temp_color1 = ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "    temp_color2 = ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "#     print(temp_color1,temp_color2)\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"flowval\"],line_color=temp_color1,\n",
    "        name=\"segment flowval \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"flowval\"],line_color=temp_color2,\n",
    "        name=\"segment flowval \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_300 * (x)\n",
    "    temp_df_range_2 = single_seg_length_300 * (x + 1)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_300[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_300[temp_df_range_1:temp_df_range_2][\"courant\"],line_color=temp_color1,\n",
    "        secondary_y=True,\n",
    "        name=\"segment courant \" + str(df_indexed_300[\"key_index\"][temp_df_range_1]) + \" \" + str(300),\n",
    "\n",
    "    )\n",
    "    temp_df_range_1 = single_seg_length_60 * (x)\n",
    "    temp_df_range_2 = single_seg_length_60 * (x + 1)\n",
    "    #         print(temp_df_range_1, temp_df_range_2)\n",
    "    test_chart.add_scatter(\n",
    "        x=df_indexed_60[temp_df_range_1:temp_df_range_2][\"time\"],\n",
    "        y=df_indexed_60[temp_df_range_1:temp_df_range_2][\"courant\"],line_color=temp_color2,\n",
    "        secondary_y=True,\n",
    "        name=\"segment courant \" + str(df_indexed_60[\"key_index\"][temp_df_range_1]) + \" \" + str(60),\n",
    "    )\n",
    "test_chart.update_yaxes(title_text=\"Flow Value\", secondary_y=False)\n",
    "test_chart.update_yaxes(title_text=\"Courant Value\", secondary_y=True)\n",
    "test_chart.update_xaxes(title_text=\"Time Step\")\n",
    "test_chart.layout.title = \"Timestep Chart 300, 60\"\n",
    "plot(test_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#A79870'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "r = lambda: random.randint(0,255)\n",
    "gen1 = ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "gen1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths = df_indexed_300\n",
    "lengths_temp = []\n",
    "for i, j in df_lengths.iterrows(): \n",
    "    lengths_temp.append(supernetwork_values[0][j['key_index']]['length'])\n",
    "df_lengths['lengths'] = pd.Series(lengths_temp, index=df_lengths.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lengths.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths = df_lengths.reset_index(drop=True)\n",
    "df_lengths = df_lengths.set_index('key_index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(major_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = []\n",
    "courant_list = []\n",
    "flowval_list = []\n",
    "for i in major_segments:\n",
    "    length_list.append(max(df_lengths.loc[i]['lengths'][:single_seg_length_300]))\n",
    "    courant_list.append(max(df_lengths.loc[i]['courant'][:single_seg_length_300]))\n",
    "    flowval_list.append(max(df_lengths.loc[i]['flowval'][:single_seg_length_300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126.81378173828125,\n",
       " 73.86154174804688,\n",
       " 47.82014846801758,\n",
       " 41.540863037109375,\n",
       " 36.24374771118164,\n",
       " 23.67105484008789,\n",
       " 17.922224044799805,\n",
       " 13.929777145385742,\n",
       " 12.283413887023926,\n",
       " 10.532113075256348,\n",
       " 9.097070693969727,\n",
       " 8.125431060791016,\n",
       " 8.072996139526367,\n",
       " 7.252985954284668,\n",
       " 6.937002658843994,\n",
       " 6.692083358764648,\n",
       " 6.539554119110107,\n",
       " 6.3316121101379395,\n",
       " 5.747074604034424,\n",
       " 5.367031574249268,\n",
       " 5.337118625640869,\n",
       " 5.220866680145264,\n",
       " 5.2163591384887695,\n",
       " 4.962591648101807,\n",
       " 4.876999855041504]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         8777735\n",
       "1         8777735\n",
       "2         8777735\n",
       "3         8777735\n",
       "4         8777735\n",
       "           ...   \n",
       "359995    8780751\n",
       "359996    8780751\n",
       "359997    8780751\n",
       "359998    8780751\n",
       "359999    8780751\n",
       "Name: key_index, Length: 360000, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indexed_60['key_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table1 = zip(length_list,major_segments)\n",
    "# table2 = sorted(table1, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = length_list\n",
    "a = major_segments\n",
    "c = courant_list\n",
    "d = flowval_list\n",
    "res = \"\\n\".join(\"{}      {}      {}       {}\".format(w   , x  , y   , z  ) for w, x, y, z in sorted(zip(b, d, c, a),reverse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0      56.463199615478516      12.283413887023926       933020058\n",
      "5.0      518.8282470703125      41.540863037109375       8778581\n",
      "10.0      15.180281639099121      126.81378173828125       933020027\n",
      "11.0      0.13794074952602386      47.82014846801758       933020017\n",
      "11.0      8.245078086853027      73.86154174804688       8777735\n",
      "14.0      15.526399612426758      8.125431060791016       933020036\n",
      "17.0      0.5986793637275696      23.67105484008789       933020061\n",
      "17.0      20.703197479248047      36.24374771118164       933020059\n",
      "23.0      105.91104888916016      5.2163591384887695       8779003\n",
      "28.0      1.60250723361969      13.929777145385742       933020020\n",
      "42.0      0.5486629605293274      9.097070693969727       8777485\n",
      "46.0      1.887703776359558      5.220866680145264       933020050\n",
      "54.0      0.33712542057037354      6.692083358764648       8777477\n",
      "54.0      27.456575393676758      17.922224044799805       8780597\n",
      "57.0      28.86312484741211      10.532113075256348       933020023\n",
      "75.0      0.2937638759613037      6.539554119110107       8780495\n",
      "91.0      12.485885620117188      4.962591648101807       8780751\n",
      "114.0      113.275390625      7.252985954284668       8778021\n",
      "126.0      1.8319164514541626      8.072996139526367       8778795\n",
      "145.0      41.112030029296875      5.747074604034424       8777481\n",
      "152.0      119.80558013916016      5.367031574249268       8780607\n",
      "164.0      91.60624694824219      6.937002658843994       8777339\n",
      "166.0      363.17681884765625      6.3316121101379395       8777867\n",
      "172.0      0.45590826869010925      4.876999855041504       8778947\n",
      "177.0      377.08563232421875      5.337118625640869       8777861\n"
     ]
    }
   ],
   "source": [
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chart = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "test_chart.add_scatter(\n",
    "    x=length_list,\n",
    "    y=courant_list,\n",
    "    name=\"courant\" + \" \" + str(300),\n",
    "    mode='markers',  \n",
    ")\n",
    "test_chart.add_scatter(\n",
    "    x=length_list,\n",
    "    y=flowval_list,\n",
    "    name=\"flowval\" + \" \" + str(300),\n",
    "    mode='markers',  \n",
    ")\n",
    "# test_chart.update_yaxes(title_text=\"Flow Value\", secondary_y=False)\n",
    "# test_chart.update_yaxes(title_text=\"Courant Value\", secondary_y=True)\n",
    "test_chart.update_xaxes(title_text=\"Length\", )\n",
    "\n",
    "test_chart.layout.title = \"Top 25 Values by Length - 300 \"\n",
    "plot(test_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
