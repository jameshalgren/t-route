{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic imports and path management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "root = pathlib.Path(\"../../\").resolve()\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v02\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_framework_v01\")))\n",
    "sys.path.append(str(root.joinpath(\"src\", \"python_routing_v01\")))\n",
    "sys.path.append(\".\")\n",
    "import nhd_io as nio\n",
    "import compute_nhd_routing_SingleSeg as tr\n",
    "import nhd_network_utilities_v01 as nnu\n",
    "import nhd_reach_utilities as nru\n",
    "\n",
    "custom_input_folder = root.joinpath(\"test\", \"input\", \"yaml\")\n",
    "custom_input_file = \"florence_933020089_dt60.yaml\"\n",
    "run_pocono2_test = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the primary data input from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob.hreha/github/t-route/src/python_framework_v02/nhd_io.py:53: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "supernetwork_parameters = None\n",
    "waterbody_parameters = None\n",
    "if custom_input_file:\n",
    "    (\n",
    "        supernetwork_parameters,\n",
    "        waterbody_parameters,\n",
    "        forcing_parameters,\n",
    "        restart_parameters,\n",
    "        output_parameters,\n",
    "        run_parameters,\n",
    "    ) = nio.read_custom_input(custom_input_folder.joinpath(custom_input_file))\n",
    "\n",
    "    break_network_at_waterbodies = run_parameters.get(\n",
    "        \"break_network_at_waterbodies\", None\n",
    "    )\n",
    "\n",
    "    dt = run_parameters.get(\"dt\", None)\n",
    "    nts = run_parameters.get(\"nts\", None)\n",
    "    qts_subdivisions = run_parameters.get(\"qts_subdivisions\", None)\n",
    "    debuglevel = -1 * int(run_parameters.get(\"debuglevel\", 0))\n",
    "    verbose = run_parameters.get(\"verbose\", None)\n",
    "    showtiming = run_parameters.get(\"showtiming\", None)\n",
    "    percentage_complete = run_parameters.get(\"percentage_complete\", None)\n",
    "    do_network_analysis_only = run_parameters.get(\"do_network_analysis_only\", None)\n",
    "    assume_short_ts = run_parameters.get(\"assume_short_ts\", None)\n",
    "    parallel_compute = run_parameters.get(\"parallel_compute\", None)\n",
    "    cpu_pool = run_parameters.get(\"cpu_pool\", None)\n",
    "    sort_networks = run_parameters.get(\"sort_networks\", None)\n",
    "\n",
    "    csv_output = output_parameters.get(\"csv_output\", None)\n",
    "    nc_output_folder = output_parameters.get(\"nc_output_folder\", None)\n",
    "\n",
    "    qlat_const = forcing_parameters.get(\"qlat_const\", None)\n",
    "    qlat_input_file = forcing_parameters.get(\"qlat_input_file\", None)\n",
    "    qlat_input_folder = forcing_parameters.get(\"qlat_input_folder\", None)\n",
    "    qlat_file_pattern_filter = forcing_parameters.get(\"qlat_file_pattern_filter\", None)\n",
    "    qlat_file_index_col = forcing_parameters.get(\"qlat_file_index_col\", None)\n",
    "    qlat_file_value_col = forcing_parameters.get(\"qlat_file_value_col\", None)\n",
    "\n",
    "    wrf_hydro_channel_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_channel_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_upstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_upstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_downstream_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_downstream_flow_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_channel_restart_depth_flow_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_channel_restart_depth_flow_field_name\", None\n",
    "    )\n",
    "\n",
    "    wrf_hydro_waterbody_restart_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_restart_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_ID_crosswalk_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_ID_crosswalk_file_field_name\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file\", None\n",
    "    )\n",
    "    wrf_hydro_waterbody_crosswalk_filter_file_field_name = restart_parameters.get(\n",
    "        \"wrf_hydro_waterbody_crosswalk_filter_file_field_name\", None\n",
    "    )\n",
    "\n",
    "# Any specific commandline arguments will override the file\n",
    "# TODO: There are probably some pathological collisions that could\n",
    "# arise from this ordering ... check these out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_pocono2_test:\n",
    "    if verbose:\n",
    "        print(\"running test case for Pocono_TEST2 domain\")\n",
    "    # Overwrite the following test defaults\n",
    "    supernetwork = \"Pocono_TEST2\"\n",
    "    break_network_at_waterbodies = False\n",
    "    qts_subdivisions = 1  # change qts_subdivisions = 1 as  default\n",
    "    dt = 300 / qts_subdivisions\n",
    "    nts = 144 * qts_subdivisions\n",
    "    csv_output = {\"csv_output_folder\": os.path.join(root, \"test\", \"output\", \"text\")}\n",
    "    nc_output_folder = os.path.join(root, \"test\", \"output\", \"text\")\n",
    "    # test 1. Take lateral flow from re-formatted wrf-hydro output from Pocono Basin simulation\n",
    "    qlat_input_file = os.path.join(\n",
    "        root, r\"test/input/geo/PoconoSampleData2/Pocono_ql_testsamp1_nwm_mc.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin program t-route ...\n",
      "creating supernetwork connections set\n",
      "supernetwork connections set complete\n",
      "... in 0.044088125228881836 seconds.\n"
     ]
    }
   ],
   "source": [
    "if showtiming:\n",
    "    program_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"begin program t-route ...\")\n",
    "\n",
    "# STEP 1: Read the supernetwork dataset and build the connections graph\n",
    "if verbose:\n",
    "    print(\"creating supernetwork connections set\")\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "\n",
    "if supernetwork_parameters:\n",
    "    supernetwork_values = nnu.get_nhd_connections(\n",
    "        supernetwork_parameters=supernetwork_parameters,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    test_folder = os.path.join(root, r\"test\")\n",
    "    geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "    supernetwork_parameters, supernetwork_values = nnu.set_networks(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "    waterbody_parameters = nnu.set_waterbody_parameters(\n",
    "        supernetwork=supernetwork,\n",
    "        geo_input_folder=geo_input_folder,\n",
    "        verbose=False,\n",
    "        debuglevel=debuglevel,\n",
    "    )\n",
    "\n",
    "if verbose:\n",
    "    print(\"supernetwork connections set complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "connections = supernetwork_values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.006093502044677734 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Separate the networks and build the sub-graph of reaches within each network\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"organizing connections into reaches ...\")\n",
    "networks = nru.compose_networks(\n",
    "    supernetwork_values,\n",
    "    break_network_at_waterbodies=break_network_at_waterbodies,\n",
    "    verbose=False,\n",
    "    debuglevel=debuglevel,\n",
    "    showtiming=showtiming,\n",
    ")\n",
    "\n",
    "if verbose:\n",
    "    print(\"reach organization complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading waterbody parameter file ...\n",
      "waterbodies complete\n",
      "... in 0.014790058135986328 seconds.\n",
      "ordering waterbody subnetworks ...\n",
      "ordering waterbody subnetworks complete\n",
      "... in 4.553794860839844e-05 seconds.\n",
      "setting waterbody initial states ...\n",
      "waterbody initial states complete\n",
      "... in 0.019099950790405273 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Organize Network for Waterbodies\n",
    "if break_network_at_waterbodies:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"reading waterbody parameter file ...\")\n",
    "\n",
    "    ## STEP 3a: Read waterbody parameter file\n",
    "    waterbodies_values = supernetwork_values[12]\n",
    "    waterbodies_segments = supernetwork_values[13]\n",
    "    connections_tailwaters = supernetwork_values[4]\n",
    "\n",
    "    waterbodies_df = nio.read_waterbody_df(waterbody_parameters, waterbodies_values,)\n",
    "    waterbodies_df = waterbodies_df.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "\n",
    "    nru.order_networks(connections, networks, connections_tailwaters)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbodies complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "    ## STEP 3b: Order subnetworks above and below reservoirs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks ...\")\n",
    "\n",
    "    max_network_seqorder = -1\n",
    "    for network in networks:\n",
    "        max_network_seqorder = max(\n",
    "            networks[network][\"network_seqorder\"], max_network_seqorder\n",
    "        )\n",
    "    ordered_networks = {}\n",
    "\n",
    "    for terminal_segment, network in networks.items():\n",
    "        if network[\"network_seqorder\"] not in ordered_networks:\n",
    "            ordered_networks[network[\"network_seqorder\"]] = []\n",
    "        ordered_networks[network[\"network_seqorder\"]].append(\n",
    "            (terminal_segment, network)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordering waterbody subnetworks complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "else:\n",
    "    # If we are not splitting the networks, we can put them all in one order\n",
    "    max_network_seqorder = 0\n",
    "    ordered_networks = {}\n",
    "    ordered_networks[0] = [\n",
    "        (terminal_segment, network) for terminal_segment, network in networks.items()\n",
    "    ]\n",
    "\n",
    "if do_network_analysis_only:\n",
    "    sys.exit()\n",
    "\n",
    "if break_network_at_waterbodies:\n",
    "    ## STEP 3c: Handle Waterbody Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting waterbody initial states ...\")\n",
    "\n",
    "    if wrf_hydro_waterbody_restart_file:\n",
    "\n",
    "        waterbody_initial_states_df = nio.get_reservoir_restart_from_wrf_hydro(\n",
    "            wrf_hydro_waterbody_restart_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file,\n",
    "            wrf_hydro_waterbody_ID_crosswalk_file_field_name,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file,\n",
    "            wrf_hydro_waterbody_crosswalk_filter_file_field_name,\n",
    "        )\n",
    "    else:\n",
    "        # TODO: Consider adding option to read cold state from route-link file\n",
    "        waterbody_initial_ds_flow_const = 0.0\n",
    "        waterbody_initial_depth_const = 0.0\n",
    "        # Set initial states from cold-state\n",
    "        waterbody_initial_states_df = pd.DataFrame(\n",
    "            0, index=waterbodies_df.index, columns=[\"qd0\", \"h0\",], dtype=\"float32\"\n",
    "        )\n",
    "        # TODO: This assignment could probably by done in the above call\n",
    "        waterbody_initial_states_df[\"qd0\"] = waterbody_initial_ds_flow_const\n",
    "        waterbody_initial_states_df[\"h0\"] = waterbody_initial_depth_const\n",
    "        waterbody_initial_states_df[\"index\"] = range(len(waterbody_initial_states_df))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"waterbody initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.020316600799560547 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Handle Channel Initial States\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"setting channel initial states ...\")\n",
    "\n",
    "if wrf_hydro_channel_restart_file:\n",
    "\n",
    "    channel_initial_states_df = nio.get_stream_restart_from_wrf_hydro(\n",
    "        wrf_hydro_channel_restart_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file,\n",
    "        wrf_hydro_channel_ID_crosswalk_file_field_name,\n",
    "        wrf_hydro_channel_restart_upstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_downstream_flow_field_name,\n",
    "        wrf_hydro_channel_restart_depth_flow_field_name,\n",
    "    )\n",
    "else:\n",
    "    # TODO: Consider adding option to read cold state from route-link file\n",
    "    channel_initial_us_flow_const = 0.0\n",
    "    channel_initial_ds_flow_const = 0.0\n",
    "    channel_initial_depth_const = 0.0\n",
    "    # Set initial states from cold-state\n",
    "    channel_initial_states_df = pd.DataFrame(\n",
    "        0, index=connections.keys(), columns=[\"qu0\", \"qd0\", \"h0\",], dtype=\"float32\"\n",
    "    )\n",
    "    channel_initial_states_df[\"qu0\"] = channel_initial_us_flow_const\n",
    "    channel_initial_states_df[\"qd0\"] = channel_initial_ds_flow_const\n",
    "    channel_initial_states_df[\"h0\"] = channel_initial_depth_const\n",
    "    channel_initial_states_df[\"index\"] = range(len(channel_initial_states_df))\n",
    "\n",
    "if verbose:\n",
    "    print(\"channel initial states complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 6.030196905136108 seconds.\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Read (or set) QLateral Inputs\n",
    "if showtiming:\n",
    "    start_time = time.time()\n",
    "if verbose:\n",
    "    print(\"creating qlateral array ...\")\n",
    "\n",
    "# initialize qlateral dict\n",
    "qlateral = {}\n",
    "\n",
    "if qlat_input_folder:\n",
    "    qlat_files = []\n",
    "    for pattern in qlat_file_pattern_filter:\n",
    "        qlat_files.extend(glob.glob(qlat_input_folder + pattern))\n",
    "    qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "        qlat_files=qlat_files,\n",
    "        index_col=qlat_file_index_col,\n",
    "        value_col=qlat_file_value_col,\n",
    "    )\n",
    "\n",
    "elif qlat_input_file:\n",
    "    qlat_df = nio.get_ql_from_csv(qlat_input_file)\n",
    "\n",
    "else:\n",
    "    qlat_df = pd.DataFrame(\n",
    "        qlat_const, index=connections.keys(), columns=range(nts), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "for index, row in qlat_df.iterrows():\n",
    "    qlateral[index] = row.tolist()\n",
    "\n",
    "if verbose:\n",
    "    print(\"qlateral array complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Sort the ordered networks\n",
    "if sort_networks:\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"sorting the ordered networks ...\")\n",
    "\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        sort_ordered_network(ordered_networks[nsq], True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"sorting complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing netcdf output to --> ../../test/output/text/8777247.ncwriting netcdf output to --> ../../test/output/text/8777239.ncwriting netcdf output to --> ../../test/output/text/8777229.nc\n",
      "\n",
      "writing netcdf output to --> ../../test/output/text/8777253.nc\n",
      "\n",
      "writing netcdf output to --> ../../test/output/text/8777191.ncwriting netcdf output to --> ../../test/output/text/8777173.nc\n",
      "\n",
      "writing netcdf output to --> ../../test/output/text/8777285.nc\n",
      "writing netcdf output to --> ../../test/output/text/8778365.nc\n",
      "writing netcdf output to --> ../../test/output/text/8777207.nc\n",
      "writing netcdf output to --> ../../test/output/text/8777187.nc\n",
      "writing netcdf output to --> ../../test/output/text/8777241.nc\n",
      "writing netcdf output to --> ../../test/output/text/8777141.nc\n",
      "writing netcdf output to --> ../../test/output/text/8777225.nc\n",
      "writing netcdf output to --> ../../test/output/text/8777125.nc\n",
      "writing netcdf output to --> ../../test/output/text/8778363.nc\n",
      "writing netcdf output to --> ../../test/output/text/8778465.nc\n",
      "writing netcdf output to --> ../../test/output/text/8778503.nc\n",
      "writing segment output to --> ../../test/output/text/933020089.csv\n",
      "writing netcdf output to --> ../../test/output/text/933020089.nc\n"
     ]
    }
   ],
   "source": [
    "# Define the pool after we create the static global objects (and collect the garbage)\n",
    "if parallel_compute:\n",
    "    import gc\n",
    "\n",
    "    gc.collect()\n",
    "    pool = multiprocessing.Pool(cpu_pool)\n",
    "\n",
    "flowveldepth_connect = (\n",
    "    {}\n",
    ")  # dict to contain values to transfer from upstream to downstream networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1108 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing routing computation ...\n",
      "routing ordered reaches for networks of order 2 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 467/1108 [00:59<01:21,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 60.87676024436951 seconds.\n",
      "max_courant: [5.51265717]\n",
      "routing ordered reaches for networks of order 1 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 499/1108 [01:23<03:12,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 85.1832218170166 seconds.\n",
      "max_courant: [0.]\n",
      "routing ordered reaches for networks of order 0 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [03:02<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... complete in 183.91847133636475 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [03:07<00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_courant: [25.36383247]\n",
      "ordered reach computation complete\n",
      "... in 187.30772423744202 seconds.\n",
      "program complete\n",
      "... in 195.129958152771 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################### Main Execution Loop across ordered networks\n",
    "if showtiming:\n",
    "    main_start_time = time.time()\n",
    "if verbose:\n",
    "    print(f\"executing routing computation ...\")\n",
    "\n",
    "compute_network_func = tr.compute_network\n",
    "\n",
    "tr.connections = connections\n",
    "tr.networks = networks\n",
    "tr.qlateral = qlateral\n",
    "tr.waterbodies_df = waterbodies_df\n",
    "tr.waterbody_initial_states_df = waterbody_initial_states_df\n",
    "tr.channel_initial_states_df = channel_initial_states_df\n",
    "\n",
    "progress_count = 0\n",
    "percentage_complete = True\n",
    "if percentage_complete:\n",
    "    for nsq in range(max_network_seqorder, -1, -1):\n",
    "        for terminal_segment, network in ordered_networks[nsq]:\n",
    "            progress_count += len(network[\"all_segments\"])\n",
    "    pbar = tqdm(total=(progress_count))\n",
    "\n",
    "for nsq in range(max_network_seqorder, -1, -1):\n",
    "\n",
    "    if parallel_compute:\n",
    "        nslist = []\n",
    "    results = []\n",
    "\n",
    "    current_index_total = 0\n",
    "\n",
    "    for terminal_segment, network in ordered_networks[nsq]:\n",
    "\n",
    "        if percentage_complete:\n",
    "            if current_index_total == 0:\n",
    "                pbar.update(0)\n",
    "\n",
    "        if break_network_at_waterbodies:\n",
    "            waterbody = waterbodies_segments.get(terminal_segment)\n",
    "        else:\n",
    "            waterbody = None\n",
    "        if not parallel_compute:  # serial execution\n",
    "            if showtiming:\n",
    "                start_time = time.time()\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"routing ordered reaches for terminal segment {terminal_segment} ...\"\n",
    "                )\n",
    "\n",
    "            results.append(\n",
    "                compute_network_func(\n",
    "                    flowveldepth_connect=flowveldepth_connect,\n",
    "                    terminal_segment=terminal_segment,\n",
    "                    supernetwork_parameters=supernetwork_parameters,\n",
    "                    waterbody_parameters=waterbody_parameters,\n",
    "                    waterbody=waterbody,\n",
    "                    nts=nts,\n",
    "                    dt=dt,\n",
    "                    qts_subdivisions=qts_subdivisions,\n",
    "                    verbose=verbose,\n",
    "                    debuglevel=debuglevel,\n",
    "                    csv_output=csv_output,\n",
    "                    nc_output_folder=nc_output_folder,\n",
    "                    assume_short_ts=assume_short_ts,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if showtiming:\n",
    "                print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "            if percentage_complete:\n",
    "                pbar.update(len(network[\"all_segments\"]))\n",
    "\n",
    "        else:  # parallel execution\n",
    "            nslist.append(\n",
    "                [\n",
    "                    flowveldepth_connect,\n",
    "                    terminal_segment,\n",
    "                    supernetwork_parameters,  # TODO: This should probably be global...\n",
    "                    waterbody_parameters,\n",
    "                    waterbody,\n",
    "                    nts,\n",
    "                    dt,\n",
    "                    qts_subdivisions,\n",
    "                    verbose,\n",
    "                    debuglevel,\n",
    "                    csv_output,\n",
    "                    nc_output_folder,\n",
    "                    assume_short_ts,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    if parallel_compute:\n",
    "        if verbose:\n",
    "            print(f\"routing ordered reaches for networks of order {nsq} ... \")\n",
    "        if debuglevel <= -2:\n",
    "            print(f\"reaches to be routed include:\")\n",
    "            print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "        # with pool:\n",
    "        # with multiprocessing.Pool() as pool:\n",
    "        results = pool.starmap(compute_network_func, nslist)\n",
    "\n",
    "        if showtiming:\n",
    "            print(\"... complete in %s seconds.\" % (time.time() - start_time))\n",
    "        if percentage_complete:\n",
    "            pbar.update(\n",
    "                sum(\n",
    "                    len(network[1][\"all_segments\"]) for network in ordered_networks[nsq]\n",
    "                )\n",
    "            )\n",
    "            # print(f\"{[network[0] for network in ordered_networks[nsq]]}\")\n",
    "\n",
    "    max_courant = 0\n",
    "    maxa = []\n",
    "    for result in results:\n",
    "        for seg in result:\n",
    "            maxa.extend(result[seg][:, 8:9])\n",
    "    max_courant = max(maxa)\n",
    "    print(f\"max_courant: {max_courant}\")\n",
    "\n",
    "    if (\n",
    "        nsq > 0\n",
    "    ):  # We skip this step for zero-order networks, i.e., those that have no downstream dependents\n",
    "        flowveldepth_connect = (\n",
    "            {}\n",
    "        )  # There is no need to preserve previously passed on values -- so we clear the dictionary\n",
    "        for i, (terminal_segment, network) in enumerate(ordered_networks[nsq]):\n",
    "            # seg = network[\"reaches\"][network[\"terminal_reach\"]][\"reach_tail\"]\n",
    "            seg = terminal_segment\n",
    "            flowveldepth_connect[seg] = {}\n",
    "            flowveldepth_connect[seg] = results[i][seg]\n",
    "            # TODO: The value passed here could be much more specific to\n",
    "            # TODO: exactly and only the most recent time step for the passing reach\n",
    "\n",
    "if parallel_compute:\n",
    "    pool.close()\n",
    "\n",
    "if percentage_complete:\n",
    "    pbar.close()\n",
    "\n",
    "if verbose:\n",
    "    print(\"ordered reach computation complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - main_start_time))\n",
    "if verbose:\n",
    "    print(\"program complete\")\n",
    "if showtiming:\n",
    "    print(\"... in %s seconds.\" % (time.time() - program_start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results)\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "all_results = {}\n",
    "seg_courant_maxes = []\n",
    "time = []\n",
    "flowval = []  # flowval\n",
    "velval_list = []  # velval\n",
    "depthval = []  # depthval\n",
    "qlatval = []  # qlatval\n",
    "storageval = []  # storageval\n",
    "qlatCumval = []  # qlatCumval\n",
    "kinCelerity = [] # ck\n",
    "courant = [] # cn\n",
    "X = [] # X\n",
    "\n",
    "for result in results:\n",
    "    all_results.update(result)\n",
    "\n",
    "# print(all_results[8780801][1][0])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# print(all_results)\n",
    "\n",
    "for key , data in all_results.items():\n",
    "    time.extend(data[:,0]) # time\n",
    "    flowval.extend(data[:,1])  # flowval\n",
    "    velval_list.extend(data[:,2]) # velval\n",
    "    depthval.extend(data[:,3])  # depthval\n",
    "    qlatval.extend(data[:,4])  # qlatval\n",
    "    storageval.extend(data[:,5]) # storageval\n",
    "    qlatCumval.extend(data[:,6])  # qlatCumval\n",
    "    kinCelerity.extend(data[:,7]) # ck\n",
    "    courant.extend(data[:,8]) # cn\n",
    "    X.extend(data[:,9]) # X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10998000"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_seg_length = len(all_results[933020089][:,0])\n",
    "single_seg_length*611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10998000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>6.984919e-09</td>\n",
       "      <td>1.062422e-02</td>\n",
       "      <td>0.055861</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>0.499502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033788</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.309672e-08</td>\n",
       "      <td>2.124843e-02</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.017565</td>\n",
       "      <td>0.499503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033795</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.833541e-08</td>\n",
       "      <td>3.187265e-02</td>\n",
       "      <td>0.055926</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>0.499503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033797</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>2.357410e-08</td>\n",
       "      <td>4.249686e-02</td>\n",
       "      <td>0.055929</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.499503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780801</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.033797</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>2.793968e-08</td>\n",
       "      <td>5.312108e-02</td>\n",
       "      <td>0.055930</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.499503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>1079700.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>8.546982e+06</td>\n",
       "      <td>1.440267e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>1079760.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>8.547031e+06</td>\n",
       "      <td>1.440275e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>1079820.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>8.547080e+06</td>\n",
       "      <td>1.440283e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>1079880.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>8.547129e+06</td>\n",
       "      <td>1.440291e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778465</th>\n",
       "      <td>1079940.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>8.547178e+06</td>\n",
       "      <td>1.440299e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10998000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                time   flowval  velval_list  depthval   qlatval    storageval  \\\n",
       "key_index                                                                       \n",
       "8780801          0.0  0.000177     0.033756  0.004995  0.000177  6.984919e-09   \n",
       "8780801         60.0  0.000177     0.033788  0.005002  0.000177  1.309672e-08   \n",
       "8780801        120.0  0.000177     0.033795  0.005004  0.000177  1.833541e-08   \n",
       "8780801        180.0  0.000177     0.033797  0.005004  0.000177  2.357410e-08   \n",
       "8780801        240.0  0.000177     0.033797  0.005004  0.000177  2.793968e-08   \n",
       "...              ...       ...          ...       ...       ...           ...   \n",
       "8778465    1079700.0  0.000033     0.000000  0.000000  0.133463  8.546982e+06   \n",
       "8778465    1079760.0  0.000033     0.000000  0.000000  0.133463  8.547031e+06   \n",
       "8778465    1079820.0  0.000033     0.000000  0.000000  0.133463  8.547080e+06   \n",
       "8778465    1079880.0  0.000033     0.000000  0.000000  0.133463  8.547129e+06   \n",
       "8778465    1079940.0  0.000033     0.000000  0.000000  0.133463  8.547178e+06   \n",
       "\n",
       "             qlatCumval  kinCelerity   courant         X  \n",
       "key_index                                                 \n",
       "8780801    1.062422e-02     0.055861  0.017548  0.499502  \n",
       "8780801    2.124843e-02     0.055914  0.017565  0.499503  \n",
       "8780801    3.187265e-02     0.055926  0.017568  0.499503  \n",
       "8780801    4.249686e-02     0.055929  0.017569  0.499503  \n",
       "8780801    5.312108e-02     0.055930  0.017569  0.499503  \n",
       "...                 ...          ...       ...       ...  \n",
       "8778465    1.440267e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.440275e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.440283e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.440291e+06     0.000000  0.000000  0.000000  \n",
       "8778465    1.440299e+06     0.000000  0.000000  0.000000  \n",
       "\n",
       "[10998000 rows x 10 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_index = all_results.keys()\n",
    "key_index = list(itertools.chain.from_iterable(itertools.repeat(x, single_seg_length) for x in key_index))\n",
    "data = {'key_index':list(key_index),\n",
    "        'time':list(time),\n",
    "        'flowval':list(flowval),\n",
    "        'velval_list':list(velval_list),\n",
    "        'depthval':list(depthval),\n",
    "        'qlatval':list(qlatval),\n",
    "        'storageval':list(storageval),\n",
    "        'qlatCumval':list(qlatCumval),\n",
    "        'kinCelerity':list(kinCelerity),\n",
    "        'courant':list(courant),\n",
    "        'X':list(X)}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index('key_index')  \n",
    "df = df.reset_index()\n",
    "df = df.set_index('key_index')  \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /home/jacob.hreha/jupyter/lib/python3.6/site-packages (4.9.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/jacob.hreha/jupyter/lib/python3.6/site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in /home/jacob.hreha/jupyter/lib/python3.6/site-packages (from plotly) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 25 courants based on our work this morning and their segment IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(933020027, 25.363832473754883), (8777735, 14.950478553771973), (933020017, 9.564001083374023), (8778581, 8.574037551879883), (933020059, 7.254691123962402), (933020061, 4.696855068206787), (8780597, 3.591726064682007), (933020020, 2.8707876205444336), (933020058, 2.4734983444213867), (933020023, 2.1059963703155518), (8777485, 1.860101580619812), (933020036, 1.6248382329940796), (8778795, 1.6150635480880737), (8778021, 1.4462398290634155), (8777339, 1.393180251121521), (8777867, 1.353600263595581), (8777477, 1.3393661975860596), (8780495, 1.263046383857727), (8777861, 1.1583272218704224), (8777481, 1.149632215499878), (8780607, 1.0738232135772705), (933020050, 1.0441739559173584), (8779003, 0.9976801872253418), (8780751, 0.9917784929275513), (8778947, 0.9753884673118591)]\n"
     ]
    }
   ],
   "source": [
    "seg_list = []\n",
    "seg_courant_maxes = []\n",
    "for seg in all_results:\n",
    "    seg_list.append(seg)\n",
    "    seg_courant_maxes.append(max(all_results[seg][:,tr.courant_index]))\n",
    "zipped = zip(seg_list,seg_courant_maxes)\n",
    "zipped = list(zipped)\n",
    "res = sorted(zipped, key = lambda x: x[1],reverse=True) \n",
    "# A.sort(reverse=True)\n",
    "res = (res)[:25]\n",
    "print((res)[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list of those IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[933020027,\n",
       " 8777735,\n",
       " 933020017,\n",
       " 8778581,\n",
       " 933020059,\n",
       " 933020061,\n",
       " 8780597,\n",
       " 933020020,\n",
       " 933020058,\n",
       " 933020023,\n",
       " 8777485,\n",
       " 933020036,\n",
       " 8778795,\n",
       " 8778021,\n",
       " 8777339,\n",
       " 8777867,\n",
       " 8777477,\n",
       " 8780495,\n",
       " 8777861,\n",
       " 8777481,\n",
       " 8780607,\n",
       " 933020050,\n",
       " 8779003,\n",
       " 8780751,\n",
       " 8778947]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_segments = []\n",
    "for x,y in res[:25]:\n",
    "    major_segments.append(x)\n",
    "major_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out the above segment IDs from the original df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.206769</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>3.463928e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.341748</td>\n",
       "      <td>1.864082</td>\n",
       "      <td>0.497108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.206816</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>3.463928e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.341824</td>\n",
       "      <td>1.864496</td>\n",
       "      <td>0.497108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.206857</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>3.463928e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.341891</td>\n",
       "      <td>1.864862</td>\n",
       "      <td>0.497107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>3.463928e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.341956</td>\n",
       "      <td>1.865216</td>\n",
       "      <td>0.497106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777735</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.206935</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>3.463928e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>0.342019</td>\n",
       "      <td>1.865557</td>\n",
       "      <td>0.497106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>1079700.0</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.119810</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>6.069202e-07</td>\n",
       "      <td>-15.666612</td>\n",
       "      <td>45.220530</td>\n",
       "      <td>0.196448</td>\n",
       "      <td>0.129526</td>\n",
       "      <td>0.494083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>1079760.0</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.119809</td>\n",
       "      <td>0.024855</td>\n",
       "      <td>6.069202e-07</td>\n",
       "      <td>-15.666626</td>\n",
       "      <td>45.220566</td>\n",
       "      <td>0.196447</td>\n",
       "      <td>0.129526</td>\n",
       "      <td>0.494083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>1079820.0</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.119809</td>\n",
       "      <td>0.024855</td>\n",
       "      <td>6.069202e-07</td>\n",
       "      <td>-15.666641</td>\n",
       "      <td>45.220603</td>\n",
       "      <td>0.196447</td>\n",
       "      <td>0.129525</td>\n",
       "      <td>0.494083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>1079880.0</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.119808</td>\n",
       "      <td>0.024855</td>\n",
       "      <td>6.069202e-07</td>\n",
       "      <td>-15.666656</td>\n",
       "      <td>45.220639</td>\n",
       "      <td>0.196446</td>\n",
       "      <td>0.129525</td>\n",
       "      <td>0.494083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780751</th>\n",
       "      <td>1079940.0</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.119808</td>\n",
       "      <td>0.024855</td>\n",
       "      <td>6.069202e-07</td>\n",
       "      <td>-15.666671</td>\n",
       "      <td>45.220675</td>\n",
       "      <td>0.196445</td>\n",
       "      <td>0.129524</td>\n",
       "      <td>0.494083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                time   flowval  velval_list  depthval       qlatval  \\\n",
       "key_index                                                             \n",
       "8777735          0.0  0.004696     0.206769  0.011542  3.463928e-05   \n",
       "8777735         60.0  0.004698     0.206816  0.011546  3.463928e-05   \n",
       "8777735        120.0  0.004700     0.206857  0.011549  3.463928e-05   \n",
       "8777735        180.0  0.004703     0.206897  0.011552  3.463928e-05   \n",
       "8777735        240.0  0.004705     0.206935  0.011556  3.463928e-05   \n",
       "...              ...       ...          ...       ...           ...   \n",
       "8780751    1079700.0  0.006394     0.119810  0.024856  6.069202e-07   \n",
       "8780751    1079760.0  0.006394     0.119809  0.024855  6.069202e-07   \n",
       "8780751    1079820.0  0.006394     0.119809  0.024855  6.069202e-07   \n",
       "8780751    1079880.0  0.006394     0.119808  0.024855  6.069202e-07   \n",
       "8780751    1079940.0  0.006394     0.119808  0.024855  6.069202e-07   \n",
       "\n",
       "           storageval  qlatCumval  kinCelerity   courant         X  \n",
       "key_index                                                           \n",
       "8777735      0.000002    0.002078     0.341748  1.864082  0.497108  \n",
       "8777735      0.000003    0.004157     0.341824  1.864496  0.497108  \n",
       "8777735      0.000003    0.006235     0.341891  1.864862  0.497107  \n",
       "8777735      0.000004    0.008313     0.341956  1.865216  0.497106  \n",
       "8777735      0.000004    0.010392     0.342019  1.865557  0.497106  \n",
       "...               ...         ...          ...       ...       ...  \n",
       "8780751    -15.666612   45.220530     0.196448  0.129526  0.494083  \n",
       "8780751    -15.666626   45.220566     0.196447  0.129526  0.494083  \n",
       "8780751    -15.666641   45.220603     0.196447  0.129525  0.494083  \n",
       "8780751    -15.666656   45.220639     0.196446  0.129525  0.494083  \n",
       "8780751    -15.666671   45.220675     0.196445  0.129524  0.494083  \n",
       "\n",
       "[450000 rows x 10 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_filtered= df.loc[ df.index.isin(major_segments), : ]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flowval</th>\n",
       "      <th>velval_list</th>\n",
       "      <th>depthval</th>\n",
       "      <th>qlatval</th>\n",
       "      <th>storageval</th>\n",
       "      <th>qlatCumval</th>\n",
       "      <th>kinCelerity</th>\n",
       "      <th>courant</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>933020027</th>\n",
       "      <td>302400.0</td>\n",
       "      <td>15.181515</td>\n",
       "      <td>4.458032</td>\n",
       "      <td>1.180036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.131263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.227305</td>\n",
       "      <td>25.363832</td>\n",
       "      <td>0.40232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time    flowval  velval_list  depthval  qlatval  storageval  \\\n",
       "key_index                                                                    \n",
       "933020027  302400.0  15.181515     4.458032  1.180036      0.0   58.131263   \n",
       "\n",
       "           qlatCumval  kinCelerity    courant        X  \n",
       "key_index                                               \n",
       "933020027         0.0     4.227305  25.363832  0.40232  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['courant'] == 25.363832473754883]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automated plotter based on filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 18000\n",
      "18000 36000\n",
      "36000 54000\n",
      "54000 72000\n",
      "72000 90000\n",
      "90000 108000\n",
      "108000 126000\n",
      "126000 144000\n",
      "144000 162000\n",
      "162000 180000\n",
      "180000 198000\n",
      "198000 216000\n",
      "216000 234000\n",
      "234000 252000\n",
      "252000 270000\n",
      "270000 288000\n",
      "288000 306000\n",
      "306000 324000\n",
      "324000 342000\n",
      "342000 360000\n",
      "360000 378000\n",
      "378000 396000\n",
      "396000 414000\n",
      "414000 432000\n",
      "432000 450000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "import plotly.io as pio\n",
    "df_indexed = df_filtered.reset_index()\n",
    "test_chart = go.FigureWidget()\n",
    "for x in range(0,25):\n",
    "    temp_df_range_1 = single_seg_length*(x)\n",
    "    temp_df_range_2 = single_seg_length*(x+1)\n",
    "    print(temp_df_range_1,temp_df_range_2)\n",
    "    test_chart.add_scatter(x=df_indexed[temp_df_range_1:temp_df_range_2]['time'],\n",
    "        y=df_indexed[temp_df_range_1:temp_df_range_2]['flowval'],\n",
    "    name=\"segment \" + str(df_indexed['key_index'][temp_df_range_1])\n",
    "            );\n",
    "test_chart.layout.title = \"Timestep Chart \" + str(dt)\n",
    "plot(test_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
